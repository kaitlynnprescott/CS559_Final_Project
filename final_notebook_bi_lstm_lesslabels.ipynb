{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Reduced Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "<ul>\n",
    "    <li>Get all possible genres.</li>\n",
    "    <li>Vectorize Genres:</li>\n",
    "    <ul>\n",
    "        <li>Save genres as a vector of 0s and 1s.</li>\n",
    "        <li>Save genres as list of strings.</li>\n",
    "    </ul>\n",
    "    <li>Process Overview Category</li>\n",
    "    <ul>\n",
    "        <li>Remove punctuation</li>\n",
    "        <li>Set to lowercase</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure': 0,\n",
       " 'Romance': 1,\n",
       " 'Horror-Thriller': 2,\n",
       " 'Comedy': 3,\n",
       " 'Science Fiction': 4,\n",
       " 'Drama': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "genre_dict['Drama'] = 5\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "genre_map['Fantasy'] = 'Science Fiction'\n",
    "genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM \n",
    "<ul>\n",
    "    <li>Get Word Embeddings</li>\n",
    "    <li>Tokenize words</li>\n",
    "    <li>Vectorize Overview</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 1, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 100\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metrics\n",
    "<ul>\n",
    "    <li>Get accuracy, precision, recall for each genre.</li>\n",
    "    <li>Get multi-label metrics.</li>\n",
    "    <li>Compute hamming loss.</li>\n",
    "    <li>Implement Delayed Early Stopping.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network\n",
    "<ul>\n",
    "    <li>Add Embedding layer</li>\n",
    "    <li>Add Convolutional layer</li>\n",
    "    <li>Add MaxPooling layer</li>\n",
    "    <li>Add Bi-directional LSTM layer</li>\n",
    "    <li>Add Dense layers</li>\n",
    "    <li>Compile model</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model_lstm = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=100, trainable=True)\n",
    "model_lstm.add(e)\n",
    "model_lstm.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_lstm.add(MaxPooling1D())\n",
    "model_lstm.add(Bidirectional(LSTM(100)))\n",
    "model_lstm.add(Dense(256, activation='relu'))\n",
    "model_lstm.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict\n",
    "Train and predict model for each epoch, with early stopping to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000\n",
      "WARNING:tensorflow:From /usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 37s 18ms/step - loss: 0.6039 - raw_multi_label_accuracy: 0.1382 - val_loss: 0.5997 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch: 2/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 24s 11ms/step - loss: 0.5881 - raw_multi_label_accuracy: 0.2298 - val_loss: 0.6022 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch: 3/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 18s 8ms/step - loss: 0.5866 - raw_multi_label_accuracy: 0.2310 - val_loss: 0.5991 - val_raw_multi_label_accuracy: 0.1355\n",
      "Epoch: 4/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 20s 10ms/step - loss: 0.5871 - raw_multi_label_accuracy: 0.2020 - val_loss: 0.6037 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch: 5/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 22s 11ms/step - loss: 0.5869 - raw_multi_label_accuracy: 0.1694 - val_loss: 0.6035 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch: 6/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 21s 10ms/step - loss: 0.5865 - raw_multi_label_accuracy: 0.1685 - val_loss: 0.6016 - val_raw_multi_label_accuracy: 0.2179\n",
      "Epoch: 7/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 18s 9ms/step - loss: 0.5855 - raw_multi_label_accuracy: 0.2112 - val_loss: 0.5985 - val_raw_multi_label_accuracy: 0.1296\n",
      "Epoch: 8/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.5845 - raw_multi_label_accuracy: 0.2085 - val_loss: 0.5981 - val_raw_multi_label_accuracy: 0.1658\n",
      "Epoch: 9/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.5833 - raw_multi_label_accuracy: 0.1870 - val_loss: 0.6003 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch: 10/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 12s 6ms/step - loss: 0.5812 - raw_multi_label_accuracy: 0.2058 - val_loss: 0.6000 - val_raw_multi_label_accuracy: 0.2086\n",
      "Epoch: 11/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.5729 - raw_multi_label_accuracy: 0.2278 - val_loss: 0.5922 - val_raw_multi_label_accuracy: 0.1283\n",
      "Epoch: 12/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.5339 - raw_multi_label_accuracy: 0.2857 - val_loss: 0.5928 - val_raw_multi_label_accuracy: 0.2676\n",
      "Epoch: 13/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.4773 - raw_multi_label_accuracy: 0.3948 - val_loss: 0.6110 - val_raw_multi_label_accuracy: 0.2948\n",
      "Epoch: 14/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 0.4343 - raw_multi_label_accuracy: 0.4698 - val_loss: 0.6190 - val_raw_multi_label_accuracy: 0.3153\n",
      "Epoch: 15/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 20s 10ms/step - loss: 0.3904 - raw_multi_label_accuracy: 0.5338 - val_loss: 0.6283 - val_raw_multi_label_accuracy: 0.3096\n",
      "Epoch: 16/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.3479 - raw_multi_label_accuracy: 0.5814 - val_loss: 0.6412 - val_raw_multi_label_accuracy: 0.3051\n",
      "Epoch: 17/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.3075 - raw_multi_label_accuracy: 0.6305 - val_loss: 0.7770 - val_raw_multi_label_accuracy: 0.3221\n",
      "Epoch: 18/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 0.2587 - raw_multi_label_accuracy: 0.6912 - val_loss: 0.8227 - val_raw_multi_label_accuracy: 0.3276\n",
      "Epoch: 19/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.2489 - raw_multi_label_accuracy: 0.7018 - val_loss: 0.7727 - val_raw_multi_label_accuracy: 0.3231\n",
      "Epoch: 20/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.1960 - raw_multi_label_accuracy: 0.7771 - val_loss: 0.8929 - val_raw_multi_label_accuracy: 0.3334\n",
      "Epoch: 21/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.1580 - raw_multi_label_accuracy: 0.8224 - val_loss: 1.0093 - val_raw_multi_label_accuracy: 0.3379\n",
      "Epoch: 22/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.1318 - raw_multi_label_accuracy: 0.8599 - val_loss: 1.0658 - val_raw_multi_label_accuracy: 0.3341\n",
      "Epoch: 23/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.1127 - raw_multi_label_accuracy: 0.8774 - val_loss: 1.1715 - val_raw_multi_label_accuracy: 0.3415\n",
      "Epoch: 24/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0894 - raw_multi_label_accuracy: 0.9062 - val_loss: 1.2456 - val_raw_multi_label_accuracy: 0.3369\n",
      "Epoch: 25/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 0.0779 - raw_multi_label_accuracy: 0.9148 - val_loss: 1.2748 - val_raw_multi_label_accuracy: 0.3373\n",
      "Epoch: 26/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.0694 - raw_multi_label_accuracy: 0.9249 - val_loss: 1.3459 - val_raw_multi_label_accuracy: 0.3241\n",
      "Epoch: 27/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.0577 - raw_multi_label_accuracy: 0.9383 - val_loss: 1.5136 - val_raw_multi_label_accuracy: 0.3443\n",
      "Epoch: 28/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.0459 - raw_multi_label_accuracy: 0.9536 - val_loss: 1.5093 - val_raw_multi_label_accuracy: 0.3404\n",
      "Epoch: 29/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.0386 - raw_multi_label_accuracy: 0.9619 - val_loss: 1.6170 - val_raw_multi_label_accuracy: 0.3279\n",
      "Epoch: 30/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.0285 - raw_multi_label_accuracy: 0.9749 - val_loss: 1.7140 - val_raw_multi_label_accuracy: 0.3242\n",
      "Epoch: 31/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.0201 - raw_multi_label_accuracy: 0.9841 - val_loss: 1.8065 - val_raw_multi_label_accuracy: 0.3320\n",
      "Epoch: 32/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0162 - raw_multi_label_accuracy: 0.9880 - val_loss: 1.9439 - val_raw_multi_label_accuracy: 0.3197\n",
      "Epoch: 33/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0113 - raw_multi_label_accuracy: 0.9945 - val_loss: 2.0647 - val_raw_multi_label_accuracy: 0.3403\n",
      "Epoch: 34/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0102 - raw_multi_label_accuracy: 0.9939 - val_loss: 2.1055 - val_raw_multi_label_accuracy: 0.3164\n",
      "Epoch: 35/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.0084 - raw_multi_label_accuracy: 0.9952 - val_loss: 2.0822 - val_raw_multi_label_accuracy: 0.3165\n",
      "Epoch: 36/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.0065 - raw_multi_label_accuracy: 0.9959 - val_loss: 2.1846 - val_raw_multi_label_accuracy: 0.3386\n",
      "Epoch: 37/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 13s 6ms/step - loss: 0.0049 - raw_multi_label_accuracy: 0.9972 - val_loss: 2.2327 - val_raw_multi_label_accuracy: 0.3257\n",
      "Epoch: 38/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0037 - raw_multi_label_accuracy: 0.9990 - val_loss: 2.3811 - val_raw_multi_label_accuracy: 0.3200\n",
      "Epoch: 39/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 0.0027 - raw_multi_label_accuracy: 0.9985 - val_loss: 2.4309 - val_raw_multi_label_accuracy: 0.3316\n",
      "Epoch: 40/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0023 - raw_multi_label_accuracy: 0.9990 - val_loss: 2.4549 - val_raw_multi_label_accuracy: 0.3331\n",
      "Epoch: 41/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 0.0026 - raw_multi_label_accuracy: 0.9992 - val_loss: 2.4414 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch: 42/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 19s 9ms/step - loss: 0.0025 - raw_multi_label_accuracy: 0.9992 - val_loss: 2.4881 - val_raw_multi_label_accuracy: 0.3200\n",
      "Epoch: 43/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 21s 10ms/step - loss: 0.0024 - raw_multi_label_accuracy: 0.9995 - val_loss: 2.4849 - val_raw_multi_label_accuracy: 0.3353\n",
      "Epoch: 44/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 0.0017 - raw_multi_label_accuracy: 0.9992 - val_loss: 2.5978 - val_raw_multi_label_accuracy: 0.3322\n",
      "Epoch: 45/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 9.2762e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.6186 - val_raw_multi_label_accuracy: 0.3275\n",
      "Epoch: 46/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 6.9142e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.6426 - val_raw_multi_label_accuracy: 0.3289\n",
      "Epoch: 47/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 5.4549e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.6679 - val_raw_multi_label_accuracy: 0.3315\n",
      "Epoch: 48/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 4.7413e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.6868 - val_raw_multi_label_accuracy: 0.3259\n",
      "Epoch: 49/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 18s 9ms/step - loss: 4.2949e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7030 - val_raw_multi_label_accuracy: 0.3310\n",
      "Epoch: 50/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 18s 8ms/step - loss: 3.9236e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7275 - val_raw_multi_label_accuracy: 0.3306\n",
      "Epoch: 51/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 21s 10ms/step - loss: 3.6035e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7519 - val_raw_multi_label_accuracy: 0.3295\n",
      "Epoch: 52/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 3.3675e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7643 - val_raw_multi_label_accuracy: 0.3304\n",
      "Epoch: 53/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 3.1057e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7812 - val_raw_multi_label_accuracy: 0.3316\n",
      "Avoid Overfitting, Initiating Early Stopping\n",
      "Epoch: 54/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 2.9480e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7894 - val_raw_multi_label_accuracy: 0.3344\n",
      "Epoch: 55/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 2.7534e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8056 - val_raw_multi_label_accuracy: 0.3345\n",
      "Epoch: 56/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 2.5918e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8137 - val_raw_multi_label_accuracy: 0.3354\n",
      "Epoch: 57/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 2.4745e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8320 - val_raw_multi_label_accuracy: 0.3354\n",
      "Epoch: 58/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 2.3134e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8406 - val_raw_multi_label_accuracy: 0.3377\n",
      "Epoch: 59/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 20s 10ms/step - loss: 2.1921e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8513 - val_raw_multi_label_accuracy: 0.3396\n",
      "Epoch: 60/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 23s 11ms/step - loss: 2.0876e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8627 - val_raw_multi_label_accuracy: 0.3343\n",
      "Epoch: 61/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 1.9907e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8723 - val_raw_multi_label_accuracy: 0.3371\n",
      "Epoch: 62/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 12s 6ms/step - loss: 1.8836e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8824 - val_raw_multi_label_accuracy: 0.3311\n",
      "Epoch: 63/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 12s 6ms/step - loss: 1.8039e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9021 - val_raw_multi_label_accuracy: 0.3391\n",
      "Epoch: 64/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 1.7146e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9018 - val_raw_multi_label_accuracy: 0.3371\n",
      "Epoch: 65/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 1.6232e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9158 - val_raw_multi_label_accuracy: 0.3353\n",
      "Epoch: 66/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 20s 10ms/step - loss: 1.5524e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9268 - val_raw_multi_label_accuracy: 0.3371\n",
      "Epoch: 67/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 25s 12ms/step - loss: 1.4790e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9402 - val_raw_multi_label_accuracy: 0.3381\n",
      "Epoch: 68/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 25s 12ms/step - loss: 1.4085e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9463 - val_raw_multi_label_accuracy: 0.3391\n",
      "Epoch: 69/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 31s 15ms/step - loss: 1.3417e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9552 - val_raw_multi_label_accuracy: 0.3361\n",
      "Epoch: 70/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 20s 9ms/step - loss: 1.2881e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9656 - val_raw_multi_label_accuracy: 0.3367\n",
      "Epoch: 71/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 1.2304e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9753 - val_raw_multi_label_accuracy: 0.3339\n",
      "Epoch: 72/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 17s 8ms/step - loss: 1.1837e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9842 - val_raw_multi_label_accuracy: 0.3371\n",
      "Epoch: 73/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 1.1279e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9955 - val_raw_multi_label_accuracy: 0.3381\n",
      "Epoch: 74/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 16s 8ms/step - loss: 1.0714e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0006 - val_raw_multi_label_accuracy: 0.3376\n",
      "Epoch: 75/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 12s 6ms/step - loss: 1.0459e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0074 - val_raw_multi_label_accuracy: 0.3361\n",
      "Epoch: 76/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 9.9033e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0158 - val_raw_multi_label_accuracy: 0.3386\n",
      "Epoch: 77/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 14s 7ms/step - loss: 9.4899e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0215 - val_raw_multi_label_accuracy: 0.3381\n",
      "Epoch: 78/1000\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 15s 7ms/step - loss: 9.1057e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0349 - val_raw_multi_label_accuracy: 0.3371\n",
      "Stopping Early to Avoid Overfitting.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "history = []\n",
    "test_err = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_recall = []\n",
    "stopping = 1\n",
    "pat = 10\n",
    "patience = 10\n",
    "delay = 25\n",
    "\n",
    "for num in range(n_epochs):\n",
    "    print(\"Epoch: {}/{}\".format(num+1, n_epochs))\n",
    "    this_hist = model_lstm.fit(x_train_seq, y_train, batch_size=100, epochs=1, validation_split=0.1)\n",
    "    history.append(this_hist)\n",
    "    \n",
    "    vl = this_hist.history['val_loss']\n",
    "    \n",
    "    if patience > -1:\n",
    "        if stopping >= vl[0]:\n",
    "            if patience < pat:\n",
    "                patience = pat\n",
    "            stopping = vl\n",
    "        else:\n",
    "            patience -= 1\n",
    "            stopping = vl\n",
    "    else:\n",
    "        delay -= 1\n",
    "        \n",
    "        \n",
    "    this_preds = nn_output_to_predictions(model_lstm.predict(x_test_seq))\n",
    "    acc = multi_label_accuracy(y_test, this_preds)\n",
    "    test_acc.append(acc)\n",
    "    test_err.append(1-acc)\n",
    "    \n",
    "    if patience == 0:\n",
    "        print(\"Avoid Overfitting, Initiating Early Stopping\")\n",
    "        patience = -1\n",
    "        \n",
    "    if delay == 0:\n",
    "        print(\"Stopping Early to Avoid Overfitting.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through history to store accuracies and errors in individual lists\n",
    "all_multi_acc = []\n",
    "all_loss = []\n",
    "all_val_multi_acc = []\n",
    "all_val_loss = []\n",
    "\n",
    "for x in history:\n",
    "    all_multi_acc.append(x.history['raw_multi_label_accuracy'])\n",
    "    all_loss.append(x.history['loss'])\n",
    "    all_val_multi_acc.append(x.history['val_raw_multi_label_accuracy'])\n",
    "    all_val_loss.append(x.history['val_loss'])\n",
    "    \n",
    "# flatten all variables to one dimension list\n",
    "flat_acc = [val for sublist in all_multi_acc for val in sublist]\n",
    "flat_loss = [val for sublist in all_loss for val in sublist]\n",
    "flat_val_acc = [val for sublist in all_val_multi_acc for val in sublist]\n",
    "flat_val_loss = [val for sublist in all_val_loss for val in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot accuracy\n",
    "plt.plot(all_multi_acc)\n",
    "plt.plot(all_val_multi_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.title(\"Bi-Directional LSTM Accuracy - Less Genres\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss (error)\n",
    "plt.plot(all_loss)\n",
    "plt.plot(all_val_loss)\n",
    "plt.plot(test_err)\n",
    "plt.title(\"Bi-Directional LSTM Loss - Less Genres\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Predictions\n",
    "<ul>\n",
    "    <li>Show Multi-Level Metrics</li>\n",
    "    <li>Show percentage of correctly labeled predicitons</li>\n",
    "    <li>Show accuracy, precision, and recall for each genre</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_lstm.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3626157407407409"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46701388888888906"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5316550925925925"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 65.68287037037037\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.6545138888888888\n",
      "Precision for Action-Adventure: 0.47093023255813954\n",
      "Recall for Action-Adventure: 0.42857142857142855\n",
      "\n",
      "Accuruacy for Romance: 0.7413194444444444\n",
      "Precision for Romance: 0.3068181818181818\n",
      "Recall for Romance: 0.23478260869565218\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.5972222222222222\n",
      "Precision for Horror-Thriller: 0.43416370106761565\n",
      "Recall for Horror-Thriller: 0.6256410256410256\n",
      "\n",
      "Accuruacy for Comedy: 0.6215277777777778\n",
      "Precision for Comedy: 0.4406779661016949\n",
      "Recall for Comedy: 0.39593908629441626\n",
      "\n",
      "Accuruacy for Science Fiction: 0.75\n",
      "Precision for Science Fiction: 0.28125\n",
      "Recall for Science Fiction: 0.2647058823529412\n",
      "\n",
      "Accuruacy for Drama: 0.5763888888888888\n",
      "Precision for Drama: 0.5575447570332481\n",
      "Recall for Drama: 0.754325259515571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
