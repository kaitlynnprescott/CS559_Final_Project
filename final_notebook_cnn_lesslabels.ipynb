{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure': 0,\n",
       " 'Romance': 1,\n",
       " 'Horror-Thriller': 2,\n",
       " 'Comedy': 3,\n",
       " 'Science Fiction': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "#genre_dict['Drama'] = 5\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "#genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    text = ' '.join(no_stopword_text)\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN STUFF here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 2, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 150\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 2.0877 - raw_multi_label_accuracy: 0.2180 - val_loss: 1.7679 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 1.5937 - raw_multi_label_accuracy: 0.1558 - val_loss: 1.3683 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 1.2566 - raw_multi_label_accuracy: 0.1077 - val_loss: 1.0980 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 1.0259 - raw_multi_label_accuracy: 0.0908 - val_loss: 0.9151 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.8760 - raw_multi_label_accuracy: 0.0884 - val_loss: 0.7966 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 2s - loss: 0.7720 - raw_multi_label_accuracy: 0.0827 - val_loss: 0.7187 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 0.7044 - raw_multi_label_accuracy: 0.0685 - val_loss: 0.6686 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.6627 - raw_multi_label_accuracy: 0.0419 - val_loss: 0.6389 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.6393 - raw_multi_label_accuracy: 0.0440 - val_loss: 0.6185 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.6249 - raw_multi_label_accuracy: 0.0394 - val_loss: 0.6090 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.6145 - raw_multi_label_accuracy: 0.0330 - val_loss: 0.6003 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 0.6073 - raw_multi_label_accuracy: 0.0283 - val_loss: 0.5973 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 0.6039 - raw_multi_label_accuracy: 0.0300 - val_loss: 0.5942 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      " - 1s - loss: 0.6011 - raw_multi_label_accuracy: 0.0173 - val_loss: 0.5912 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.5981 - raw_multi_label_accuracy: 0.0240 - val_loss: 0.5902 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.5957 - raw_multi_label_accuracy: 0.0139 - val_loss: 0.5896 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.5932 - raw_multi_label_accuracy: 0.0143 - val_loss: 0.5883 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 0.5878 - raw_multi_label_accuracy: 0.0150 - val_loss: 0.5910 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 0.5829 - raw_multi_label_accuracy: 0.0223 - val_loss: 0.5940 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.5710 - raw_multi_label_accuracy: 0.0375 - val_loss: 0.5987 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.5622 - raw_multi_label_accuracy: 0.0456 - val_loss: 0.6047 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.5508 - raw_multi_label_accuracy: 0.0566 - val_loss: 0.6171 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.5470 - raw_multi_label_accuracy: 0.0770 - val_loss: 0.6166 - val_raw_multi_label_accuracy: 0.0069\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 0.5389 - raw_multi_label_accuracy: 0.0781 - val_loss: 0.6200 - val_raw_multi_label_accuracy: 0.0136\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.5343 - raw_multi_label_accuracy: 0.0857 - val_loss: 0.6215 - val_raw_multi_label_accuracy: 0.0134\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.5294 - raw_multi_label_accuracy: 0.0960 - val_loss: 0.6364 - val_raw_multi_label_accuracy: 0.0915\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 0.5269 - raw_multi_label_accuracy: 0.1040 - val_loss: 0.6339 - val_raw_multi_label_accuracy: 0.0420\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.5215 - raw_multi_label_accuracy: 0.1053 - val_loss: 0.6410 - val_raw_multi_label_accuracy: 0.0750\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.5178 - raw_multi_label_accuracy: 0.1186 - val_loss: 0.6371 - val_raw_multi_label_accuracy: 0.0721\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.5140 - raw_multi_label_accuracy: 0.1318 - val_loss: 0.6573 - val_raw_multi_label_accuracy: 0.0689\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.5086 - raw_multi_label_accuracy: 0.1348 - val_loss: 0.6722 - val_raw_multi_label_accuracy: 0.0848\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.5043 - raw_multi_label_accuracy: 0.1535 - val_loss: 0.6758 - val_raw_multi_label_accuracy: 0.0737\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.4979 - raw_multi_label_accuracy: 0.1660 - val_loss: 0.6686 - val_raw_multi_label_accuracy: 0.0451\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.4948 - raw_multi_label_accuracy: 0.1697 - val_loss: 0.6848 - val_raw_multi_label_accuracy: 0.0513\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.4885 - raw_multi_label_accuracy: 0.1976 - val_loss: 0.7085 - val_raw_multi_label_accuracy: 0.0688\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.4826 - raw_multi_label_accuracy: 0.2422 - val_loss: 0.7127 - val_raw_multi_label_accuracy: 0.0444\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.4778 - raw_multi_label_accuracy: 0.2610 - val_loss: 0.7380 - val_raw_multi_label_accuracy: 0.0788\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.4745 - raw_multi_label_accuracy: 0.2740 - val_loss: 0.7694 - val_raw_multi_label_accuracy: 0.0841\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.4669 - raw_multi_label_accuracy: 0.3157 - val_loss: 0.7810 - val_raw_multi_label_accuracy: 0.0997\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.4609 - raw_multi_label_accuracy: 0.3452 - val_loss: 0.8029 - val_raw_multi_label_accuracy: 0.0756\n",
      "Epoch 41/1000\n",
      " - 2s - loss: 0.4552 - raw_multi_label_accuracy: 0.3518 - val_loss: 0.7857 - val_raw_multi_label_accuracy: 0.1028\n",
      "Epoch 42/1000\n",
      " - 2s - loss: 0.4467 - raw_multi_label_accuracy: 0.3690 - val_loss: 0.7794 - val_raw_multi_label_accuracy: 0.0816\n",
      "Epoch 43/1000\n",
      " - 2s - loss: 0.4397 - raw_multi_label_accuracy: 0.4089 - val_loss: 0.8493 - val_raw_multi_label_accuracy: 0.0929\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.4289 - raw_multi_label_accuracy: 0.4389 - val_loss: 0.8449 - val_raw_multi_label_accuracy: 0.1205\n",
      "Epoch 45/1000\n",
      " - 2s - loss: 0.4195 - raw_multi_label_accuracy: 0.4531 - val_loss: 0.9072 - val_raw_multi_label_accuracy: 0.1787\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.4091 - raw_multi_label_accuracy: 0.5026 - val_loss: 0.8951 - val_raw_multi_label_accuracy: 0.1492\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.4029 - raw_multi_label_accuracy: 0.5228 - val_loss: 0.8895 - val_raw_multi_label_accuracy: 0.1900\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.3953 - raw_multi_label_accuracy: 0.5416 - val_loss: 0.9115 - val_raw_multi_label_accuracy: 0.2099\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.3846 - raw_multi_label_accuracy: 0.5572 - val_loss: 0.9353 - val_raw_multi_label_accuracy: 0.2285\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.3759 - raw_multi_label_accuracy: 0.5892 - val_loss: 0.9459 - val_raw_multi_label_accuracy: 0.2255\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.3648 - raw_multi_label_accuracy: 0.5896 - val_loss: 0.9592 - val_raw_multi_label_accuracy: 0.2255\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.3537 - raw_multi_label_accuracy: 0.6124 - val_loss: 0.9757 - val_raw_multi_label_accuracy: 0.2394\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.3420 - raw_multi_label_accuracy: 0.6299 - val_loss: 0.9572 - val_raw_multi_label_accuracy: 0.2295\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.3423 - raw_multi_label_accuracy: 0.6279 - val_loss: 0.9867 - val_raw_multi_label_accuracy: 0.2454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      " - 1s - loss: 0.3310 - raw_multi_label_accuracy: 0.6441 - val_loss: 1.0216 - val_raw_multi_label_accuracy: 0.2476\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 0.3258 - raw_multi_label_accuracy: 0.6547 - val_loss: 1.0006 - val_raw_multi_label_accuracy: 0.2557\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.3223 - raw_multi_label_accuracy: 0.6561 - val_loss: 1.0983 - val_raw_multi_label_accuracy: 0.2544\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 0.3178 - raw_multi_label_accuracy: 0.6558 - val_loss: 1.0515 - val_raw_multi_label_accuracy: 0.2422\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 0.3064 - raw_multi_label_accuracy: 0.6880 - val_loss: 1.1016 - val_raw_multi_label_accuracy: 0.2517\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.3062 - raw_multi_label_accuracy: 0.6852 - val_loss: 1.0676 - val_raw_multi_label_accuracy: 0.2621\n",
      "Epoch 61/1000\n",
      " - 1s - loss: 0.3043 - raw_multi_label_accuracy: 0.6764 - val_loss: 1.1220 - val_raw_multi_label_accuracy: 0.2718\n",
      "Epoch 62/1000\n",
      " - 1s - loss: 0.3046 - raw_multi_label_accuracy: 0.6786 - val_loss: 1.1411 - val_raw_multi_label_accuracy: 0.2634\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 0.2969 - raw_multi_label_accuracy: 0.6882 - val_loss: 1.1137 - val_raw_multi_label_accuracy: 0.2494\n",
      "Epoch 64/1000\n",
      " - 1s - loss: 0.2872 - raw_multi_label_accuracy: 0.6964 - val_loss: 1.1418 - val_raw_multi_label_accuracy: 0.2851\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 0.2868 - raw_multi_label_accuracy: 0.7019 - val_loss: 1.1389 - val_raw_multi_label_accuracy: 0.2738\n",
      "Epoch 66/1000\n",
      " - 1s - loss: 0.2902 - raw_multi_label_accuracy: 0.6983 - val_loss: 1.1217 - val_raw_multi_label_accuracy: 0.3010\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 0.2845 - raw_multi_label_accuracy: 0.6970 - val_loss: 1.1761 - val_raw_multi_label_accuracy: 0.2797\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.2853 - raw_multi_label_accuracy: 0.7046 - val_loss: 1.1256 - val_raw_multi_label_accuracy: 0.2630\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.2766 - raw_multi_label_accuracy: 0.7150 - val_loss: 1.1834 - val_raw_multi_label_accuracy: 0.2582\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.2757 - raw_multi_label_accuracy: 0.7143 - val_loss: 1.2062 - val_raw_multi_label_accuracy: 0.2618\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 0.2720 - raw_multi_label_accuracy: 0.7174 - val_loss: 1.1911 - val_raw_multi_label_accuracy: 0.2707\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.2680 - raw_multi_label_accuracy: 0.7254 - val_loss: 1.2187 - val_raw_multi_label_accuracy: 0.2891\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.2743 - raw_multi_label_accuracy: 0.7201 - val_loss: 1.1826 - val_raw_multi_label_accuracy: 0.2666\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.2727 - raw_multi_label_accuracy: 0.7347 - val_loss: 1.2152 - val_raw_multi_label_accuracy: 0.2772\n",
      "Epoch 75/1000\n",
      " - 1s - loss: 0.2670 - raw_multi_label_accuracy: 0.7320 - val_loss: 1.2406 - val_raw_multi_label_accuracy: 0.2769\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 0.2645 - raw_multi_label_accuracy: 0.7291 - val_loss: 1.1969 - val_raw_multi_label_accuracy: 0.2787\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 0.2623 - raw_multi_label_accuracy: 0.7401 - val_loss: 1.2591 - val_raw_multi_label_accuracy: 0.2776\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 0.2593 - raw_multi_label_accuracy: 0.7417 - val_loss: 1.2528 - val_raw_multi_label_accuracy: 0.2671\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.2604 - raw_multi_label_accuracy: 0.7366 - val_loss: 1.2616 - val_raw_multi_label_accuracy: 0.2715\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.2577 - raw_multi_label_accuracy: 0.7374 - val_loss: 1.2276 - val_raw_multi_label_accuracy: 0.2793\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.2619 - raw_multi_label_accuracy: 0.7378 - val_loss: 1.2893 - val_raw_multi_label_accuracy: 0.2766\n",
      "Epoch 82/1000\n",
      " - 1s - loss: 0.2582 - raw_multi_label_accuracy: 0.7461 - val_loss: 1.3060 - val_raw_multi_label_accuracy: 0.2691\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 0.2614 - raw_multi_label_accuracy: 0.7385 - val_loss: 1.2696 - val_raw_multi_label_accuracy: 0.2707\n",
      "Epoch 84/1000\n",
      " - 1s - loss: 0.2487 - raw_multi_label_accuracy: 0.7503 - val_loss: 1.2878 - val_raw_multi_label_accuracy: 0.2654\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.2539 - raw_multi_label_accuracy: 0.7375 - val_loss: 1.2409 - val_raw_multi_label_accuracy: 0.2859\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.2501 - raw_multi_label_accuracy: 0.7532 - val_loss: 1.2503 - val_raw_multi_label_accuracy: 0.2841\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 0.2515 - raw_multi_label_accuracy: 0.7568 - val_loss: 1.3097 - val_raw_multi_label_accuracy: 0.2966\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.2478 - raw_multi_label_accuracy: 0.7500 - val_loss: 1.2951 - val_raw_multi_label_accuracy: 0.2846\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.2509 - raw_multi_label_accuracy: 0.7535 - val_loss: 1.3470 - val_raw_multi_label_accuracy: 0.2934\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 0.2522 - raw_multi_label_accuracy: 0.7482 - val_loss: 1.3128 - val_raw_multi_label_accuracy: 0.2632\n",
      "Epoch 91/1000\n",
      " - 1s - loss: 0.2474 - raw_multi_label_accuracy: 0.7534 - val_loss: 1.2870 - val_raw_multi_label_accuracy: 0.2827\n",
      "Epoch 92/1000\n",
      " - 1s - loss: 0.2429 - raw_multi_label_accuracy: 0.7573 - val_loss: 1.3002 - val_raw_multi_label_accuracy: 0.2837\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 0.2392 - raw_multi_label_accuracy: 0.7701 - val_loss: 1.2779 - val_raw_multi_label_accuracy: 0.2788\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 0.2441 - raw_multi_label_accuracy: 0.7649 - val_loss: 1.2902 - val_raw_multi_label_accuracy: 0.3083\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.2407 - raw_multi_label_accuracy: 0.7706 - val_loss: 1.3116 - val_raw_multi_label_accuracy: 0.2818\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.2404 - raw_multi_label_accuracy: 0.7626 - val_loss: 1.3058 - val_raw_multi_label_accuracy: 0.2905\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 0.2382 - raw_multi_label_accuracy: 0.7652 - val_loss: 1.3309 - val_raw_multi_label_accuracy: 0.2906\n",
      "Epoch 98/1000\n",
      " - 1s - loss: 0.2404 - raw_multi_label_accuracy: 0.7627 - val_loss: 1.3342 - val_raw_multi_label_accuracy: 0.3039\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.2378 - raw_multi_label_accuracy: 0.7812 - val_loss: 1.3263 - val_raw_multi_label_accuracy: 0.2913\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.2386 - raw_multi_label_accuracy: 0.7640 - val_loss: 1.2976 - val_raw_multi_label_accuracy: 0.2839\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.2391 - raw_multi_label_accuracy: 0.7720 - val_loss: 1.3236 - val_raw_multi_label_accuracy: 0.2876\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.2286 - raw_multi_label_accuracy: 0.7833 - val_loss: 1.3134 - val_raw_multi_label_accuracy: 0.2947\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.2335 - raw_multi_label_accuracy: 0.7733 - val_loss: 1.3330 - val_raw_multi_label_accuracy: 0.2963\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.2324 - raw_multi_label_accuracy: 0.7739 - val_loss: 1.3303 - val_raw_multi_label_accuracy: 0.2835\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 0.2308 - raw_multi_label_accuracy: 0.7807 - val_loss: 1.3236 - val_raw_multi_label_accuracy: 0.2951\n",
      "Epoch 106/1000\n",
      " - 1s - loss: 0.2288 - raw_multi_label_accuracy: 0.7731 - val_loss: 1.3446 - val_raw_multi_label_accuracy: 0.2924\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 0.2249 - raw_multi_label_accuracy: 0.7876 - val_loss: 1.3501 - val_raw_multi_label_accuracy: 0.2947\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 0.2281 - raw_multi_label_accuracy: 0.7811 - val_loss: 1.3141 - val_raw_multi_label_accuracy: 0.2932\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 0.2283 - raw_multi_label_accuracy: 0.7816 - val_loss: 1.3920 - val_raw_multi_label_accuracy: 0.2958\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.2282 - raw_multi_label_accuracy: 0.7783 - val_loss: 1.3821 - val_raw_multi_label_accuracy: 0.2941\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 0.2270 - raw_multi_label_accuracy: 0.7786 - val_loss: 1.3188 - val_raw_multi_label_accuracy: 0.2946\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.2239 - raw_multi_label_accuracy: 0.7837 - val_loss: 1.3518 - val_raw_multi_label_accuracy: 0.2846\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 0.2258 - raw_multi_label_accuracy: 0.7811 - val_loss: 1.3323 - val_raw_multi_label_accuracy: 0.2939\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.2273 - raw_multi_label_accuracy: 0.7797 - val_loss: 1.3694 - val_raw_multi_label_accuracy: 0.2986\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 0.2218 - raw_multi_label_accuracy: 0.7917 - val_loss: 1.3136 - val_raw_multi_label_accuracy: 0.2960\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.2199 - raw_multi_label_accuracy: 0.7867 - val_loss: 1.2971 - val_raw_multi_label_accuracy: 0.3009\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.2263 - raw_multi_label_accuracy: 0.7820 - val_loss: 1.3674 - val_raw_multi_label_accuracy: 0.2897\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.2204 - raw_multi_label_accuracy: 0.7921 - val_loss: 1.3385 - val_raw_multi_label_accuracy: 0.3009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      " - 1s - loss: 0.2207 - raw_multi_label_accuracy: 0.7847 - val_loss: 1.3623 - val_raw_multi_label_accuracy: 0.3009\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.2170 - raw_multi_label_accuracy: 0.7966 - val_loss: 1.3945 - val_raw_multi_label_accuracy: 0.2968\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 0.2198 - raw_multi_label_accuracy: 0.7847 - val_loss: 1.4212 - val_raw_multi_label_accuracy: 0.3142\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 0.2225 - raw_multi_label_accuracy: 0.7816 - val_loss: 1.3738 - val_raw_multi_label_accuracy: 0.3095\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 0.2125 - raw_multi_label_accuracy: 0.7998 - val_loss: 1.3630 - val_raw_multi_label_accuracy: 0.3033\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 0.2146 - raw_multi_label_accuracy: 0.7959 - val_loss: 1.3978 - val_raw_multi_label_accuracy: 0.2951\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 0.2199 - raw_multi_label_accuracy: 0.7858 - val_loss: 1.4430 - val_raw_multi_label_accuracy: 0.2995\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 0.2204 - raw_multi_label_accuracy: 0.7881 - val_loss: 1.4169 - val_raw_multi_label_accuracy: 0.3133\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 0.2143 - raw_multi_label_accuracy: 0.7915 - val_loss: 1.4088 - val_raw_multi_label_accuracy: 0.2983\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.2082 - raw_multi_label_accuracy: 0.8012 - val_loss: 1.3626 - val_raw_multi_label_accuracy: 0.3036\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.2152 - raw_multi_label_accuracy: 0.8006 - val_loss: 1.4166 - val_raw_multi_label_accuracy: 0.3169\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.2129 - raw_multi_label_accuracy: 0.7992 - val_loss: 1.4075 - val_raw_multi_label_accuracy: 0.3122\n",
      "Epoch 131/1000\n",
      " - 1s - loss: 0.2109 - raw_multi_label_accuracy: 0.7957 - val_loss: 1.3667 - val_raw_multi_label_accuracy: 0.3121\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.2175 - raw_multi_label_accuracy: 0.7921 - val_loss: 1.3395 - val_raw_multi_label_accuracy: 0.3041\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.2107 - raw_multi_label_accuracy: 0.8008 - val_loss: 1.4171 - val_raw_multi_label_accuracy: 0.2936\n",
      "Epoch 134/1000\n",
      " - 1s - loss: 0.2098 - raw_multi_label_accuracy: 0.7970 - val_loss: 1.4090 - val_raw_multi_label_accuracy: 0.3054\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 0.2122 - raw_multi_label_accuracy: 0.7944 - val_loss: 1.3978 - val_raw_multi_label_accuracy: 0.3148\n",
      "Epoch 136/1000\n",
      " - 1s - loss: 0.2148 - raw_multi_label_accuracy: 0.8001 - val_loss: 1.4518 - val_raw_multi_label_accuracy: 0.3102\n",
      "Epoch 137/1000\n",
      " - 1s - loss: 0.2110 - raw_multi_label_accuracy: 0.7957 - val_loss: 1.4507 - val_raw_multi_label_accuracy: 0.3080\n",
      "Epoch 138/1000\n",
      " - 1s - loss: 0.2101 - raw_multi_label_accuracy: 0.7958 - val_loss: 1.4005 - val_raw_multi_label_accuracy: 0.3119\n",
      "Epoch 139/1000\n",
      " - 1s - loss: 0.2105 - raw_multi_label_accuracy: 0.7962 - val_loss: 1.3648 - val_raw_multi_label_accuracy: 0.3123\n",
      "Epoch 140/1000\n",
      " - 1s - loss: 0.2090 - raw_multi_label_accuracy: 0.7987 - val_loss: 1.4165 - val_raw_multi_label_accuracy: 0.3200\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 0.2100 - raw_multi_label_accuracy: 0.7985 - val_loss: 1.3851 - val_raw_multi_label_accuracy: 0.3097\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.2053 - raw_multi_label_accuracy: 0.8164 - val_loss: 1.3726 - val_raw_multi_label_accuracy: 0.3090\n",
      "Epoch 143/1000\n",
      " - 1s - loss: 0.2039 - raw_multi_label_accuracy: 0.8041 - val_loss: 1.4062 - val_raw_multi_label_accuracy: 0.3203\n",
      "Epoch 144/1000\n",
      " - 1s - loss: 0.2128 - raw_multi_label_accuracy: 0.7920 - val_loss: 1.3592 - val_raw_multi_label_accuracy: 0.3086\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 0.2079 - raw_multi_label_accuracy: 0.8055 - val_loss: 1.4082 - val_raw_multi_label_accuracy: 0.3173\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.2127 - raw_multi_label_accuracy: 0.7961 - val_loss: 1.4326 - val_raw_multi_label_accuracy: 0.3121\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 0.2060 - raw_multi_label_accuracy: 0.8024 - val_loss: 1.4415 - val_raw_multi_label_accuracy: 0.3063\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 0.2038 - raw_multi_label_accuracy: 0.8099 - val_loss: 1.4978 - val_raw_multi_label_accuracy: 0.3107\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 0.2114 - raw_multi_label_accuracy: 0.8001 - val_loss: 1.4957 - val_raw_multi_label_accuracy: 0.3093\n",
      "Epoch 150/1000\n",
      " - 1s - loss: 0.2046 - raw_multi_label_accuracy: 0.8063 - val_loss: 1.4917 - val_raw_multi_label_accuracy: 0.3144\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 0.2071 - raw_multi_label_accuracy: 0.7980 - val_loss: 1.4503 - val_raw_multi_label_accuracy: 0.3064\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 0.2028 - raw_multi_label_accuracy: 0.8093 - val_loss: 1.4059 - val_raw_multi_label_accuracy: 0.3122\n",
      "Epoch 153/1000\n",
      " - 1s - loss: 0.2041 - raw_multi_label_accuracy: 0.8136 - val_loss: 1.4867 - val_raw_multi_label_accuracy: 0.3145\n",
      "Epoch 154/1000\n",
      " - 1s - loss: 0.2010 - raw_multi_label_accuracy: 0.8078 - val_loss: 1.5556 - val_raw_multi_label_accuracy: 0.3122\n",
      "Epoch 155/1000\n",
      " - 1s - loss: 0.2025 - raw_multi_label_accuracy: 0.8083 - val_loss: 1.4491 - val_raw_multi_label_accuracy: 0.3124\n",
      "Epoch 156/1000\n",
      " - 1s - loss: 0.2011 - raw_multi_label_accuracy: 0.8107 - val_loss: 1.5191 - val_raw_multi_label_accuracy: 0.3113\n",
      "Epoch 157/1000\n",
      " - 1s - loss: 0.2015 - raw_multi_label_accuracy: 0.8060 - val_loss: 1.5057 - val_raw_multi_label_accuracy: 0.3188\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 0.1995 - raw_multi_label_accuracy: 0.8086 - val_loss: 1.5152 - val_raw_multi_label_accuracy: 0.3260\n",
      "Epoch 159/1000\n",
      " - 1s - loss: 0.1992 - raw_multi_label_accuracy: 0.8087 - val_loss: 1.5064 - val_raw_multi_label_accuracy: 0.3211\n",
      "Epoch 160/1000\n",
      " - 1s - loss: 0.1981 - raw_multi_label_accuracy: 0.8088 - val_loss: 1.4707 - val_raw_multi_label_accuracy: 0.3152\n",
      "Epoch 161/1000\n",
      " - 1s - loss: 0.1955 - raw_multi_label_accuracy: 0.8099 - val_loss: 1.4106 - val_raw_multi_label_accuracy: 0.3128\n",
      "Epoch 162/1000\n",
      " - 1s - loss: 0.1960 - raw_multi_label_accuracy: 0.8148 - val_loss: 1.4835 - val_raw_multi_label_accuracy: 0.3088\n",
      "Epoch 163/1000\n",
      " - 1s - loss: 0.1984 - raw_multi_label_accuracy: 0.8082 - val_loss: 1.5183 - val_raw_multi_label_accuracy: 0.2964\n",
      "Epoch 164/1000\n",
      " - 1s - loss: 0.2016 - raw_multi_label_accuracy: 0.8028 - val_loss: 1.4576 - val_raw_multi_label_accuracy: 0.3137\n",
      "Epoch 165/1000\n",
      " - 1s - loss: 0.1941 - raw_multi_label_accuracy: 0.8083 - val_loss: 1.4558 - val_raw_multi_label_accuracy: 0.3183\n",
      "Epoch 166/1000\n",
      " - 1s - loss: 0.1961 - raw_multi_label_accuracy: 0.8106 - val_loss: 1.4982 - val_raw_multi_label_accuracy: 0.3092\n",
      "Epoch 167/1000\n",
      " - 1s - loss: 0.1963 - raw_multi_label_accuracy: 0.8103 - val_loss: 1.5322 - val_raw_multi_label_accuracy: 0.3232\n",
      "Epoch 168/1000\n",
      " - 1s - loss: 0.1991 - raw_multi_label_accuracy: 0.8114 - val_loss: 1.5123 - val_raw_multi_label_accuracy: 0.3170\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 0.1950 - raw_multi_label_accuracy: 0.8117 - val_loss: 1.5791 - val_raw_multi_label_accuracy: 0.3160\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 0.1966 - raw_multi_label_accuracy: 0.8164 - val_loss: 1.5405 - val_raw_multi_label_accuracy: 0.3071\n",
      "Epoch 171/1000\n",
      " - 1s - loss: 0.1962 - raw_multi_label_accuracy: 0.8113 - val_loss: 1.5759 - val_raw_multi_label_accuracy: 0.3193\n",
      "Epoch 172/1000\n",
      " - 1s - loss: 0.1946 - raw_multi_label_accuracy: 0.8172 - val_loss: 1.5396 - val_raw_multi_label_accuracy: 0.3267\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 0.1955 - raw_multi_label_accuracy: 0.8070 - val_loss: 1.6396 - val_raw_multi_label_accuracy: 0.3139\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 0.1915 - raw_multi_label_accuracy: 0.8143 - val_loss: 1.5492 - val_raw_multi_label_accuracy: 0.3179\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 0.1921 - raw_multi_label_accuracy: 0.8192 - val_loss: 1.5778 - val_raw_multi_label_accuracy: 0.3232\n",
      "Epoch 176/1000\n",
      " - 1s - loss: 0.1892 - raw_multi_label_accuracy: 0.8146 - val_loss: 1.5566 - val_raw_multi_label_accuracy: 0.3215\n",
      "Epoch 177/1000\n",
      " - 1s - loss: 0.1873 - raw_multi_label_accuracy: 0.8267 - val_loss: 1.5834 - val_raw_multi_label_accuracy: 0.3192\n",
      "Epoch 178/1000\n",
      " - 1s - loss: 0.1930 - raw_multi_label_accuracy: 0.8155 - val_loss: 1.5236 - val_raw_multi_label_accuracy: 0.3247\n",
      "Epoch 179/1000\n",
      " - 1s - loss: 0.1863 - raw_multi_label_accuracy: 0.8220 - val_loss: 1.5669 - val_raw_multi_label_accuracy: 0.3194\n",
      "Epoch 180/1000\n",
      " - 1s - loss: 0.1909 - raw_multi_label_accuracy: 0.8169 - val_loss: 1.5489 - val_raw_multi_label_accuracy: 0.3191\n",
      "Epoch 181/1000\n",
      " - 1s - loss: 0.1881 - raw_multi_label_accuracy: 0.8202 - val_loss: 1.5419 - val_raw_multi_label_accuracy: 0.3174\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 0.1948 - raw_multi_label_accuracy: 0.8148 - val_loss: 1.5507 - val_raw_multi_label_accuracy: 0.3287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      " - 1s - loss: 0.1908 - raw_multi_label_accuracy: 0.8166 - val_loss: 1.5881 - val_raw_multi_label_accuracy: 0.3208\n",
      "Epoch 184/1000\n",
      " - 1s - loss: 0.1860 - raw_multi_label_accuracy: 0.8269 - val_loss: 1.5786 - val_raw_multi_label_accuracy: 0.3211\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 0.1912 - raw_multi_label_accuracy: 0.8123 - val_loss: 1.6274 - val_raw_multi_label_accuracy: 0.3228\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 0.1853 - raw_multi_label_accuracy: 0.8208 - val_loss: 1.5991 - val_raw_multi_label_accuracy: 0.3195\n",
      "Epoch 187/1000\n",
      " - 1s - loss: 0.1849 - raw_multi_label_accuracy: 0.8239 - val_loss: 1.6297 - val_raw_multi_label_accuracy: 0.3169\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 0.1836 - raw_multi_label_accuracy: 0.8278 - val_loss: 1.6911 - val_raw_multi_label_accuracy: 0.3090\n",
      "Epoch 189/1000\n",
      " - 1s - loss: 0.1829 - raw_multi_label_accuracy: 0.8289 - val_loss: 1.6059 - val_raw_multi_label_accuracy: 0.3178\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 0.1858 - raw_multi_label_accuracy: 0.8197 - val_loss: 1.5792 - val_raw_multi_label_accuracy: 0.3179\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.1935 - raw_multi_label_accuracy: 0.8170 - val_loss: 1.5833 - val_raw_multi_label_accuracy: 0.3223\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 0.1928 - raw_multi_label_accuracy: 0.8233 - val_loss: 1.6279 - val_raw_multi_label_accuracy: 0.3261\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 0.1875 - raw_multi_label_accuracy: 0.8278 - val_loss: 1.6683 - val_raw_multi_label_accuracy: 0.3174\n",
      "Epoch 194/1000\n",
      " - 1s - loss: 0.1872 - raw_multi_label_accuracy: 0.8250 - val_loss: 1.6028 - val_raw_multi_label_accuracy: 0.3177\n",
      "Epoch 195/1000\n",
      " - 1s - loss: 0.1870 - raw_multi_label_accuracy: 0.8245 - val_loss: 1.6238 - val_raw_multi_label_accuracy: 0.3298\n",
      "Epoch 196/1000\n",
      " - 1s - loss: 0.1818 - raw_multi_label_accuracy: 0.8290 - val_loss: 1.6133 - val_raw_multi_label_accuracy: 0.3289\n",
      "Epoch 197/1000\n",
      " - 1s - loss: 0.1865 - raw_multi_label_accuracy: 0.8229 - val_loss: 1.5919 - val_raw_multi_label_accuracy: 0.3166\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 0.1844 - raw_multi_label_accuracy: 0.8270 - val_loss: 1.6197 - val_raw_multi_label_accuracy: 0.3230\n",
      "Epoch 199/1000\n",
      " - 1s - loss: 0.1876 - raw_multi_label_accuracy: 0.8194 - val_loss: 1.5547 - val_raw_multi_label_accuracy: 0.3127\n",
      "Epoch 200/1000\n",
      " - 1s - loss: 0.1813 - raw_multi_label_accuracy: 0.8264 - val_loss: 1.5695 - val_raw_multi_label_accuracy: 0.3107\n",
      "Epoch 201/1000\n",
      " - 1s - loss: 0.1872 - raw_multi_label_accuracy: 0.8267 - val_loss: 1.5741 - val_raw_multi_label_accuracy: 0.3139\n",
      "Epoch 202/1000\n",
      " - 1s - loss: 0.1793 - raw_multi_label_accuracy: 0.8358 - val_loss: 1.6309 - val_raw_multi_label_accuracy: 0.3233\n",
      "Epoch 203/1000\n",
      " - 1s - loss: 0.1828 - raw_multi_label_accuracy: 0.8264 - val_loss: 1.5448 - val_raw_multi_label_accuracy: 0.3086\n",
      "Epoch 204/1000\n",
      " - 1s - loss: 0.1771 - raw_multi_label_accuracy: 0.8352 - val_loss: 1.6428 - val_raw_multi_label_accuracy: 0.3203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bf90910b8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model_cnn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "#e = Embedding(num_words_kept, word_vec_len, input_length=max_seq_len, trainable=True)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(50, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "#model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
    "model_cnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=200)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36687370600414065"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4689440993788821"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46670117322291227"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 66.50103519668737\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.5424430641821946\n",
      "Precision for Action-Adventure: 0.43089430894308944\n",
      "Recall for Action-Adventure: 0.5668449197860963\n",
      "\n",
      "Accuruacy for Romance: 0.7370600414078675\n",
      "Precision for Romance: 0.29411764705882354\n",
      "Recall for Romance: 0.14150943396226415\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.5734989648033126\n",
      "Precision for Horror-Thriller: 0.46534653465346537\n",
      "Recall for Horror-Thriller: 0.4895833333333333\n",
      "\n",
      "Accuruacy for Comedy: 0.5921325051759835\n",
      "Precision for Comedy: 0.536697247706422\n",
      "Recall for Comedy: 0.5492957746478874\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8799171842650103\n",
      "Precision for Science Fiction: 0.4\n",
      "Recall for Science Fiction: 0.07142857142857142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN but with multiple filter sizes so we don't just filter on group of words at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "model_input = Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)(model_input)\n",
    "two_word_filter = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(e)\n",
    "two_word_filter = GlobalMaxPooling1D()(two_word_filter)\n",
    "three_word_filter = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(e)\n",
    "three_word_filter = GlobalMaxPooling1D()(three_word_filter)\n",
    "four_word_filter = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(e)\n",
    "four_word_filter = GlobalMaxPooling1D()(four_word_filter)\n",
    "merged = concatenate([two_word_filter, three_word_filter, four_word_filter], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(len(genre_dict))(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[model_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 2.8865 - raw_multi_label_accuracy: 0.0867 - val_loss: 2.2903 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 3s - loss: 1.9246 - raw_multi_label_accuracy: 0.0448 - val_loss: 1.5395 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 4s - loss: 1.3227 - raw_multi_label_accuracy: 0.0285 - val_loss: 1.0945 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 4s - loss: 0.9769 - raw_multi_label_accuracy: 0.0267 - val_loss: 0.8523 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 6s - loss: 0.7883 - raw_multi_label_accuracy: 0.0196 - val_loss: 0.7164 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 4s - loss: 0.6907 - raw_multi_label_accuracy: 0.0198 - val_loss: 0.6514 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 3s - loss: 0.6352 - raw_multi_label_accuracy: 0.0231 - val_loss: 0.6189 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 3s - loss: 0.6003 - raw_multi_label_accuracy: 0.0332 - val_loss: 0.6026 - val_raw_multi_label_accuracy: 0.0035\n",
      "Epoch 9/1000\n",
      " - 3s - loss: 0.5557 - raw_multi_label_accuracy: 0.2094 - val_loss: 0.5944 - val_raw_multi_label_accuracy: 0.1632\n",
      "Epoch 10/1000\n",
      " - 3s - loss: 0.4808 - raw_multi_label_accuracy: 0.4554 - val_loss: 0.5871 - val_raw_multi_label_accuracy: 0.1961\n",
      "Epoch 11/1000\n",
      " - 3s - loss: 0.4390 - raw_multi_label_accuracy: 0.5177 - val_loss: 0.5722 - val_raw_multi_label_accuracy: 0.1753\n",
      "Epoch 12/1000\n",
      " - 3s - loss: 0.4152 - raw_multi_label_accuracy: 0.5278 - val_loss: 0.5753 - val_raw_multi_label_accuracy: 0.1487\n",
      "Epoch 13/1000\n",
      " - 3s - loss: 0.3943 - raw_multi_label_accuracy: 0.5496 - val_loss: 0.5796 - val_raw_multi_label_accuracy: 0.1719\n",
      "Epoch 14/1000\n",
      " - 3s - loss: 0.3704 - raw_multi_label_accuracy: 0.5841 - val_loss: 0.5802 - val_raw_multi_label_accuracy: 0.2193\n",
      "Epoch 15/1000\n",
      " - 4s - loss: 0.3365 - raw_multi_label_accuracy: 0.6599 - val_loss: 0.5820 - val_raw_multi_label_accuracy: 0.2137\n",
      "Epoch 16/1000\n",
      " - 5s - loss: 0.2966 - raw_multi_label_accuracy: 0.7234 - val_loss: 0.5925 - val_raw_multi_label_accuracy: 0.2310\n",
      "Epoch 17/1000\n",
      " - 3s - loss: 0.2608 - raw_multi_label_accuracy: 0.7726 - val_loss: 0.5989 - val_raw_multi_label_accuracy: 0.2358\n",
      "Epoch 18/1000\n",
      " - 4s - loss: 0.2328 - raw_multi_label_accuracy: 0.7952 - val_loss: 0.6090 - val_raw_multi_label_accuracy: 0.2315\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.2068 - raw_multi_label_accuracy: 0.8373 - val_loss: 0.6116 - val_raw_multi_label_accuracy: 0.2444\n",
      "Epoch 20/1000\n",
      " - 3s - loss: 0.1851 - raw_multi_label_accuracy: 0.8537 - val_loss: 0.6267 - val_raw_multi_label_accuracy: 0.2359\n",
      "Epoch 21/1000\n",
      " - 3s - loss: 0.1705 - raw_multi_label_accuracy: 0.8740 - val_loss: 0.6310 - val_raw_multi_label_accuracy: 0.2601\n",
      "Epoch 22/1000\n",
      " - 3s - loss: 0.1562 - raw_multi_label_accuracy: 0.8848 - val_loss: 0.6250 - val_raw_multi_label_accuracy: 0.2722\n",
      "Epoch 23/1000\n",
      " - 3s - loss: 0.1435 - raw_multi_label_accuracy: 0.9024 - val_loss: 0.6551 - val_raw_multi_label_accuracy: 0.2761\n",
      "Epoch 24/1000\n",
      " - 3s - loss: 0.1336 - raw_multi_label_accuracy: 0.9045 - val_loss: 0.6601 - val_raw_multi_label_accuracy: 0.2493\n",
      "Epoch 25/1000\n",
      " - 3s - loss: 0.1285 - raw_multi_label_accuracy: 0.9100 - val_loss: 0.6684 - val_raw_multi_label_accuracy: 0.2885\n",
      "Epoch 26/1000\n",
      " - 3s - loss: 0.1219 - raw_multi_label_accuracy: 0.9161 - val_loss: 0.6767 - val_raw_multi_label_accuracy: 0.2949\n",
      "Epoch 27/1000\n",
      " - 3s - loss: 0.1140 - raw_multi_label_accuracy: 0.9230 - val_loss: 0.6837 - val_raw_multi_label_accuracy: 0.2688\n",
      "Epoch 28/1000\n",
      " - 3s - loss: 0.1089 - raw_multi_label_accuracy: 0.9234 - val_loss: 0.6964 - val_raw_multi_label_accuracy: 0.2736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bd79fb470>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39233954451345754"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6348039215686274"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4342650103519669"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 73.58178053830228\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.6459627329192547\n",
      "Precision for Action-Adventure: 0.5645161290322581\n",
      "Recall for Action-Adventure: 0.37433155080213903\n",
      "\n",
      "Accuruacy for Romance: 0.7805383022774327\n",
      "Precision for Romance: 0.5\n",
      "Recall for Romance: 0.16037735849056603\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.7163561076604554\n",
      "Precision for Horror-Thriller: 0.7131782945736435\n",
      "Recall for Horror-Thriller: 0.4791666666666667\n",
      "\n",
      "Accuruacy for Comedy: 0.6542443064182195\n",
      "Precision for Comedy: 0.6127450980392157\n",
      "Recall for Comedy: 0.5868544600938967\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8819875776397516\n",
      "Precision for Science Fiction: 0.4\n",
      "Recall for Science Fiction: 0.03571428571428571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "normal_nn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "normal_nn.add(e)\n",
    "normal_nn.add(Flatten())\n",
    "normal_nn.add(Dense(256, activation='relu'))\n",
    "normal_nn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "normal_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "normal_nn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(normal_nn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "lstm_model = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "lstm_model.add(e)\n",
    "lstm_model.add(LSTM(100, dropout=0.25, recurrent_dropout=0.25))\n",
    "lstm_model.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "lstm_model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(lstm_model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
