{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on all genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)\n",
    "genre_set = {'Comedy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "<ul>\n",
    "    <li>Get all possible genres.</li>\n",
    "    <li>Vectorize Genres:</li>\n",
    "    <ul>\n",
    "        <li>Save genres as a vector of 0s and 1s.</li>\n",
    "        <li>Save genres as list of strings.</li>\n",
    "    </ul>\n",
    "    <li>Process Overview Category</li>\n",
    "    <ul>\n",
    "        <li>Remove punctuation</li>\n",
    "        <li>Set to lowercase</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_all_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        for i in range(numElems):\n",
    "            genre_set.add(json_genres[i]['name'])\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #20 0s\n",
    "        for i in range(numElems):\n",
    "            ret[genre_dict[(json_genres[i]['name'])]] = 1\n",
    "        return ret\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "\n",
    "def get_labels_as_strs(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = []#20 0s\n",
    "        for i in range(numElems):\n",
    "            ret.append(json_genres[i]['name'])\n",
    "        return ret\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of genres \n",
    "def getAllGenres():\n",
    "    full_data = pd.read_csv('train.csv')\n",
    "\n",
    "    y = full_data['genres']\n",
    "    y.apply(parse_all_genres_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllGenres()#populate the genre set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get set to dictionary for indexing of target vectors\n",
    "genre_dict = {}\n",
    "index = 0\n",
    "for genre in genre_set:\n",
    "    genre_dict[genre] = index\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize genres\n",
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    label_strs = y.apply(get_labels_as_strs)\n",
    "    all_data['genres_labels'] = label_strs\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_labels', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM \n",
    "<ul>\n",
    "    <li>Get Word Embeddings</li>\n",
    "    <li>Tokenize words</li>\n",
    "    <li>Vectorize Overview</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 1, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metrics\n",
    "<ul>\n",
    "    <li>Get accuracy, precision, recall for each genre.</li>\n",
    "    <li>Get multi-label metrics.</li>\n",
    "    <li>Compute hamming loss.</li>\n",
    "    <li>Implement Delayed Early Stopping.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuracy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network\n",
    "<ul>\n",
    "    <li>Add Embedding layer</li>\n",
    "    <li>Add Convolutional layer</li>\n",
    "    <li>Add MaxPooling layer</li>\n",
    "    <li>Add Bi-directional LSTM layer</li>\n",
    "    <li>Add Dense layers</li>\n",
    "    <li>Compile model</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Bidirectional\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model_lstm = Sequential()\n",
    "#e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=200, trainable=False)\n",
    "#e = Embedding(num_words_kept, word_vec_len, input_length=200, trainable=True)\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=200, trainable=True)\n",
    "model_lstm.add(e)\n",
    "model_lstm.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_lstm.add(MaxPooling1D())\n",
    "model_lstm.add(Bidirectional(LSTM(100)))\n",
    "model_lstm.add(Dense(256, activation='relu'))\n",
    "model_lstm.add(Dense(20, activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "# print(model_lstm.summary())\n",
    "#model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
    "\n",
    "# model_lstm.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 10, delay=250)], epochs=1000, batch_size=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*20\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict\n",
    "Train and predict model for each epoch, with early stopping to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000\n",
      "WARNING:tensorflow:From /usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 25s 12ms/step - loss: 0.4232 - raw_multi_label_accuracy: 0.1180 - val_loss: 0.3213 - val_raw_multi_label_accuracy: 0.0620\n",
      "Epoch: 2/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 24s 11ms/step - loss: 0.3148 - raw_multi_label_accuracy: 0.0930 - val_loss: 0.3144 - val_raw_multi_label_accuracy: 0.1635\n",
      "Epoch: 3/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 25s 12ms/step - loss: 0.3126 - raw_multi_label_accuracy: 0.0753 - val_loss: 0.3154 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch: 4/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 44s 21ms/step - loss: 0.3124 - raw_multi_label_accuracy: 0.0914 - val_loss: 0.3145 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch: 5/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 38s 17ms/step - loss: 0.3126 - raw_multi_label_accuracy: 0.0593 - val_loss: 0.3146 - val_raw_multi_label_accuracy: 0.1646\n",
      "Epoch: 6/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 46s 22ms/step - loss: 0.3117 - raw_multi_label_accuracy: 0.1112 - val_loss: 0.3142 - val_raw_multi_label_accuracy: 0.0158\n",
      "Epoch: 7/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 33s 15ms/step - loss: 0.3118 - raw_multi_label_accuracy: 0.1129 - val_loss: 0.3144 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch: 8/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 25s 12ms/step - loss: 0.3115 - raw_multi_label_accuracy: 0.0963 - val_loss: 0.3144 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch: 9/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 26s 12ms/step - loss: 0.3115 - raw_multi_label_accuracy: 0.0812 - val_loss: 0.3145 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch: 10/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 31s 15ms/step - loss: 0.3116 - raw_multi_label_accuracy: 0.1155 - val_loss: 0.3142 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch: 11/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 35s 16ms/step - loss: 0.3114 - raw_multi_label_accuracy: 0.0821 - val_loss: 0.3140 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch: 12/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 29s 14ms/step - loss: 0.3104 - raw_multi_label_accuracy: 0.0805 - val_loss: 0.3136 - val_raw_multi_label_accuracy: 0.1234\n",
      "Epoch: 13/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 13ms/step - loss: 0.3108 - raw_multi_label_accuracy: 0.1018 - val_loss: 0.3131 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch: 14/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.3107 - raw_multi_label_accuracy: 0.1020 - val_loss: 0.3138 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch: 15/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 29s 13ms/step - loss: 0.3091 - raw_multi_label_accuracy: 0.1101 - val_loss: 0.3134 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch: 16/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 29s 14ms/step - loss: 0.3081 - raw_multi_label_accuracy: 0.0960 - val_loss: 0.3131 - val_raw_multi_label_accuracy: 0.0840\n",
      "Epoch: 17/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 26s 12ms/step - loss: 0.3026 - raw_multi_label_accuracy: 0.1294 - val_loss: 0.3110 - val_raw_multi_label_accuracy: 0.0548\n",
      "Epoch: 18/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 26s 12ms/step - loss: 0.2920 - raw_multi_label_accuracy: 0.1357 - val_loss: 0.3108 - val_raw_multi_label_accuracy: 0.1157\n",
      "Epoch: 19/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 28s 13ms/step - loss: 0.2808 - raw_multi_label_accuracy: 0.1867 - val_loss: 0.3141 - val_raw_multi_label_accuracy: 0.1025\n",
      "Epoch: 20/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 29s 14ms/step - loss: 0.2706 - raw_multi_label_accuracy: 0.2423 - val_loss: 0.3269 - val_raw_multi_label_accuracy: 0.0911\n",
      "Epoch: 21/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 13ms/step - loss: 0.2644 - raw_multi_label_accuracy: 0.2622 - val_loss: 0.3183 - val_raw_multi_label_accuracy: 0.1764\n",
      "Epoch: 22/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 13ms/step - loss: 0.2578 - raw_multi_label_accuracy: 0.2830 - val_loss: 0.3238 - val_raw_multi_label_accuracy: 0.1443\n",
      "Epoch: 23/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 29s 13ms/step - loss: 0.2495 - raw_multi_label_accuracy: 0.3071 - val_loss: 0.3276 - val_raw_multi_label_accuracy: 0.1549\n",
      "Epoch: 24/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 33s 16ms/step - loss: 0.2369 - raw_multi_label_accuracy: 0.3409 - val_loss: 0.3302 - val_raw_multi_label_accuracy: 0.1845\n",
      "Epoch: 25/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 37s 17ms/step - loss: 0.2212 - raw_multi_label_accuracy: 0.3859 - val_loss: 0.3428 - val_raw_multi_label_accuracy: 0.2005\n",
      "Epoch: 26/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 33s 15ms/step - loss: 0.2075 - raw_multi_label_accuracy: 0.4162 - val_loss: 0.3578 - val_raw_multi_label_accuracy: 0.1863\n",
      "Epoch: 27/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 33s 16ms/step - loss: 0.1948 - raw_multi_label_accuracy: 0.4543 - val_loss: 0.3810 - val_raw_multi_label_accuracy: 0.2149\n",
      "Epoch: 28/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 37s 17ms/step - loss: 0.1850 - raw_multi_label_accuracy: 0.4799 - val_loss: 0.3845 - val_raw_multi_label_accuracy: 0.2013\n",
      "Epoch: 29/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 36s 17ms/step - loss: 0.1781 - raw_multi_label_accuracy: 0.5021 - val_loss: 0.4090 - val_raw_multi_label_accuracy: 0.2002\n",
      "Epoch: 30/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.1716 - raw_multi_label_accuracy: 0.5214 - val_loss: 0.4005 - val_raw_multi_label_accuracy: 0.2054\n",
      "Epoch: 31/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 28s 13ms/step - loss: 0.1597 - raw_multi_label_accuracy: 0.5490 - val_loss: 0.4148 - val_raw_multi_label_accuracy: 0.2027\n",
      "Epoch: 32/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.1509 - raw_multi_label_accuracy: 0.5762 - val_loss: 0.4351 - val_raw_multi_label_accuracy: 0.2222\n",
      "Epoch: 33/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 42s 20ms/step - loss: 0.1412 - raw_multi_label_accuracy: 0.6073 - val_loss: 0.4620 - val_raw_multi_label_accuracy: 0.2067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 26s 12ms/step - loss: 0.1342 - raw_multi_label_accuracy: 0.6256 - val_loss: 0.4847 - val_raw_multi_label_accuracy: 0.2039\n",
      "Epoch: 35/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 24s 11ms/step - loss: 0.1282 - raw_multi_label_accuracy: 0.6430 - val_loss: 0.4894 - val_raw_multi_label_accuracy: 0.2108\n",
      "Epoch: 36/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 33s 15ms/step - loss: 0.1203 - raw_multi_label_accuracy: 0.6663 - val_loss: 0.5116 - val_raw_multi_label_accuracy: 0.2118\n",
      "Epoch: 37/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 46s 21ms/step - loss: 0.1119 - raw_multi_label_accuracy: 0.6858 - val_loss: 0.5351 - val_raw_multi_label_accuracy: 0.2065\n",
      "Epoch: 38/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 57s 27ms/step - loss: 0.1069 - raw_multi_label_accuracy: 0.7098 - val_loss: 0.5578 - val_raw_multi_label_accuracy: 0.2242\n",
      "Epoch: 39/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 36s 17ms/step - loss: 0.1014 - raw_multi_label_accuracy: 0.7263 - val_loss: 0.5932 - val_raw_multi_label_accuracy: 0.2145\n",
      "Epoch: 40/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.0955 - raw_multi_label_accuracy: 0.7315 - val_loss: 0.6096 - val_raw_multi_label_accuracy: 0.2109\n",
      "Avoid Overfitting, Initiating Early Stopping\n",
      "Epoch: 41/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 12ms/step - loss: 0.0892 - raw_multi_label_accuracy: 0.7611 - val_loss: 0.6274 - val_raw_multi_label_accuracy: 0.2002\n",
      "Epoch: 42/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 13ms/step - loss: 0.0820 - raw_multi_label_accuracy: 0.7841 - val_loss: 0.6425 - val_raw_multi_label_accuracy: 0.2110\n",
      "Epoch: 43/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 13ms/step - loss: 0.0768 - raw_multi_label_accuracy: 0.7968 - val_loss: 0.6704 - val_raw_multi_label_accuracy: 0.2126\n",
      "Epoch: 44/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 22s 10ms/step - loss: 0.0725 - raw_multi_label_accuracy: 0.8116 - val_loss: 0.7092 - val_raw_multi_label_accuracy: 0.2110\n",
      "Epoch: 45/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 22s 10ms/step - loss: 0.0688 - raw_multi_label_accuracy: 0.8218 - val_loss: 0.6953 - val_raw_multi_label_accuracy: 0.2116\n",
      "Epoch: 46/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 16s 8ms/step - loss: 0.0680 - raw_multi_label_accuracy: 0.8211 - val_loss: 0.7419 - val_raw_multi_label_accuracy: 0.2060\n",
      "Epoch: 47/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 17s 8ms/step - loss: 0.0623 - raw_multi_label_accuracy: 0.8409 - val_loss: 0.7041 - val_raw_multi_label_accuracy: 0.2090\n",
      "Epoch: 48/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 20s 9ms/step - loss: 0.0571 - raw_multi_label_accuracy: 0.8514 - val_loss: 0.7576 - val_raw_multi_label_accuracy: 0.2125\n",
      "Epoch: 49/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 23s 11ms/step - loss: 0.0531 - raw_multi_label_accuracy: 0.8660 - val_loss: 0.7822 - val_raw_multi_label_accuracy: 0.2139\n",
      "Epoch: 50/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 18s 8ms/step - loss: 0.0496 - raw_multi_label_accuracy: 0.8764 - val_loss: 0.8169 - val_raw_multi_label_accuracy: 0.2106\n",
      "Epoch: 51/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 17s 8ms/step - loss: 0.0473 - raw_multi_label_accuracy: 0.8808 - val_loss: 0.8323 - val_raw_multi_label_accuracy: 0.2142\n",
      "Epoch: 52/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 20s 9ms/step - loss: 0.0459 - raw_multi_label_accuracy: 0.8863 - val_loss: 0.8217 - val_raw_multi_label_accuracy: 0.2142\n",
      "Epoch: 53/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 47s 22ms/step - loss: 0.0439 - raw_multi_label_accuracy: 0.8849 - val_loss: 0.8729 - val_raw_multi_label_accuracy: 0.2192\n",
      "Epoch: 54/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 45s 21ms/step - loss: 0.0402 - raw_multi_label_accuracy: 0.8995 - val_loss: 0.8873 - val_raw_multi_label_accuracy: 0.2130\n",
      "Epoch: 55/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.0375 - raw_multi_label_accuracy: 0.9107 - val_loss: 0.9377 - val_raw_multi_label_accuracy: 0.2144\n",
      "Epoch: 56/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 23s 11ms/step - loss: 0.0348 - raw_multi_label_accuracy: 0.9184 - val_loss: 0.9221 - val_raw_multi_label_accuracy: 0.2094\n",
      "Epoch: 57/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 30s 14ms/step - loss: 0.0324 - raw_multi_label_accuracy: 0.9223 - val_loss: 0.9445 - val_raw_multi_label_accuracy: 0.2079\n",
      "Epoch: 58/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 27s 12ms/step - loss: 0.0316 - raw_multi_label_accuracy: 0.9241 - val_loss: 0.9584 - val_raw_multi_label_accuracy: 0.2066\n",
      "Epoch: 59/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 18s 9ms/step - loss: 0.0326 - raw_multi_label_accuracy: 0.9182 - val_loss: 0.9827 - val_raw_multi_label_accuracy: 0.2078\n",
      "Epoch: 60/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 16s 7ms/step - loss: 0.0337 - raw_multi_label_accuracy: 0.9108 - val_loss: 0.9750 - val_raw_multi_label_accuracy: 0.2073\n",
      "Epoch: 61/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 22s 10ms/step - loss: 0.0316 - raw_multi_label_accuracy: 0.9194 - val_loss: 1.0118 - val_raw_multi_label_accuracy: 0.2148\n",
      "Epoch: 62/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 17s 8ms/step - loss: 0.0288 - raw_multi_label_accuracy: 0.9285 - val_loss: 1.0080 - val_raw_multi_label_accuracy: 0.2218\n",
      "Epoch: 63/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 20s 9ms/step - loss: 0.0253 - raw_multi_label_accuracy: 0.9374 - val_loss: 1.0529 - val_raw_multi_label_accuracy: 0.2090\n",
      "Epoch: 64/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 24s 11ms/step - loss: 0.0227 - raw_multi_label_accuracy: 0.9499 - val_loss: 1.0728 - val_raw_multi_label_accuracy: 0.2096\n",
      "Epoch: 65/1000\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 19s 9ms/step - loss: 0.0213 - raw_multi_label_accuracy: 0.9535 - val_loss: 1.0787 - val_raw_multi_label_accuracy: 0.2143\n",
      "Stopping Early to Avoid Overfitting.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "history = []\n",
    "test_err = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_recall = []\n",
    "stopping = 1\n",
    "pat = 10\n",
    "patience = 10\n",
    "delay = 25\n",
    "\n",
    "for num in range(n_epochs):\n",
    "    print(\"Epoch: {}/{}\".format(num+1, n_epochs))\n",
    "    this_hist = model_lstm.fit(x_train_seq, y_train, batch_size=100, epochs=1, validation_split=0.1)\n",
    "    history.append(this_hist)\n",
    "    \n",
    "    vl = this_hist.history['val_loss']\n",
    "    \n",
    "    if patience > -1:\n",
    "        if stopping >= vl[0]:\n",
    "            if patience < pat:\n",
    "                patience = pat\n",
    "            stopping = vl\n",
    "        else:\n",
    "            patience -= 1\n",
    "            stopping = vl\n",
    "    else:\n",
    "        delay -= 1\n",
    "        \n",
    "    this_preds = nn_output_to_predictions(model_lstm.predict(x_test_seq))\n",
    "    acc = multi_label_accuracy(y_test, this_preds)\n",
    "    test_acc.append(acc)\n",
    "    test_err.append(1-acc)\n",
    "    \n",
    "    if patience == 0:\n",
    "        print(\"Avoid Overfitting, Initiating Early Stopping\")\n",
    "        patience = -1\n",
    "        \n",
    "    if delay == 0:\n",
    "        print(\"Stopping Early to Avoid Overfitting.\")\n",
    "        break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy and Loss\n",
    "Use accuracy and loss metrics collected from each epoch and plot to compare training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through history to store accuracies and errors in individual lists\n",
    "all_multi_acc = []\n",
    "all_loss = []\n",
    "all_val_multi_acc = []\n",
    "all_val_loss = []\n",
    "\n",
    "for x in history:\n",
    "    all_multi_acc.append(x.history['raw_multi_label_accuracy'])\n",
    "    all_loss.append(x.history['loss'])\n",
    "    all_val_multi_acc.append(x.history['val_raw_multi_label_accuracy'])\n",
    "    all_val_loss.append(x.history['val_loss'])\n",
    "    \n",
    "# flatten all variables to one dimension list\n",
    "flat_acc = [val for sublist in all_multi_acc for val in sublist]\n",
    "flat_loss = [val for sublist in all_loss for val in sublist]\n",
    "flat_val_acc = [val for sublist in all_val_multi_acc for val in sublist]\n",
    "flat_val_loss = [val for sublist in all_val_loss for val in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot accuracy\n",
    "plt.plot(all_multi_acc)\n",
    "plt.plot(all_val_multi_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.title(\"Bi-Directional LSTM Accuracy - All Genres\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd81PX9wPHX+y57byCQEGRPQQPiBlEBt1XRKq5aqVtrtdW2v6q1rVZta1utVuuoAxcurLhQFFkKKHuPAEmI2Xvd+Pz++N6FEDIuIcdlvJ+Pxz2S+973vve+y+X7/n62GGNQSimlAGyBDkAppVTXoUlBKaVUA00KSimlGmhSUEop1UCTglJKqQaaFJRSSjXQpNBNicjTIvJ/gT5GV3stEckSkdP9/Tq9nYgYERni+f1FEflDoGNSnUOTQhflObnViEiliJSIyIcikuZ93BhzgzHmQR+eXyEipSKyTERuEBGbr8c4jNivEZEljbf567Xao7WTl4icLyJrRKRcRApF5AsRGeRJZpWeW72IOBrd/0hEMjwnyO+bHC/Js39WK/E0nFi7Is/7d4vIU4d5nH4i8qyI5Ho+t12ev8WIzopVdR5NCl3bucaYKKAf8APwzw48PxoYCDwM/Ap4zpcnikhQO1+r2/KcmF8CfgHEAoOAJwGXJ5lFef4OfwLe8N43xsxsdJgIERnT6P7lwO4j9Bb85SqgBLhUREI7cgARSQSWARHAyUA0cAzwFXBGJ8XZ+PV6zffWXzQpdAPGmFpgHjDKu609RXZjTJkxZj5wKXC19+TV+BgiMkVEskXkVyKSB7zg2X6O5wraW9oY1yiGNBF5R0QKRKRIRJ4QkZHA08DxnqvC0ubiFZHrRWSHiBSLyHwRSW30mPGUarZ7XvdJERHPY4M9V/FFniv6V0UkroMfrdd4YLcx5nNjqTDGvG2M2duOY7wMXN3o/lVYiabdRMQmIr8VkT0iki8iL4lIrOexMBF5xfP+S0VkpYj08Tx2jecqvEJEdovIFR15fc+xxPMefgs4gHM7eKifA+XAlcaYnZ7Pt9QY84IxpuEiR0Qme75fpSKyVkSmNHrsSxF5UESWet7bpyKS5HnMW1K7TkT2Al/4cLxO+5x6Ik0K3YCIRGCd0FccznGMMd8C2VhXbM3pCyRglSzmiMgE4HngZ0Ai8G9gvoiEiogd+B+wB8gA+gOvG2M2AzcAyz1X04ecsEXkNOAhYBZWKWgP8HqT3c4BJgLjPPtN9z7d89xUYCSQBtzfns+hGd8BI0TkbyIyVUSiOnCMV4DLRMQuIqOAKOCbDsZzjec2FTjKc6wnPI9djVWaScP6m9wA1IhIJPAPYKandHgCsKaDrw9wEjAA6+/yJgcnvPY4HXjXGONuaQcR6Q98CPwB6/t3F/C2iCQ32u1y4FogBQjx7NPYqVjfh+mtHc8Pn1OPo0mha3vPc6VdhlXUfrQTjpmL9Y/SHDdwnzGmzhhTA8wB/m2M+cYY4zLG/BeoAyYDk7BOzHcbY6qMMbXGmCUtHLepK4DnjTHfGWPqgHuxShYZjfZ52HNFuRdYhHU1jzFmhzHmM0+MBcBfsU4IHWaM2QVMwUpsbwKFnpJNe5JDNrAV6yR4FVbJoaOuAP5qjNlljKnE+nwu81SNOLCSwRDP32S1Mabc8zw3MEZEwo0x+40xGw8jhquBj4wxJcBcYIaIpHTgOElAnveOiJznuXqvEJFPPZtnAwuMMQuMMW5jzGfAKuCsRsd5wRizzfO9fBPP96GR+z3fwxofjteZn1OPo0mha7vAc6UdBtwCfCUifZvuJFaDp7fxs62icH+guIXHCjxVVV4DgV94/olLPQkqDSsZpAF7jDHO9r4pz/P3eO94TnxFnti88hr9Xo11tYyI9BGR10UkR0TKsa7QkzoQw0GMMSuMMbOMMclYJalTgN+08zAvYV3h/5jDSwoHfT6e34OAPp7jfgK8LlbD7SMiEmyMqcIqTd4A7BerY0KzDbmNviuVIpLezOPhwCXAqwDGmOXAXqyr9fYqwioN4jnWfM93+udYV/xgfc8uafI9O6nx82jh+9DIvka/t3i89nxOvZUmhW7Ac0X4DuDC+nI3fXxmo8bPV1s6johMxDrxtnRF33TK3H3AH40xcY1uEcaY1zyPpUvzDXttTb2bi/WP640rEuvqN6eN54HV2GuAscaYGKyrQvHheT4zxqwE3gHGtLVvE28DZwO72tke0dRBnw+QDjiBH4wxDmPMA8aYUVhVH+dglUwwxnxijDkD62S6BXi2uYM3+q5EtRDnhUAM8C8RyROrjak/HatC+hy4QBr1emvGPuDlJt+zSGPMw+14ncbfuVaP5+vn1FtpUugGxHI+EA9s7sDzY0TkHKz64VeMMet9fOqzwA0icpwnhkgROVtEooFvgf3Aw57tYSJyoud5PwADRCSkheO+BlwrIuPF6tXyJ+AbY0yWDzFFA5VAmafu+G4f34uX3ROr9xYiIieJ1fCdAuC5cjyPdrbheK5CTwN+2o6nhTSJx471+fxcrC6hjXs9OT1tHmM9+5VjVSe5PSWo8z0Jtg7rM2qxHr8NV2O1JY3FqqYZD5wIHC0iY9t5rL9ifW9fFquTgHi+P42rf14BzhWR6Z42mTCxOj4M6GD8LR6vkz+nHkmTQtf2gYhUYv3z/xG4up31nx+ISAXWldNvsP5Br/X1ycaYVcD1WI2cJcAOrOoRjDEurB4pQ7CqFrKxiuVg9QDZCOSJSGEzx10I/B/WlfV+YDBwmY9hPYDVpbEMqzHxHV/fj8c9QE2j2xdAKVYSWO/5vD8G3gUeaeexMcasMsbsbMdTNjaJ51qsE/LLwGKsbq21wK2e/fti9UQrx7pA+Mqzrw24E6uUUYzVznJje+P3JNppwOPGmLxGt9VYn0u7SgvGmEKsNqharBJqBVbDbrQ3PmPMPuB84NdAAdb39W46eH5q43id8jn1ZGJ0kR2llFIeWlJQSinVQJOCUkqpBpoUlFJKNdCkoJRSqkG3mzwqKSnJZGRkBDoMpZTqVlavXl3oGZzZqm6XFDIyMli1alWgw1BKqW5FRPa0vZdWHymllGpEk4JSSqkGmhSUUko16HZtCs1xOBxkZ2dTW1vb9s7dXFhYGAMGDCA4ODjQoSileqAekRSys7OJjo4mIyMDkU6dMLNLMcZQVFREdnY2gwYNCnQ4SqkeqEdUH9XW1pKYmNijEwKAiJCYmNgrSkRKqcDoEUkB6PEJwau3vE+lVGD0iOojpZTqseqrIHsV7F0Bw2dCv3F+fTlNCp2gtLSUuXPnctNNN7XreWeddRZz584lLu6Qte2VUr3ZnmWw+QPYuxz2rwPjAgQiEzUpdAelpaX861//OiQpOJ1OgoJa/ogXLFjg79CUUt2J2wVf/dm6BYVB/0w46eeQfjwMyIRw/19AalLoBPfccw87d+5k/PjxBAcHExYWRnx8PFu2bGHbtm1ccMEF7Nu3j9raWm6//XbmzJkDHJiyo7KykpkzZ3LSSSexbNky+vfvz/vvv094eHiA35lS6oipLoZ3rocdC2H8FXDWYxASccTD6HFJ4YEPNrIpt7xTjzkqNYb7zh3d4uMPP/wwGzZsYM2aNXz55ZecffbZbNiwoaHb6PPPP09CQgI1NTVMnDiRiy66iMTExIOOsX37dl577TWeffZZZs2axdtvv83s2bM79X0opbqo3DXw5pVQkQfnPA7HXgMB6lTS45JCVzBp0qSDxhH84x//4N133wVg3759bN++/ZCkMGjQIMaPt9YyP/bYY8nKyjpi8SqlAmjLhzDvJxCRCNd+DAOODWg4PS4ptHZFf6RERkY2/P7ll1+ycOFCli9fTkREBFOmTGl2nEFoaGjD73a7nZqamiMSq1IqgGrL4YPbIXk4zH4HIpMCHVHPSwqBEB0dTUVFRbOPlZWVER8fT0REBFu2bGHFihVHODqlVJf19V+gqgAuf6NLJATQpNApEhMTOfHEExkzZgzh4eH06dOn4bEZM2bw9NNPM3LkSIYPH87kyZMDGKlSqssoyYIV/4Jxl0H/wFYZNSbGmEDH0C6ZmZmm6SI7mzdvZuTIkQGK6Mjrbe9XqR7pzath2ydw62qI7e/3lxOR1caYzLb26zHTXCilVLexZzlseg9OuuOIJIT20KSglFJHktsNn9wL0alwwq2BjuYQ2qaglFJH0vo3Ifd7uPDfEBLZ9v5HmN+Sgog8D5wD5BtjxjTzuAB/B84CqoFrjDHf+SsepZQ6ogp3wAszICgcEgdD4hDrtvTvkDoBxs4KdITN8mdJ4UXgCeClFh6fCQz13I4DnvL8VEqp7s3lhHfngMsBR02Foh2w7g2oKwcELn4ebF2z9t5vScEYs1hEMlrZ5XzgJWN1f1ohInEi0s8Ys99fMXWEy+0ityqXvhF9Cba3bwnMivoKqp3VuNwu3MaNy7gwxpAalUqIPcRPER/gdDvZX7WfqOAo4sPi/f56SimPr/8COautk/+Yi6xtxkBVIdRXQMJRgY2vFYFsU+gP7Gt0P9uz7ZCkICJzgDkA6enpRyQ4r1pXLeV15UQHRxNn932GwvK6cvZVWG/PbrNjFzs2sVHrrCUhNoHKykpyc3O57bbbmDdv3iHPnzJlCo899hiZmW32IGtQVFPE8xueJ6s8i73le8muzMbpdjI0fijvnPeOz8dRSh2GnO+sWU7HXHwgIYA1l1FUMpAcsNB80S0amo0xzwDPgDVO4Ui+tsPtOOinL+pcdeRU5hAWFMag2EHYxComuo2bzUWbMVhvITU1tdmE0FELdi/gpU0vMSx+GEPjhzItfRqbijbxXf53GGN01Tal/M1RA+/+DKL6wNmPBTqaDglkUsgB0hrdH+DZ1qU43c6DfjbnnnvuIS0tjZtvvhm3cXP3b+5GbMK6FesoKy3D4XDwhz/8gfPPPx+7zd7wvKysLM455xw2bNhATU0N1157LWvXrmXEiBEdmvsoqyyL2NBY3j7v7YZtL218ieX7l1NeX05saGy7j6mUasa+lbDvGxh8GqSMPDCj6cL7oXAbXPkuhHfPKttAJoX5wC0i8jpWA3NZp7QnfHQP5K0/7MN4xbjrkYQMqk//XYv7XHrppdxxxx3cdNNN5Fbm8uG7H/Lhgg9JvSeVmJgYCgsLmTx5Mueddx5BtuY/8qeeeoqIiAg2b97MunXrOOaYY9oda1Z5FhkxGQdtS4lIAaCgukCTglKdYfP/YN614Kq37selw7CZVjvBN0/DpDlWsuim/Nkl9TVgCpAkItnAfUAwgDHmaWABVnfUHVhdUq/1VyyHwzsNSGvVRxMmTCA/P5+Nuzaydd9WEhMSGZw+mJ///OcsXrwYm81GTk4OP/zwA8ERzTdWL168mNtuuw2AcePGMW5c+5fcyyrLYnLqwXMrJUdY9Zf5NfkMiR/S7mMqpRpZPw/emWN1KT3/SWu5zG0fw3f/BWctJA6F0x8IdJSHxZ+9j37cxuMGuLnTX3jmw516uNyy3VQ7qgl2tVx9BHDBjy5g7ptzKSss44rLruDVV1+loKCA1atXExwcTEZGBrW1tQRHta8Hk6+qHdXk1+QzKHbQQdtTwg+UFJRSh+G7l2D+bTDwRLj8dQiNhpQRkHkt1FfDnqXWFNgBWC2tM3XNjrJdSEObgnHS2uSB086bxkfvfsRnH3zGrFmzKCsrIyUlheDgYBYtWsSePXsACJIgjDGHHOuUU05h7ty5AGzYsIF169a1K86s8iwABsYMPGh7UoQ1HW9BjSYFpTpsxdMw/1YYMg2ueMtKCI2FRMDQM6yqpG6uW/Q+CiSn24mIYIzBZVwESfMfWcbwDGqqaujfvz/9+vXjiiuu4Nxzz2Xs2LFkZmYyYsQIgIY2BZdxHfT8G2+8kWuvvZaRI0cycuRIjj22fVPp7im3kk7TNoXwoHCiQ6LJr85v1/GUUljTW3/xB1j/Fow4xxp3EBTa5tO6M00KrfAOOgsPCqfGWYPT7WyxodjhcrDom0X0i+oHQFJSEsuXLz9kv/K6clbuWYnD7SAjI4MNGzYAEB4ezuuvv97hWLPKshCEtOi0Qx5LDk/W6iOl2qO62BqA9u0zIDY4+S6Yci/Ye/4ps+e/w8PgrToKCwqjxlmDw+0gjLBD9vMmD19GPHuTSmtdXDsiqzyL1KhUwoIOjS85Ipn8Gi0pKNUmtwuWPwmLH7NGHo+/HKb8ustNb+1PmhRa4TTWiTs8KJwSSlo8kXt7JgXbApsUmrYneKWEp7Dqh1XNPqZUr+FyWCf94EMvnABr4Nk718PmD2DIGXDGA9An8Gu+H2na0NwK78nee/XdmUmhPSOk22KMYU/5nkPaE7ySI5IpqClotaFcqR7vnevhL8Ng5X+s5NBYVRH89zxrDMKMh2H2vF6ZEECTQqu8SSDEFoLdZm/xRN6epGATG3abvVNLCoU1hVQ5qlouKUSk4HQ7Ka0r7bTXVKpbyV0DG9+F4Ej48Bfwn9OtNQ0AinfBc2dA3jqY9V+YfGNgYw0wrT5qhbfnkU1sBNmCWi4puBwI0mIjdFOtHasjvN1RM2Izmn08OdwzgK06X2dLVb3Tlw9DWCzcvAK2fQqf/BqePc1qM9j6MRgXXDUf0nX2fi0ptMLpdhJsC0ZECLYFt1p9FGQP8nnCudaO1RENSaGF6qOGqS50rILqjXJWw7aPrKUvw2Jh3CVw6yqYeD2smWutfnbdZ5oQPDQptMLhdjRc/QfZglqsPioqLuL1533vTtr4WI8//jjV1dWHFeeesj2E2kPpG9m32ce9U11ot1TVK335sDU53aSfHdgWFgtnPQK3rIKfLYakoYGLr4vpNUnBGIPD1b7G3cbjEoLEqvJprrG2qKSIV5971efjBkkQLre14E5nJIWs8izSY9IbpuhuqnH1ka/yqvJ4Zt0znd5LSqkjKnsVbP/UU0qIOfTxxMEQ7vs6Kb1Br2lTKKgpoKC6gJGJI1s8eTbVOCl4G5GdxkmwHGhQNsbw6AOPsnf3XsaPH88ZZ5xBSkoKb775JnV1dVx44YU88MADVFVVMWvWLLKzs6l31nPdHdfxSfUn5ObmMnXqVJKSkli0aFGH3tue8j0MjW/5SifEHkJcaJzP1UdOt5O7vrqLtQVrGZEwglMGnNKhuJQKuC8fgohEa+ZS5ZMelxT+/O2f2VK85ZDtTreTOlcd4UHhPiUFg6HaUU2IPYSxSWO58egbG47TuJeR0+3k5//3c7K2ZbFmzRo+/fRT5s2bx7fffosxhvPOO4/FixdTUFBAamoqH374IeV15WzK2cTR6Ufz97/9nUWLFpGUlNSh9+twO8iuyOaMgWe0ul9SeJLPJYWn1j7F2oK1BNuCWbB7gSYF1T3t+xZ2LLRmLW06V5FqUY9LCi1pvPqZT0nBU00kWI3HLQ0687YNePf79NNP+fTTT5kwYQIAlZWVbN++nZNPPplf/OIX/OpXv+L0GaeTOja1U6pmcipycBpniz2PvFIiUnxqU1iZt5Jn1z3LBUMuwC52Ptr9ETXOGsKDwg87VqWOqEV/gogkmHR9oCPpVnpcUvjVpF81u91t3Gwp3kJCWEKLDbKNVTmqyCqzRglHhUQ1tEc0bWxuSAqenkfGGO69915+9rOf0dR3333HggULePC+Bxl3wjgevP/Bdr235rQ0O2pTyeHJ7Cjd0eo+ZXVl3Pv1vQyMGci9k+5lXeE63t7+Nl9nf82ZGWf6HNPust2kRaf53EVXqU7ldsP3L8GuRXDmH6zeRcpnvaah2SY2Quwh1LnqfNq/6YA07zKaTa/u6131REZFUllRCcD06dN5/vnnqay07ufk5JCfn09ubi4RERHMnj2bu+6+i83rNuNwO4iOjqaioqLD76ul2VGbSolIoaimCFfTkZwexhjuW3YfRbVF/PmUPxMRHMHEPhNJDEvko90f+RzPluItnP/e+by7412fn6NUp9n7DTx3OnxwOwyYCJnXBTqibqdXXcqF2cOodvjW08d78vde7bY0gM3hdpCYmMiJJ57ImDFjmDlzJpdffjnHH388AFFRUbzyyivs2LGDu+++G5vNRnBwML96+Fc43U7mzJnDjBkzSE1N7VBD8+6y3cSHxre51GZyRDIu46KkroSk8EPbL97a9haf7/2cuzLvYlTiKMBKhNMzpjNv2zwq6yuJColqM54XN76IwbAmfw2XDLuk3e9HqQ4p3Wutj7zhbYjuBxc8DeMuBVuvue7tNL0qKYTaQymrK8PldjVc+bek8Whmr+bGKjjdToLtwQ0L5HjdfvvtB90fPHgw06dPb7i/o3QHTreTW2+9lVtvvbWjb8ma86iN9gQ4eAW2pkmhtLaUR1Y+wgmpJ3DlqCsPemzmoJnM3TKXRfsWce7gc1t9jbyqPD7e/TEAGws3tuNdKHUYCnfAv0+xRiWf+is48XatMjoMvSqNhtqtxTF8qUJqPJrZq7mSQr273qc5j5rqrFHNWeVZbVYdQaMBbM10S11XuI46Vx3Xj73+kEb4o5OPJjUylQW7F7T5Gi9vehmAC4dcyK6yXVQ5qnx4B0odpsWPgHHDTStg6q81IRymXpUUvLOd+pIUGo9m9mruRO5wOTqUFIKk5RHSvqqsr6SwprDNRmY4MNVFc91SNxVtQhBGJo485DERYfqg6azIXUFJbUmLxy+vL2fetnlMz5jO6QNPx2DYVLSpHe9GqQ4o3GGtijbxOkgY1Pb+qk09Jin4Mi10sC0Ym9ioddW2uW9zq6x5Swpu4wbat7hOU0G2A6Oa26Px/g2NzD5UHyWGJwLNT3WxsWgjGbEZRAY3f4U1M2MmTuNk4d6FLR7/7W1vU+2s5urRVzMmaYx1XK1CUv729WNgD7WqjFSn6BFJISwsjKKiojZPsCJCqD2UOqdv1UfNJQWgoQdPe6bMbirIFoTBHLJWc2uMMRQVFREWZpV4dpfvBtrueeSNMSEsodkV2DYVbWpoXG7OiIQRZMRktNgLyeFy8MrmVziu73GMShxFQlgCqZGpbCzSpKD8qGgnrHsTMn8CUSmBjqbH6BENzQMGDCA7O5uCgrYHZ5XWlVLrrKUmsqbFfdzGTV5VHpUhlZSGHFiDoNZZS3FtMc48JyH2kAP3w6377eF9rusHV7uSSlhYGAMGDACskoJNbM2uy9yc5gawFdYUkl+dz6iElpOCiDBz0EyeXvs0+dX5DVVRXh9lfUR+dT4PnPBAw7bRSaPZULjB17elVPt9/RewB2spoZP1iKQQHBzMoEG+1Sf+d+N/eWztYyy+dHGLawtklWVxx3t38KeT/nRQj5tNRZu443938PjUx5mWPo03t77Jg989yMKLF9Insk+7Yl5bsJY7FtzBv6b9i5MHnNyu5zaOMzUy1eeE1NxUF956/9ZKCgAzBs3gqbVP8WnWp8weNbthuzGGFze+yJC4IZyYemLD9tGJo/lsz2eU1pYSF6YTjqlOVrwL1r4Ox/0Motv3v6da1yOqj9pjaJw1cVxro3u9PXS8PXa8GtYl8Fxt76/aT5AENdvvvy3emUsPZ40DX7ujeqVEpBzyeq01Mjd2VOxRjEgYwQsbX+Cvq/7KJ1mfkFuZy9LcpWwv2c41o685qKeWt11BG5vVYcn93loEp+kMx4u1lOAvPaKk0B6D4wYDVlKY2Hdis/t4r6a9ffu94kPjsYu94fHcylz6RPZpc8xDc7yJpD3TWTdmjCGrPItj+xzr83OSw5Mpqik6qL1kY9FGBsYMbLGRubG7Mu/i79/9nVc2v9LQnmIXOynhKZw16KyD9vUmmQ1FGzih/wk+x6gUYK2ZvPB38P0r1v3oflbbwTFXg6Ma1r5mzWkU3faUNap9el1SSIlIITokmh0lLZcUCmsKgUNLCnabncTwxIar7byqPPpF9utQHCH2EOJD4xteq73yqvKocdb41B3VKyUiBYOhqKaoobprU9GmFpNjU8f1O465Z8+l3lXP9pLtrC9cz+bizZw64NRDemDFhMSQEZOh7Qqqfdxu+O6/8PkDUFdhlQQGTIJVz8OiP8JXj0DsALAFwYl3BDraHqnXJQURYWjc0Farj/Kr8wmzhxEVfOi0DinhKQdVH2X2yexwLEkRvk9n3dTXOV8DcEyfY3x+TuMqqz6RfXxqZG5OiD2E0UmjGZ00utX9RieNZmXeynYdW/ViJVkw7zrIWQUDT4KzH4MUT7XmyHOsMQmrnoPvX4XJN0JMxy7IVOv82qYgIjNEZKuI7BCRe5p5PF1EFonI9yKyTkTOau44nW1I3BC2l25vsQtrQU0ByRHJza65nByRTH5NPk63k/zqfJ9mXG1JSnhKh0sKC/csZGDMwIY2Ep9er8kANl8bmTtqTOIY8qvzdRlQ1TZnHbwxG4q2w4XPwDX/O5AQvJKGwIyH4N69cPr9gYiyV/BbUhARO/AkMBMYBfxYRJqefX4LvGmMmQBcBvzLX/E0NiR+CBX1FS1epRdUFzRcVTfl7dZZWFOIy7joF9Xxq5X2LHzTWFldGSvzVnJ6+unNJq6WeKvDvInI10bmjvKWJLQKSbXps99B3nq48N9w9KXQ1ve6Hd971T7+LClMAnYYY3YZY+qB14Hzm+xjAO/CqbFArh/jaTAkbgjQcg8kb0mhOcnhyZTWlTaMJu5omwIcmM7aO0LaV4v2LcJpnG2uttZUQlgCNrEdVFLwtZG5I0YkjMAudh3Eplq3ZQF88zQcdyMMnxnoaHo9f7Yp9Af2NbqfDRzXZJ/7gU9F5FYgEji9uQOJyBxgDkB6evphB9Y4KZzY/8RDHi+oLuDk/s2PHfBWwawvXA8cXlJIjkjGaZyU1JY0TEPhi4V7FtIvsl+7q32CbEEkhh1oKN9YtPGw2kTaEh4UzuC4wWwoOrSk8N0P37Fg9wL6RPQhNSqV/lH96R/Vn6TwpHaVflQ3V5YN798EfcfBGQ+0vb/yu0A3NP8YeNEY8xcROR54WUTGGHPwpbMx5hngGYDMzMz2TRbUjPiweJLCk5otKVQ5qqh2VrdcUvBsX5u/FjjMpNCo4dfXpFDlqGJZ7jIuHX5ph06eyRHJ5FfnH2hk9lN7gtfoxNEs2rcIY0xDvDmVOdzy+S3Uueqod9cftP8ZA8/gsVMf82nJVNXNuZzw9vXWGIRLXoSCWqkNAAAgAElEQVSg0EBHpPBv9VEO0Hj+hQGebY1dB7wJYIxZDoQBHVvBvp0Gxw1utluqt1G0pTYF7/Z1heuIDY0lIjiiwzE0TGfdjobYxdmLcbgd7a46anjN8GQKqgsaGplHJ7beg+hwjUkaQ2ldKTmV1p/e4Xbwy8W/xGB474L3+PaKb3n//Pd5ctqTXDnqSj7b8xn/Wf8fv8akuojFj8DeZXD2XyFxcKCjUR7+TAorgaEiMkhEQrAakuc32WcvMA1AREZiJYUj0lVlaNxQdpbtPKQ+v6XRzF7e6qPi2uLDKiVAx0Y1f7bnM5LCkxifMr5jrxmRTEFNgd8bmb28jc3edoUnvn+CdQXruP+E+0mLTiM8KJyj4o7ilAGncHfm3Zw16Cye+P4JluUs82tcKsDWvWWNOTj6cqthWXUZfksKxhgncAvwCbAZq5fRRhH5vYic59ntF8D1IrIWeA24xrR3LukOGhI3hBpnTcMVrFdLo5m94kLjGkYDH053VDgwqtnXkkKNs4YlOUuYlj6tw9UrKeEpFNcWs7ZgrV8bmb2GxQ0j2BbMxsKNLM1ZyvMbnufiYRczPWP6IfuKCPcdfx+D4wbzy69/ecjfRvUQ370M71wPGZ6xCKpL8WvFrTFmgTFmmDFmsDHmj55tvzPGzPf8vskYc6Ix5mhjzHhjzKf+jKexIfGexuYmVUgtjWb2EpGGhHG4JQXvqGZfSwrLcpdR46xhWvq0Dr+m932tzFvp9/YEgGB7MMPjh7Msdxm/XvJrhsQN4ZcTf9ni/hHBETw+9XFcbhd3fnmnTwsiqW5k5X9g/i0weCpc/qauktYF9drWvMGxB+ZAaqy10cxe3hPr4SYFaN+o5oV7FhIbGktm3473GPJWf9W56o5IUgCrCmlryVaqHdU8esqjhAeFt7r/wJiB/PGkP7KpaBMPffPQEYlRHQHLn4QPfwHDZsJlr0FIx9vjlP/02qQQFRJFamQq20q2HbS9tdHMXt4Ta2ckBV9HNTtcDr7a9xVT06Z2aFEfr8YN6EcqKRydfDQA90y6p6GE1pbT0k/jp2N/ytvb3+bVza/6Mzx1JCz9O3zyaxh5Hsx6CYLDAh2RakGgu6QG1PiU8SzYvYDi2mJmj5zNqWmntjqa2cv7+OG2KQAtdo1tasX+FVQ4Kjrc68jLW8oRhJEJ/m1k9po5aCYDYwYyNmlsu553y/hb2Fm6k4e/fZgwexgXDbuo2f0q6isorS0lLca3xYbUEVa0ExbeD6POh4ueB3uvPu10eb36r/O743/HyISRvLrlVW5bdBvp0emU1pVyfOrxrT7PO8NoalTqYcfgHdW8tmAtQsulk/d2vEdkcCST+00+rNdLCEvALnbSotOICmm5iqwzBdmCGJc8rt3Ps9vsPHbqY9y26DYeWP4AIfaQgxY9Avg6+2vuW3YfpXWlPH3600zqN6nZYxljWJ67HJvNxvD44S0usNTTGWNYtG8RGwo3cHzq8UxImXDIsrOHq7i2mDpn3YEpYJY+DrZgmPlol0oIxhgqHBUU1hRSVFNEYU0hhTWFlNSWkByRTEZMBoNiB5ESkeJTx47y+nIq6ysb9rWJDZvYMMbgNm4M1k+b2EgKT2rxczfGUFRbRGxIbIfWfz9cXecvFACRwZFcM+YaZo+azcK9C3l508vsrdjb5vKWFwy5gOTw5EOWpeyI/lH9cRonsxfMbnPfc446p93LfjblXb6zo11aj7QQewiPT3mcmz+/md8u/S2h9lDOzDjTap9Y9Sjzts1jSNwQokOiuW3Rbbww/YVDutm6jZuHvnmI17e+3rAtJSKF4fHDGZEwgpGJIxmZMJL+Uf07bTR1rbOWb/O+ZV/FPlIjU0mLTmNA9ADCggJTbWKM4Yt9X/Dvtf9mc/FmAJ5d/yzxofFMTZ/KtPRpTO43udXv1/7K/Xy4+0NO7n8ywxOGWxvLc2HHQphwJQb4cPeH/OmbP1HjqOGiYRdxw6DzSVrzGhx79SErpFU7qtlWso3NxZvZWryVzcWbya3MJcQeQkRQBOFB4YQFhRETEkNKRAopESn0iehDn4g+9I3qS2pk6kGfp9u42Vy8mWU5y1iSs4StJVuJCo4iNjSWuNA4YkNjgQNL0BbWFDbbkUEQDAc6QYYHhZMenU5GbAYZMRlkxFrJAmB9wXrWF65nXcE6ssqzfP572MVOSkQKqVGpDasn7q/aT25lLvur9lPnqiMxLJErRl7BrOGzGmI/EuQI9QDtNJmZmWbVqlV+O/6u0l30jex7WIPS2sPhcrDqh1U43c429z065WhiQmLa3K8teVV5RAZHEh0SfdjHOlKqHdXcsPAG1hes55YJtzBv2zxyKnO4ZvQ13DzhZkpqS7jqo6uoc9Xx8syXSY+xpkOpd9XzmyW/4eOsj7ly1JWc3P9ktpVsY0vxFraWbGV36W6cxvrsY0JiGJk4kqFxQ0mOSCYpPImksCQSwxNJi05r9TthjCG3Kpevs79mcfZivs37ttkTTkp4Cv2i+lnHbnTrH9WfgTED6RvZt+FK0xjD/qr9rCtcx/qC9VTUVzA9YzqT+01udmGnsroyluYspcZZQ1hQGGH2MMKCwiirK+OFjS+wpXgL6dHpzBk3h6npU1mRu4LP937O4uzFVDoqSQpP4vqx13PxsIsPSg5Ot5NXN7/Kk2uepMZZgyCcO/hcbp1wK33fuQl2fk7JjId4sHYHn+35jPHJ4xkWP4x3tr9DMIarSkq45scfE5E8nE1Fm1iSs4RluctYV7AOl3EBEBsay4iEEaRHp+NwO6x11J011DprKa0rJb86n5K6kkPes/eziw+LZ13BOopriwGrvWxc0jhqXbWU1ZVRVldGaV0pbuMmJSKFpPAkksOTD/ydG92iQ6IpqC5gT/kessqzrFuZ9TOnMueQsU0JYQmMSx7HuKRxJIUnYTBW6QA3brcbEWkoNQiCw+0gryqvIQnkVuVS76qnX2S/hilfUiJSWJq7lKU5SwkPCueioRdx1airDmsCThFZbYxps5eKJgXVbVTUVzDn0zlsKNpA/6j+/PGkPx608tzust1c/dHVRAZH8tLMl4gIjuCORXewYv8K7jz2Tq4dc+0hx6xz1bGjZAcbizayuXgzm4s2s6tsFzXOmoP2E4T0mHRGJIxgRMIIhsYNpbi2mG0l29hesp1tJdsaTlpp0WmcMuCUhivq/ZX72Vexr+GWV51HUU0RBTUFlNWVHfQ6ofZQ0qLTSAxPZEfJDopqixq2h9hCqHBUkBKRwnmDz+P8wecTERzBF3u/YOHehazKW9Vwkm1qYMxAfjbuZ8wcNPOQaot6Vz0r9q/g+Q3Ps/qH1aRGpnLD0Tdw7uBz2VK8hQeWP8CW4i2cMuAUbp1wKwt2LbAa/42bK0qKGW2CeSgmlLKgEG6ZcAvXjL4Gu83Onry1/PPdS/gkIpS40DgEoaSuBEEYlTiKE1JPYFzyOEYkjKBPRJ82S2n1rnryq/P5ofoH9lftJ6cih5zKHHIrc8mvyWdkwkhO6n8SJ6Se0K65xNqj3lXP3vK9ZJVn4TROxiaNJTUy1W/zdW0t3sqLG1/k490fYzD8dvJvuXjYxR06liYF1SOV1ZXx2Z7PmDloZrMD7zYUbuAnn/yE9Oh0gmxBbCnewv0n3M8FQy5o1+tUO6oprCmkoKaAgpoCssqyGqo4Gg+qCw8KZ0jcEIbFD2NY/DCOTz2ejJgMn08S9a56CmsKya7IJqs8i73le9lTsYeC6gIGxw1mbNJYxiaPZVj8MIwxfLnvS97f+T5LcpYcdMWaEZPB6QNP57S000iOSKbWWUutq5ZaZy1gTTfSVtuBt93lH9//g41FG+kb2Zcfqn4gKTyJe4+796Cp2nPLs3nirfP4n92BERjqcPJQcDrDr/wIbJ769y/+CIsfYeMVc3ku53NC7aGc1P8kjk89noSwhPb8OXq9/ZX7eXnzy/xoyI987sHXlCYF1Wsty13GzZ/fjF2shuopaVM69fjl9eXsLN1JQlgCA6IGdGiN7sNVUF3Agt0LcLgdnJZ2GkfFHdVpxzbG8MXeL3hl8ysMTxjOzeNvPrSqcd1b8M5P2TLjQdbG9eHCikpCPrwTznrMWju5rgL+NhoyTobLtEtxV6BJQfVqa/LXEBEcwbD4YYEOpedx1sETmRAWB3O+skoGxsArF8He5XDjMtg831o45/ovoP+xbR9T+Z2vSaHXDl5TPdv4lPGaEA7Xrq+sdZGbWvkfKN0LZ/z+QFWRCJz3T6vr6Xs3WqOXj5qiCaEb0qSglDrUnuXw0vnw5CT438+h4gdre00pLH4UBp9mzV/UWGx/aw3lvcuh8gc4+RdHPm512Hr1OAWlVDMcNdakdXFpMHQ6rH4B1r4BJ94GNSVWYji9hVXSxl8Ou76E2jKrPUF1O5oUlFIH+/IhKNoBV71vVQFNvhE+f8DaDjDuMujXwgh1EbjoWauNQZdV7ZY0KSilDshZDcv+CcdcbSUEsFZFm/US7PsW1r4Gp7Q89XkDTQjdliYFpZTFWQfv3QxRfeHMBw99PG2SdVM9miYFpZTl679AwWZr8ZuwIzfXjupatPeRUgry1ltJYdxlMOzQpVJV76FJQanerqoI3roWwuOtLqWqV9PqI6V6s7pKmHsJlO2DK9+FCJ2TqLfTpKBUb+WshzevhNzv4dJXYeAJgY5IdQGaFJTqjdxuazqKnV9Y01OMOCvQEakuQtsUlOptjIFPfg0b5sG038ExVwU6ItWFaElBqd6kMt+avXTta3DcjXDSnYGOSHUxmhSU6g1cTmt200V/Ake1NVnd1N/qyGN1CE0KSvV0WUtgwS8hfyMcNRVmPgLJOq24ap4mBaV6qvpq+Oz/rBJCbDpc+gqMOEdLB6pVmhSU6olyVsM7c6zZTo+/Bab+BkIiAh2V6gY0KSjVk7icsOSv8NWfIaoPXDUfjjo10FGpbsSvXVJFZIaIbBWRHSJyTwv7zBKRTSKyUUTm+jMepXq0/C3wwgxY9EcYfSHcuFQTgmo3v5UURMQOPAmcAWQDK0VkvjFmU6N9hgL3AicaY0pEJMVf8SjVYznrYcnf4OvHICQSLnoOxl4c6KhUN+XP6qNJwA5jzC4AEXkdOB/Y1Gif64EnjTElAMaYfD/Go1TPs28lzL/VmvJ6zMUw42GISg50VKob82f1UX9gX6P72Z5tjQ0DhonIUhFZISIzmjuQiMwRkVUisqqgoMBP4SrVzSx+DJ47A+rK4cdvwMXPaUJQhy3QDc1BwFBgCjAAWCwiY40xpY13MsY8AzwDkJmZaY50kEp1OdsXwhcPWm0H5/4DwmICHZHqIfxZUsgB0hrdH+DZ1lg2MN8Y4zDG7Aa2YSUJpVRLKvPhvRsgeSRc8JQmBNWpfEoKInK7iMSI5TkR+U5EzmzjaSuBoSIySERCgMuA+U32eQ+rlICIJGFVJ+1q1ztQqjcxBt67CWrLreqi4PBAR6R6GF9LCj8xxpQDZwLxwJXAw609wRjjBG4BPgE2A28aYzaKyO9F5DzPbp8ARSKyCVgE3G2MKerA+1Cqd/jm37DjMzjzD9BndKCjUT2Qr20K3nHxZwEve07ubY6VN8YsABY02fa7Rr8b4E7PTSnVmrwN1rQVQ6fDpOsDHY3qoXwtKawWkU+xksInIhINuP0XllLqIPXV8PZ11jrKF/xL5y9SfuNrSeE6YDywyxhTLSIJwLX+C0sp1aC+Ct66Fgq2wOx3IDIp0BGpHszXksLxwFZjTKmIzAZ+C5T5LyylFABVhfDfc612hLP/CkOmBToi1cP5mhSeAqpF5GjgF8BO4CW/RaWUguLd8NyZ8MNGmPUyTLwu0BGpXsDXpOD0NAqfDzxhjHkSiPZfWEr1crnfW6OVq4vgqvdh5DmBjkj1Er62KVSIyL1YXVFPFhEbEOy/sJTqxXYugtevgIgEuOZDSB4e6IhUL+JrSeFSoA5rvEIe1ujkR/0WlVK91ab3Ye4siM+A6z7ThKCOOJ+SgicRvArEisg5QK0xRtsUlOpMq/8Lb10DqRPg2g8hpl+gI1K9kK/TXMwCvgUuAWYB34iITtiuVGdZ8jh8cBsMPg2ufNcaj6BUAPjapvAbYKJ3vQMRSQYWAvP8FZhSvYIxsPA+WPp3GHMRXPA0BIUEOirVi/maFGxNFsApws9LeSrV4znr4P2bYf1bkHkdnPUo2OyBjkr1cr4mhY9F5BPgNc/9S2kyp5FSqh2qi+GN2bBnKUz7HZx0p05doboEn5KCMeZuEbkIONGz6RljzLv+C0upHqwkC169xPr5o//AuEsCHZFSDXxeec0Y8zbwth9jUapnqyqEvSvgf3eAywFXvgcZJ7b9PKWOoFaTgohUAM0tfylYM1/rkk9KtaR4N3z3EuSthx82QMV+a3tcOlyzAJKHBTY+pZrRalIwxuhUFkp1xL6V1iC0unJIGg6DToW+Y63bgEwIiQx0hEo1y+fqI6WUj7Z+ZE11Hd0HfroQEgcHOiKlfKbdSpXqTKtfhNcvh5QR1jQVmhBUN6MlBaU6gzHw5cPw1cMw5Ay45EUIjQp0VEq1myYFpTrD5w/Akr/B+Nlw7uNg10mEVfekSUGpw/X1X6yEkPkTa3U0HYSmujFtU1DqcHz7LHz+exg7C876iyYE1e1pUlCqo9a8BgvuguFnwwX/Apv+O6nuT7/FSnXEpvnw/k3W+IOLn9c2BNVjaFJQqj2MsaqM5l0L/TPhsrkQHBboqJTqNL2qobne6SYkSPOg6iBHLXx4J6x5FYZOh4ue1W6nqsfpNWfI/3y9iwm//5Q6pyvQoajuqCwbXphhJYRTfwU/fh3CYgMdlVKdrteUFAbER1BV72JDThnHDkwIdDiqO9m5CN7+qbUozmWvwYizAh2RUn7j15KCiMwQka0iskNE7mllv4tExIhIpr9iycyw1rxdmVXir5dQ3Y3bBXuWQ311848X7YTXr4CXL4CIBLj+C00IqsfzW0lBROzAk8AZQDawUkTmG2M2NdkvGrgd+MZfsQAkRYVyVFIkq7KK4VSdj6bXczmsq/9N70FwBAw9E0ZfYP101sFXj8DKZyEoDE77LUy+GUIiAh21Un7nz+qjScAOY8wuABF5HTgf2NRkvweBPwN3+zEWACZmJPDJpjzcboPNpoOMei1HLbx1DWz7CE76OdSWweYPrAQRFA72EKivgAlXwtTfWLOdKtVL+DMp9Af2NbqfDRzXeAcROQZIM8Z8KCItJgURmQPMAUhPT+9wQJkZ8byxah87CyoZ2keXiuiV6qvhjStg5xdw9l9g4k+t7Wc9BnuWWYmhphROvhP6jA5srEoFQMAamkXEBvwVuKatfY0xzwDPAGRmZja3EpxPJmZYDcwrs0o0KfRGdRUw9zLYsxTOfxImzD7wmM0Og062bkr1Yv5MCjlAWqP7AzzbvKKBMcCXYs0X0xeYLyLnGWNW+SOggYkRJEWFsjKrmMuP63iJQ3UDznoo3gUlu6Eky7rt+goKt8FF/4GxFwc6QqW6JH8mhZXAUBEZhJUMLgMu9z5ojCkDkrz3ReRL4C5/JQTPazAxI56VWcX+egnVFRTvhlcuguKdB7aFREHCILj0Fe1BpFQr/JYUjDFOEbkF+ASwA88bYzaKyO+BVcaY+f567dZkZiTw0YY89pfV0C82PBAhKH/K2wCv/Ahc9XDeE5AyEuIzICJRZzBVygd+bVMwxiwAFjTZ9rsW9p3iz1i8JnrGK6zKKuHcozUp9Ch7llltBqFRcNV8a0lMpVS79JppLrxG9YshIsRujVdQPceWBfDyhRCVAj/5RBOCUh3U65JCkN3GhPQ4HdncUzjrYcnj8MZsSBllJYS4tLafp5RqVq9LCmB1Td2SV055rSPQoajDsWMhPHUCLLwPhs+Eqz+AyMRAR6VUt9Zrk4LbwPd7SwMdiuqI4t3w2uVWDyPjgsvfhMte1WmsleoEvWaW1MbGp8Vhtwmrsoo5dVhyoMNRvirPhaV/h1UvgC0ITr8fJt8EQaGBjkypHqNXJoXI0CBGp8bw7W5tbO4WynJgyd/gu5esksHRl8HU30JMv0BHplSP0yuTAkDmwARe/WaPrsbWldRVQnkOVOyHijzrZ8E22DAPjBvGX2HNSRSfEehIleqxek9ScDmt+W08A5gmZsTz/NLdbMgt45j0+AAH10PUVVrTTa9+EZKGwegfWaOHm65QVlcBOd9B3noo2nHgVrH/0GOGxR5IBnE6NYlS/tZ7ksKaV+CrR2HwFDhqKpkpkwFYlVWsSeFweZPB0n9ATTEMPBHyN8P2G6xpqIecDhknQ8EWyF4F+ZsAz7yG4QmQNBQGnwaJgyE23aoWiu4H0X0hJDKgb02p3qb3JIW4dOh/jDVv/vevkAx8FjGIvV8NYPNqIULqCZd6QqlHbHbc9lDc9lBMUBjGFoJBAINpNEerzR6ELSgYm92OzR6MzWbDuN1WVQcGjBvBmnNJBATBWsbBIMYNxjTsa8SOERtGgsBmw4gdERuIDbFZv9uCggiyByH2IBC71dhqD7JOvPYQ677Nbk3x4HJYi8W46q3XsNkPPMe7n+f42Dzbw+IgMhkik6xbaMyhU0M466FsH5TugZI91hX+mrlWMhhyOpx6D6RNtN5b9irY+A5sfA+2LrCu+gdMhFHnWT9TJ1grmimlugwxpsMzUQdEZmamWbXqMObMc7sgdw3s+oL933+EqzSXahNMlTuEWhNCLcHYMIRJPaE4CMVBCM2PZ7DjJkhc2HFjx40NN25sGGj4aSWTAwRjPWYEN9bNeyybGOuYuLB5jmDDjWA8xzfY8byeHIG/m9isRCJi/Y6Aq86TyDxsQXDUVGsx+7SJzR/H7baqhqL7gU3bb5QKBBFZbYxpc8nj3lNS8LLZYcCxMOBY+p1yYF2fOqeLkioHhZV11LvcGGNwGqg34DbWqd1mE8+Vv3UhXOd0U+d0UeuwfjpcBpsc2Me7n9NtcLkNTrfB6XI3H1ZDaYIDV+fGWAnGbXAbqHe5qal3UetwUVPvpK6+nmBchNichBgXweIiCBcuWzAOgnFKME4JotYJlbX1VNXUUlVbR1VNLXX1DuqdThwOB26XiyBxEUsVSVLOiJg6RsfWMzjKwZDkCELtYiUC47aWrowfCHEDrQbfmFTrM231M7dBbP/D/tMppfyv9yWFFoQG2ekba6dvbFigQzninC43FbVONu0v5/u9JXy/t5R5+0op2lNPRIidCyf058rjBzKib0ygQ1VK+Vnvqz5SPjHGsD6njJeX72H+2lzqnG4mZSRw5fEDmTGmL8F2rQZSqjvxtfpIk4JqU0lVPW+t3scrK/ayt7ia1Ngwrjohgx9PTCc2IjjQ4SmlfKBJQXU6t9vwxZZ8nluym+W7iogIsXPxsQO4+oQMBifrvENKdWWaFJRfbcwt44WlWcxfk0u9y81xgxK4/Lh0po/uS1hwGw3PSqkjTpOCOiIKKuqYtzqb11fuZU9RNXERwfxowgBOH5XChLR4wkM0QSjVFWhSUEeU221YvquIud/u5dONeThchmC7cPSAOCYNSmDSoAQmZiQQGaod3pQKBE0KKmDKax2sziphxe4ivt1dzPrsMpxuK0mMT4vjhMFJnDgkifFpcToZoVJHiCYF1WVU1ztZvaeEpTuKWLazkPU5ZRgD0aFBTBuZwowx/Th1WLJWNSnlRzqiWXUZESFBnDw0mZOHWgsalVU7WL6riEVb8vl0Ux7vrcklPNjO1BHJXJKZxpRhyUjTOZeUUkeElhRUQDldbr7ZXcxHG/bz8YYfKKysY9yAWG6fNpTTRqRoclCqk2j1kep2HC4373yXzT+/2EF2SQ1j+1vJYdpITQ5KHS5fk4K28qkuI9hu49KJ6Sy6awqPXDSOshoHP31pFT9+dgU78isCHZ5SvYImBdXlBNttzJqYxue/OJU/XDCGTbnlzPz71zz2yVZqHa5Ah6dUj6ZJQXVZwXYbsycP5Iu7pnDuuFSeWLSDM/+2mEVb8wMdmlI9liYF1eUlRYXy10vHM/f64wi2C9e+sJIrn/uGDTllgQ5NqR7Hr0lBRGaIyFYR2SEi9zTz+J0isklE1onI5yIy0J/xqO7thMFJfHT7Kfz27JGszynjnH8u4dbXvmdPUVWgQ1Oqx/Bb7yMRsQPbgDOAbGAl8GNjzKZG+0wFvjHGVIvIjcAUY8ylrR1Xex8psEZNP/PVLv6zZBdOl+HHk9K5eeqQXrlIklK+6Aq9jyYBO4wxu4wx9cDrwPmNdzDGLDLGVHvurgAG+DEe1YPEhAVz1/ThLL57KpdOTOO1b/dyyiOLuO/9DeSV1QY6PKW6LX8mhf7Avkb3sz3bWnId8JEf41E9UEpMGH+8cCyL7prCRcf259VvDiSH7JLqtg+glDpIl5jmQkRmA5nAqS08PgeYA5Cenn4EI1PdRVpCBA/9aBw3TRnCv77cwavf7OWlFXs4aUgSl05M44xRfQgN0rmVlGqLP9sUjgfuN8ZM99y/F8AY81CT/U4H/gmcaoxps6+htikoX+SU1vDGyn3MW7WP3LJa4iKCuWB8f2aM6csx6fE6O6vqdQI+zYWIBGE1NE8DcrAami83xmxstM8EYB4wwxiz3ZfjalJQ7eFyG5buKOSNVfv4bOMP1LvcRITYmXxUIicPTeLkoUkMTo7SaTRUjxfwWVKNMU4RuQX4BLADzxtjNorI74FVxpj5wKNAFPCW559yrzHmPH/FpHofu004ZVgypwxLprzWwYqdRXy9vZAlOwr5YotVME2JDmXyUYkcPziR449KZGBihCYJ1WvphHiq19pXXM2SHYUs31nE8l1FFFTUAZCRGMF1Jx/FJccO0PWmVY8R8Oojf9GkoPzBGMPOgiqW7yri7dXZrNlXSlJUCNeeOIjZkwcSGx4c6BCVOiyaFJTqIGMM3+wu5qkvd/LVtgKiQoO4+NgBnHt0Ksekx2nVkuqWNCko1Qk25JTxzA6xVyAAAA2NSURBVOJdfLwxj3qnm/5x4Zx7dCrnHt2PUf1iNEGobkOTglKdqLzWwWcbf+CDdbl8vb0Ql9swvE80l2QO4MIJ/UmMCg10iEq1SpOCUn5SXFXPh+v3M291Nmv3lRJkE6aNTOGSY9M4aWiSNk6rLkmTglJHwLYfKnhr1T7e+S6Hoqp6QoNsTBqUwClDrW6ww/roGAjVNWhSUOoIcrjcLN1RyOJthXy9vYDt+ZXA/7d3rzFy1ecdx7/P3G+7szt792Vv4NgYbGxwzSWhMqAgl0YhL4jSNI2iKlLeUClIldqgtqmaV+2b0r6I2kQpLWlRGoWEFBEUCA5BciTAiy/s2maxsdf2rr33+3V2Zp6+OGeH8eLLYpidOZ7nIx2dOWfOzP7GPrvPnP855/+Hhqowe9tT7Gmv5Q/aU9zWUo3fZ0XCrL+S37xmTCUJ+n3s29rIvq2NAFycXODgqVF+/8EoXX0T/Kr7EgCJcIB7O1M8sr2Zh25rpN7ORZgyY0cKxqyDi5MLHOob51DfOK+/N8LA5AIisKetlke2N7P/jmY2p2KljmluYtZ8ZEyZUlVOXJrm1eNDvHpiiJOXpgHYsTHJozta+OMdLbTWWYEwny4rCsZ4xIXxeV7uvsTLPYMcuzAJwPaWau5uq2XHxiR3bEyypSlB0G89u5obZ0XBGA/qn5jn1z2DvHZyiJ6BaWaXMgCEAj5ua6lm9+YadrmTddxnPg4rCsZ4XC6n9I3N0T0wxfGL0xy7MEn3wBTz6SwAtbEgu1trubvNubJp56ak3SNhrsquPjLG43w+obMhQWdDgsd2OSPZZrI5Tg3PcuT8JEcvTPDOuYl8F+BBv3DHxiR7O1Lc21HHnvZaqiLWkZ/5eOxIwRiPG59Lc/jcBF3nJujqG+dY/yTLWcUncPuGJPd0pHjgMw3c05GyI4kKZs1HxlSohXSWI+cnePPsOG+dGePIhUnSmRyRoI/7OuvYt7WRB7bU01Eft3MSFcSaj4ypUNGQn/tvref+W+sBp0i8eWaM3/UO87v3R3i91xkRtyoSYMfGpDNtSnL7hiStqZjdcV3hrCgYc5OLhvw8uK2RB7c5d1v3jTqDCXUPTNEzMMUzvz/LctZpMQgHfGxpSrC1qZqtzQk66xO018fZnIoSDljTUyWwomBMhWmvj9NeH+er7nI6k6N3cIaTg9O8PzhD79AMB0+P8PPD/fnX+AQ21ERpTcVIhANEgn7CAR+RoJ+aWJCdm2q4q7XGuhC/CVhRMKbChQI+dmxympAKTc6nOTs6R9/YHGdH5zk3Nsf58XnG59IsLmdZXM6xmMkys5ghm3OONNrqYtzVWsvu1hp2bqphW3OVndz2GCsKxpgrqomF2N0aYndr7TW3W0hn6R6Y4vD5CY6cn+Dg6VFeODIAOJfJbm2uYsdGp0Dc0pCgsyFOSzJiJ7nLlBUFY8wnEg352duRYm9HCnD6dro0tci7/ZMc65+iu3+KX717kZ+8ncm/Jhby0+E2Y7XXxWhLxWmri7E5FaM+ESYUsC49SsWKgjHmUyUibKiJsqEmyv47WgCnUIzMLHF6ZJYzI3N84M6PD0zxSs8gmdzll8Yno0HqEyHqE2FS8RCJcIBEJODMwwFqYkFqYyFS8RC18RB18RDJaNCOPj4FVhSMMUUnIjRWR2isjnD/LfWXPZfJ5rg4uUjf2Bz9EwuMzi4xOrvEyIwzPzU8y9xShtnFDLPpDFe7taoqEqCzPk5HfZzOhgRtdTGaqyM0JyM0VUfs3MYaWVEwxpRUwO+jtS62pu7CczllLp1hamGZibllxufTTMylGZ1d4tzYPGdH5zjUN8Evj178yGurI4F8gWhJRmiujtCUjNBUFaGhKkxDVfhjN13lcsrCcpb5dJaFdJZw0EdtLOTp5i8rCsYYz/D5hKpIkKpIkE3XOP+9kM7SPzHP4PQiQ9NLDE0vMjS9yOCUM+8dnGFkdumKRx3JaJBYyJ+/7DYc8BHw+9wrrpyrrhaWnSKwsJy94s+vjgSoS4Spi4docgtQS9I5amlJRmmri1EXD5Vlc5cVBWPMTSca8rOlqYotTVVX3SaTzTEyu8Tw9IdNVSvzBfeP/1Imy1Imx3I2R000SCTkJxLwEw35iAb9REMB4iF/vogsZXKMzaYZn1tidC7N2OwSJy5Oc+DkEIvLuct+fjzkp63uwxPsjVVhGqsjNLnzVCxEPOwnsM7jaFhRMMZUpIDfR0sySksyWvSfpapML2S4NL3AxckFzo/N0zfm3PvROzTDgfeGSWdyV3xtNOgnEQlQFQ7w5Oc/wxfv3FDUrFYUjDGmyESEZCxIMhZkW3P1R55fKRrDMx82d00uLDsn15eWmV3KMLOYIRULFT1rUYuCiOwH/hXwAz9S1X9c9XwY+DFwNzAGfEVV+4qZyRhjyk1h0bhWk9d6KFpjlYj4ge8DfwRsB74qIttXbfZNYEJVbwWeBv6pWHmMMcZcXzHPYOwFTqvqGVVNA/8LPLZqm8eAZ93HzwMPSzmejjfGmApRzKKwEbhQsNzvrrviNqqaAaaAutVvJCLfEpEuEekaGRkpUlxjjDGeuMNCVX+oqntUdU9DQ0Op4xhjzE2rmEVhANhcsLzJXXfFbUQkACRxTjgbY4wpgWIWhUPAFhHpEJEQ8CfAi6u2eRH4hvv4ceC36rVBo40x5iZStEtSVTUjIn8BvIJzSeozqnpcRL4HdKnqi8B/AP8tIqeBcZzCYYwxpkSKep+Cqr4MvLxq3XcLHi8CXy5mBmOMMWsnXmutEZER4NwNvrweGP0U46w3L+f3cnaw/KXk5exQPvnbVPW6V+p4rih8EiLSpap7Sp3jRnk5v5ezg+UvJS9nB+/l98QlqcYYY9aHFQVjjDF5lVYUfljqAJ+Ql/N7OTtY/lLycnbwWP6KOqdgjDHm2irtSMEYY8w1WFEwxhiTVzFFQUT2i0iviJwWke+UOs/1iMgzIjIsIj0F61Ii8hsROeXOrzF0eemIyGYReV1ETojIcRH5tru+7POLSERE3haRY272f3DXd4jIW+7+81O365ayJSJ+ETkiIi+5y57JLyJ9ItItIkdFpMtdV/b7DoCI1IjI8yLynoicFJH7vJJ9RUUUhTUO+FNu/gvYv2rdd4ADqroFOOAul6MM8Jequh24F3jC/ff2Qv4l4CFVvRPYBewXkXtxBoB62h0QagJngKhy9m3gZMGy1/I/qKq7Cq7v98K+A85Ik79W1W3AnTj/B17J7lDVm34C7gNeKVh+Cniq1LnWkLsd6ClY7gVa3MctQG+pM67xc/wf8Hmv5QdiwGHgHpw7UgNX2p/KbcLpkfgA8BDwEiAey98H1K9aV/b7Dk4vz2dxL+DxUvbCqSKOFFjbgD9e0KSql9zHg0BTKcOshYi0A7uBt/BIfrfp5SgwDPwG+ACYVGcgKCj//edfgL8Ccu5yHd7Kr8CrIvKOiHzLXeeFfacDGAH+0226+5GIxPFG9rxKKQo3HXW+dpT19cQikgB+DjypqtOFz5VzflXNquounG/ce4FtJY60ZiLyBWBYVd8pdZZP4HOqehdOc+8TIvKHhU+W8b4TAO4C/k1VdwNzrGoqKuPseZVSFNYy4I8XDIlIC4A7Hy5xnqsSkSBOQXhOVX/hrvZMfgBVnQRex2luqXEHgoLy3n8+C3xRRPpwxkV/CKed2yv5UdUBdz4MvIBTmL2w7/QD/ar6lrv8PE6R8EL2vEopCmsZ8McLCgcl+gZOW33ZERHBGSvjpKr+c8FTZZ9fRBpEpMZ9HMU5F3ISpzg87m5WltkBVPUpVd2kqu04+/lvVfVreCS/iMRFpGrlMfAI0IMH9h1VHQQuiMhWd9XDwAk8kP0ypT6psV4T8CjwPk778N+UOs8a8v4EuAQs43wD+SZO2/AB4BTwGpAqdc6rZP8cziHyu8BRd3rUC/mBncARN3sP8F13fSfwNnAa+BkQLnXWNXyWfcBLXsrv5jzmTsdXfle9sO+4OXcBXe7+80ug1ivZVybr5sIYY0xepTQfGWOMWQMrCsYYY/KsKBhjjMmzomCMMSbPioIxxpg8KwrGrCMR2bfSc6kx5ciKgjHGmDwrCsZcgYj8mTuuwlER+YHbSd6siDztjrNwQEQa3G13icibIvKuiLyw0l++iNwqIq+5YzMcFpFb3LdPFPS5/5x7B7gxZcGKgjGriMhtwFeAz6rTMV4W+BoQB7pU9XbgDeDv3Zf8GPhrVd0JdBesfw74vjpjM9yPc4c6OL3GPokztkcnTn9FxpSFwPU3MabiPAzcDRxyv8RHcToxywE/dbf5H+AXIpIEalT1DXf9s8DP3P57NqrqCwCqugjgvt/bqtrvLh/FGTfjYPE/ljHXZ0XBmI8S4FlVfeqylSJ/t2q7G+0jZqngcRb7PTRlxJqPjPmoA8DjItII+fGB23B+X1Z6Gv1T4KCqTgETIvKAu/7rwBuqOgP0i8iX3PcIi0hsXT+FMTfAvqEYs4qqnhCRv8UZ/cuH01PtEziDpux1nxvGOe8ATnfI/+7+0T8D/Lm7/uvAD0Tke+57fHkdP4YxN8R6STVmjURkVlUTpc5hTDFZ85Exxpg8O1IwxhiTZ0cKxhhj8qwoGGOMybOiYIwxJs+KgjHGmDwrCsYYY/L+H/kfnSpmBbH0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss (error)\n",
    "plt.plot(all_loss)\n",
    "plt.plot(all_val_loss)\n",
    "plt.plot(test_err)\n",
    "plt.title(\"Bi-Directional LSTM Loss - All Genres\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Predictions\n",
    "<ul>\n",
    "    <li>Show Multi-Level Metrics</li>\n",
    "    <li>Show percentage of correctly labeled predicitons</li>\n",
    "    <li>Show accuracy, precision, and recall for each genre</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_lstm.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26660684374252236"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4083475298126064"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3856185690356546"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 84.48911222780569\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Action: 0.6566164154103853\n",
      "Precision for Action: 0.36046511627906974\n",
      "Recall for Action: 0.39490445859872614\n",
      "\n",
      "Accuracy for Adventure: 0.8123953098827471\n",
      "Precision for Adventure: 0.28205128205128205\n",
      "Recall for Adventure: 0.11578947368421053\n",
      "\n",
      "Accuracy for Animation: 0.9530988274706867\n",
      "Precision for Animation: 0.3333333333333333\n",
      "Recall for Animation: 0.037037037037037035\n",
      "\n",
      "Accuracy for Comedy: 0.6063651591289783\n",
      "Precision for Comedy: 0.45077720207253885\n",
      "Recall for Comedy: 0.4027777777777778\n",
      "\n",
      "Accuracy for Family: 0.9095477386934674\n",
      "Precision for Family: 0.0\n",
      "Recall for Family: 0.0\n",
      "\n",
      "Accuracy for War: 0.9279731993299832\n",
      "Precision for War: 0.041666666666666664\n",
      "Recall for War: 0.047619047619047616\n",
      "\n",
      "Accuracy for Documentary: 0.9731993299832495\n",
      "Precision for Documentary: 0.5\n",
      "Recall for Documentary: 0.0625\n",
      "\n",
      "Accuracy for Crime: 0.6934673366834171\n",
      "Precision for Crime: 0.19014084507042253\n",
      "Recall for Crime: 0.28421052631578947\n",
      "\n",
      "Accuracy for Fantasy: 0.8994974874371859\n",
      "Precision for Fantasy: 0.1111111111111111\n",
      "Recall for Fantasy: 0.043478260869565216\n",
      "\n",
      "Accuracy for Music: 0.9748743718592965\n",
      "Precision for Music: 0.0\n",
      "Recall for Music: 0.0\n",
      "\n",
      "Accuracy for Thriller: 0.6331658291457286\n",
      "Precision for Thriller: 0.35795454545454547\n",
      "Recall for Thriller: 0.3727810650887574\n",
      "\n",
      "Accuracy for Drama: 0.559463986599665\n",
      "Precision for Drama: 0.57\n",
      "Recall for Drama: 0.7147335423197492\n",
      "\n",
      "Accuracy for TV Movie: 1.0\n",
      "Precision for TV Movie: 0.0\n",
      "Recall for TV Movie: 0.0\n",
      "\n",
      "Accuracy for Mystery: 0.8927973199329984\n",
      "Precision for Mystery: 0.1\n",
      "Recall for Mystery: 0.075\n",
      "\n",
      "Accuracy for Romance: 0.7621440536013401\n",
      "Precision for Romance: 0.3465346534653465\n",
      "Recall for Romance: 0.3153153153153153\n",
      "\n",
      "Accuracy for History: 0.9346733668341709\n",
      "Precision for History: 0.1\n",
      "Recall for History: 0.08695652173913043\n",
      "\n",
      "Accuracy for Science Fiction: 0.8877721943048577\n",
      "Precision for Science Fiction: 0.4\n",
      "Recall for Science Fiction: 0.16129032258064516\n",
      "\n",
      "Accuracy for Horror: 0.8542713567839196\n",
      "Precision for Horror: 0.10256410256410256\n",
      "Recall for Horror: 0.07142857142857142\n",
      "\n",
      "Accuracy for Western: 0.983249581239531\n",
      "Precision for Western: 0.0\n",
      "Recall for Western: 0.0\n",
      "\n",
      "Accuracy for Foreign: 0.983249581239531\n",
      "Precision for Foreign: 0.2\n",
      "Recall for Foreign: 0.14285714285714285\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
