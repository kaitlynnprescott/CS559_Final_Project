{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure': 0,\n",
       " 'Romance': 1,\n",
       " 'Horror-Thriller': 2,\n",
       " 'Comedy': 3,\n",
       " 'Science Fiction': 4,\n",
       " 'Drama': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "genre_dict['Drama'] = 5\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "genre_map['Fantasy'] = 'Science Fiction'\n",
    "genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN STUFF here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 1, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 100\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 100, 32)           3200000   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 99, 100)           6500      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,314,298\n",
      "Trainable params: 3,314,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2072 samples, validate on 231 samples\n",
      "Epoch 1/1000\n",
      " - 6s - loss: 0.6029 - raw_multi_label_accuracy: 0.2081 - val_loss: 0.6013 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch 2/1000\n",
      " - 5s - loss: 0.5890 - raw_multi_label_accuracy: 0.2234 - val_loss: 0.6013 - val_raw_multi_label_accuracy: 0.2168\n",
      "Epoch 3/1000\n",
      " - 5s - loss: 0.5884 - raw_multi_label_accuracy: 0.2309 - val_loss: 0.6022 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch 4/1000\n",
      " - 7s - loss: 0.5872 - raw_multi_label_accuracy: 0.2223 - val_loss: 0.6021 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch 5/1000\n",
      " - 7s - loss: 0.5888 - raw_multi_label_accuracy: 0.1891 - val_loss: 0.5993 - val_raw_multi_label_accuracy: 0.2182\n",
      "Epoch 6/1000\n",
      " - 5s - loss: 0.5861 - raw_multi_label_accuracy: 0.2266 - val_loss: 0.6002 - val_raw_multi_label_accuracy: 0.2186\n",
      "Epoch 7/1000\n",
      " - 5s - loss: 0.5860 - raw_multi_label_accuracy: 0.2256 - val_loss: 0.6001 - val_raw_multi_label_accuracy: 0.2082\n",
      "Epoch 8/1000\n",
      " - 5s - loss: 0.5834 - raw_multi_label_accuracy: 0.2080 - val_loss: 0.6043 - val_raw_multi_label_accuracy: 0.2186\n",
      "Epoch 9/1000\n",
      " - 5s - loss: 0.5809 - raw_multi_label_accuracy: 0.1539 - val_loss: 0.6016 - val_raw_multi_label_accuracy: 0.2171\n",
      "Epoch 10/1000\n",
      " - 6s - loss: 0.5650 - raw_multi_label_accuracy: 0.2027 - val_loss: 0.5903 - val_raw_multi_label_accuracy: 0.1931\n",
      "Epoch 11/1000\n",
      " - 5s - loss: 0.4891 - raw_multi_label_accuracy: 0.3585 - val_loss: 0.6165 - val_raw_multi_label_accuracy: 0.2219\n",
      "Epoch 12/1000\n",
      " - 5s - loss: 0.4248 - raw_multi_label_accuracy: 0.4525 - val_loss: 0.6341 - val_raw_multi_label_accuracy: 0.2642\n",
      "Epoch 13/1000\n",
      " - 4s - loss: 0.3501 - raw_multi_label_accuracy: 0.5659 - val_loss: 0.7089 - val_raw_multi_label_accuracy: 0.2825\n",
      "Epoch 14/1000\n",
      " - 5s - loss: 0.2884 - raw_multi_label_accuracy: 0.6519 - val_loss: 0.8557 - val_raw_multi_label_accuracy: 0.3211\n",
      "Epoch 15/1000\n",
      " - 4s - loss: 0.2711 - raw_multi_label_accuracy: 0.6770 - val_loss: 0.7555 - val_raw_multi_label_accuracy: 0.3132\n",
      "Epoch 16/1000\n",
      " - 5s - loss: 0.2355 - raw_multi_label_accuracy: 0.7245 - val_loss: 0.8921 - val_raw_multi_label_accuracy: 0.2974\n",
      "Epoch 17/1000\n",
      " - 6s - loss: 0.1883 - raw_multi_label_accuracy: 0.7804 - val_loss: 0.8731 - val_raw_multi_label_accuracy: 0.3099\n",
      "Epoch 18/1000\n",
      " - 4s - loss: 0.1454 - raw_multi_label_accuracy: 0.8270 - val_loss: 0.9709 - val_raw_multi_label_accuracy: 0.3126\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.1157 - raw_multi_label_accuracy: 0.8698 - val_loss: 1.0948 - val_raw_multi_label_accuracy: 0.3357\n",
      "Epoch 20/1000\n",
      " - 5s - loss: 0.0987 - raw_multi_label_accuracy: 0.8899 - val_loss: 1.1397 - val_raw_multi_label_accuracy: 0.3366\n",
      "Epoch 21/1000\n",
      " - 5s - loss: 0.0835 - raw_multi_label_accuracy: 0.9166 - val_loss: 1.2896 - val_raw_multi_label_accuracy: 0.3103\n",
      "Epoch 22/1000\n",
      " - 5s - loss: 0.0652 - raw_multi_label_accuracy: 0.9307 - val_loss: 1.2965 - val_raw_multi_label_accuracy: 0.3167\n",
      "Epoch 23/1000\n",
      " - 6s - loss: 0.0549 - raw_multi_label_accuracy: 0.9467 - val_loss: 1.4575 - val_raw_multi_label_accuracy: 0.2982\n",
      "Epoch 24/1000\n",
      " - 5s - loss: 0.0451 - raw_multi_label_accuracy: 0.9544 - val_loss: 1.5190 - val_raw_multi_label_accuracy: 0.3192\n",
      "Epoch 25/1000\n",
      " - 5s - loss: 0.0364 - raw_multi_label_accuracy: 0.9652 - val_loss: 1.6352 - val_raw_multi_label_accuracy: 0.3180\n",
      "Epoch 26/1000\n",
      " - 5s - loss: 0.0307 - raw_multi_label_accuracy: 0.9706 - val_loss: 1.6136 - val_raw_multi_label_accuracy: 0.3366\n",
      "Epoch 27/1000\n",
      " - 4s - loss: 0.0239 - raw_multi_label_accuracy: 0.9793 - val_loss: 1.7683 - val_raw_multi_label_accuracy: 0.3317\n",
      "Epoch 28/1000\n",
      " - 4s - loss: 0.0166 - raw_multi_label_accuracy: 0.9868 - val_loss: 1.8494 - val_raw_multi_label_accuracy: 0.3324\n",
      "Epoch 29/1000\n",
      " - 4s - loss: 0.0130 - raw_multi_label_accuracy: 0.9908 - val_loss: 1.9479 - val_raw_multi_label_accuracy: 0.3181\n",
      "Epoch 30/1000\n",
      " - 4s - loss: 0.0104 - raw_multi_label_accuracy: 0.9923 - val_loss: 2.0195 - val_raw_multi_label_accuracy: 0.3244\n",
      "Epoch 31/1000\n",
      " - 4s - loss: 0.0080 - raw_multi_label_accuracy: 0.9960 - val_loss: 2.0729 - val_raw_multi_label_accuracy: 0.3352\n",
      "Epoch 32/1000\n",
      " - 4s - loss: 0.0063 - raw_multi_label_accuracy: 0.9970 - val_loss: 2.1288 - val_raw_multi_label_accuracy: 0.3338\n",
      "Epoch 33/1000\n",
      " - 4s - loss: 0.0049 - raw_multi_label_accuracy: 0.9980 - val_loss: 2.2167 - val_raw_multi_label_accuracy: 0.3297\n",
      "Epoch 34/1000\n",
      " - 4s - loss: 0.0041 - raw_multi_label_accuracy: 0.9982 - val_loss: 2.2611 - val_raw_multi_label_accuracy: 0.3296\n",
      "Epoch 35/1000\n",
      " - 4s - loss: 0.0038 - raw_multi_label_accuracy: 0.9980 - val_loss: 2.3003 - val_raw_multi_label_accuracy: 0.3242\n",
      "Epoch 36/1000\n",
      " - 4s - loss: 0.0048 - raw_multi_label_accuracy: 0.9970 - val_loss: 2.3160 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 37/1000\n",
      " - 4s - loss: 0.0046 - raw_multi_label_accuracy: 0.9971 - val_loss: 2.3567 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 38/1000\n",
      " - 4s - loss: 0.0049 - raw_multi_label_accuracy: 0.9966 - val_loss: 2.4214 - val_raw_multi_label_accuracy: 0.3226\n",
      "Epoch 39/1000\n",
      " - 4s - loss: 0.0034 - raw_multi_label_accuracy: 0.9982 - val_loss: 2.4467 - val_raw_multi_label_accuracy: 0.3353\n",
      "Epoch 40/1000\n",
      " - 4s - loss: 0.0028 - raw_multi_label_accuracy: 0.9988 - val_loss: 2.5000 - val_raw_multi_label_accuracy: 0.3285\n",
      "Epoch 41/1000\n",
      " - 4s - loss: 0.0023 - raw_multi_label_accuracy: 0.9985 - val_loss: 2.5154 - val_raw_multi_label_accuracy: 0.3310\n",
      "Epoch 42/1000\n",
      " - 4s - loss: 0.0032 - raw_multi_label_accuracy: 0.9979 - val_loss: 2.4796 - val_raw_multi_label_accuracy: 0.3310\n",
      "Epoch 43/1000\n",
      " - 4s - loss: 0.0047 - raw_multi_label_accuracy: 0.9965 - val_loss: 2.6016 - val_raw_multi_label_accuracy: 0.3174\n",
      "Epoch 44/1000\n",
      " - 4s - loss: 0.0117 - raw_multi_label_accuracy: 0.9883 - val_loss: 2.4143 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 45/1000\n",
      " - 4s - loss: 0.0133 - raw_multi_label_accuracy: 0.9857 - val_loss: 2.5021 - val_raw_multi_label_accuracy: 0.3190\n",
      "Epoch 46/1000\n",
      " - 4s - loss: 0.0938 - raw_multi_label_accuracy: 0.9076 - val_loss: 1.7278 - val_raw_multi_label_accuracy: 0.3294\n",
      "Epoch 47/1000\n",
      " - 5s - loss: 0.0566 - raw_multi_label_accuracy: 0.9389 - val_loss: 1.7770 - val_raw_multi_label_accuracy: 0.3179\n",
      "Epoch 48/1000\n",
      " - 4s - loss: 0.0215 - raw_multi_label_accuracy: 0.9795 - val_loss: 2.0274 - val_raw_multi_label_accuracy: 0.3117\n",
      "Epoch 49/1000\n",
      " - 4s - loss: 0.0096 - raw_multi_label_accuracy: 0.9929 - val_loss: 2.1765 - val_raw_multi_label_accuracy: 0.3153\n",
      "Epoch 50/1000\n",
      " - 4s - loss: 0.0048 - raw_multi_label_accuracy: 0.9987 - val_loss: 2.2539 - val_raw_multi_label_accuracy: 0.3260\n",
      "Epoch 51/1000\n",
      " - 4s - loss: 0.0031 - raw_multi_label_accuracy: 0.9987 - val_loss: 2.3437 - val_raw_multi_label_accuracy: 0.3140\n",
      "Epoch 52/1000\n",
      " - 4s - loss: 0.0025 - raw_multi_label_accuracy: 0.9993 - val_loss: 2.3801 - val_raw_multi_label_accuracy: 0.3223\n",
      "Epoch 53/1000\n",
      " - 4s - loss: 0.0017 - raw_multi_label_accuracy: 0.9995 - val_loss: 2.4638 - val_raw_multi_label_accuracy: 0.3319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      " - 4s - loss: 0.0014 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.4810 - val_raw_multi_label_accuracy: 0.3144\n",
      "Epoch 55/1000\n",
      " - 4s - loss: 0.0012 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.5189 - val_raw_multi_label_accuracy: 0.3172\n",
      "Epoch 56/1000\n",
      " - 5s - loss: 0.0011 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.5526 - val_raw_multi_label_accuracy: 0.3164\n",
      "Epoch 57/1000\n",
      " - 5s - loss: 9.4884e-04 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.5893 - val_raw_multi_label_accuracy: 0.3199\n",
      "Epoch 58/1000\n",
      " - 5s - loss: 8.8635e-04 - raw_multi_label_accuracy: 0.9998 - val_loss: 2.6110 - val_raw_multi_label_accuracy: 0.3153\n",
      "Epoch 59/1000\n",
      " - 5s - loss: 8.2568e-04 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.6532 - val_raw_multi_label_accuracy: 0.3176\n",
      "Epoch 60/1000\n",
      " - 4s - loss: 7.1539e-04 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.6785 - val_raw_multi_label_accuracy: 0.3177\n",
      "Epoch 61/1000\n",
      " - 5s - loss: 6.2930e-04 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.7059 - val_raw_multi_label_accuracy: 0.3135\n",
      "Epoch 62/1000\n",
      " - 5s - loss: 5.7156e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7310 - val_raw_multi_label_accuracy: 0.3161\n",
      "Epoch 63/1000\n",
      " - 5s - loss: 5.2926e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7576 - val_raw_multi_label_accuracy: 0.3180\n",
      "Epoch 64/1000\n",
      " - 5s - loss: 4.8457e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.7830 - val_raw_multi_label_accuracy: 0.3175\n",
      "Epoch 65/1000\n",
      " - 4s - loss: 4.5037e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8025 - val_raw_multi_label_accuracy: 0.3184\n",
      "Epoch 66/1000\n",
      " - 4s - loss: 4.1513e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8233 - val_raw_multi_label_accuracy: 0.3171\n",
      "Epoch 67/1000\n",
      " - 4s - loss: 3.8700e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8501 - val_raw_multi_label_accuracy: 0.3185\n",
      "Epoch 68/1000\n",
      " - 4s - loss: 3.6017e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8676 - val_raw_multi_label_accuracy: 0.3199\n",
      "Epoch 69/1000\n",
      " - 4s - loss: 3.3932e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.8864 - val_raw_multi_label_accuracy: 0.3213\n",
      "Epoch 70/1000\n",
      " - 4s - loss: 3.1546e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9061 - val_raw_multi_label_accuracy: 0.3208\n",
      "Epoch 71/1000\n",
      " - 4s - loss: 2.9595e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9204 - val_raw_multi_label_accuracy: 0.3255\n",
      "Epoch 72/1000\n",
      " - 4s - loss: 2.7865e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9413 - val_raw_multi_label_accuracy: 0.3195\n",
      "Epoch 73/1000\n",
      " - 4s - loss: 2.6980e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9565 - val_raw_multi_label_accuracy: 0.3241\n",
      "Epoch 74/1000\n",
      " - 4s - loss: 2.6839e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9808 - val_raw_multi_label_accuracy: 0.3168\n",
      "Epoch 75/1000\n",
      " - 4s - loss: 2.4235e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 2.9883 - val_raw_multi_label_accuracy: 0.3250\n",
      "Epoch 76/1000\n",
      " - 4s - loss: 2.2424e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0042 - val_raw_multi_label_accuracy: 0.3186\n",
      "Epoch 77/1000\n",
      " - 4s - loss: 2.1253e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0189 - val_raw_multi_label_accuracy: 0.3241\n",
      "Epoch 78/1000\n",
      " - 4s - loss: 2.0068e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0363 - val_raw_multi_label_accuracy: 0.3241\n",
      "Epoch 79/1000\n",
      " - 5s - loss: 1.9335e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0534 - val_raw_multi_label_accuracy: 0.3209\n",
      "Epoch 80/1000\n",
      " - 5s - loss: 1.8078e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0624 - val_raw_multi_label_accuracy: 0.3250\n",
      "Epoch 81/1000\n",
      " - 4s - loss: 1.7437e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0767 - val_raw_multi_label_accuracy: 0.3260\n",
      "Epoch 82/1000\n",
      " - 4s - loss: 1.6632e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.0922 - val_raw_multi_label_accuracy: 0.3246\n",
      "Epoch 83/1000\n",
      " - 4s - loss: 1.5743e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1048 - val_raw_multi_label_accuracy: 0.3222\n",
      "Epoch 84/1000\n",
      " - 4s - loss: 1.5052e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1136 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 85/1000\n",
      " - 4s - loss: 1.4474e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1259 - val_raw_multi_label_accuracy: 0.3222\n",
      "Epoch 86/1000\n",
      " - 4s - loss: 1.3775e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1396 - val_raw_multi_label_accuracy: 0.3227\n",
      "Epoch 87/1000\n",
      " - 4s - loss: 1.3232e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1496 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 88/1000\n",
      " - 4s - loss: 1.2582e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1611 - val_raw_multi_label_accuracy: 0.3222\n",
      "Epoch 89/1000\n",
      " - 4s - loss: 1.2058e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1722 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 90/1000\n",
      " - 4s - loss: 1.1577e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1815 - val_raw_multi_label_accuracy: 0.3227\n",
      "Epoch 91/1000\n",
      " - 4s - loss: 1.1154e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.1901 - val_raw_multi_label_accuracy: 0.3222\n",
      "Epoch 92/1000\n",
      " - 4s - loss: 1.0769e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2010 - val_raw_multi_label_accuracy: 0.3231\n",
      "Epoch 93/1000\n",
      " - 4s - loss: 1.0421e-04 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2120 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 94/1000\n",
      " - 4s - loss: 9.8739e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2203 - val_raw_multi_label_accuracy: 0.3227\n",
      "Epoch 95/1000\n",
      " - 4s - loss: 9.5892e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2307 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 96/1000\n",
      " - 4s - loss: 9.1600e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2383 - val_raw_multi_label_accuracy: 0.3231\n",
      "Epoch 97/1000\n",
      " - 4s - loss: 8.8310e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2449 - val_raw_multi_label_accuracy: 0.3222\n",
      "Epoch 98/1000\n",
      " - 5s - loss: 8.5020e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2536 - val_raw_multi_label_accuracy: 0.3231\n",
      "Epoch 99/1000\n",
      " - 4s - loss: 8.2133e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2622 - val_raw_multi_label_accuracy: 0.3245\n",
      "Epoch 100/1000\n",
      " - 4s - loss: 7.9606e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2709 - val_raw_multi_label_accuracy: 0.3259\n",
      "Epoch 101/1000\n",
      " - 4s - loss: 7.6969e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2799 - val_raw_multi_label_accuracy: 0.3240\n",
      "Epoch 102/1000\n",
      " - 4s - loss: 7.5041e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2885 - val_raw_multi_label_accuracy: 0.3231\n",
      "Epoch 103/1000\n",
      " - 4s - loss: 7.2760e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.2938 - val_raw_multi_label_accuracy: 0.3296\n",
      "Epoch 104/1000\n",
      " - 4s - loss: 7.0023e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3063 - val_raw_multi_label_accuracy: 0.3264\n",
      "Epoch 105/1000\n",
      " - 4s - loss: 6.7622e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3105 - val_raw_multi_label_accuracy: 0.3286\n",
      "Epoch 106/1000\n",
      " - 4s - loss: 6.5298e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3181 - val_raw_multi_label_accuracy: 0.3273\n",
      "Epoch 107/1000\n",
      " - 4s - loss: 6.3409e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3249 - val_raw_multi_label_accuracy: 0.3254\n",
      "Epoch 108/1000\n",
      " - 4s - loss: 6.1073e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3320 - val_raw_multi_label_accuracy: 0.3259\n",
      "Epoch 109/1000\n",
      " - 4s - loss: 5.9681e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3414 - val_raw_multi_label_accuracy: 0.3277\n",
      "Epoch 110/1000\n",
      " - 4s - loss: 5.7840e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3470 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 111/1000\n",
      " - 4s - loss: 5.6186e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3560 - val_raw_multi_label_accuracy: 0.3272\n",
      "Epoch 112/1000\n",
      " - 4s - loss: 5.4613e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3640 - val_raw_multi_label_accuracy: 0.3277\n",
      "Epoch 113/1000\n",
      " - 4s - loss: 5.2721e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3683 - val_raw_multi_label_accuracy: 0.3305\n",
      "Epoch 114/1000\n",
      " - 4s - loss: 5.1273e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3749 - val_raw_multi_label_accuracy: 0.3258\n",
      "Epoch 115/1000\n",
      " - 4s - loss: 5.0221e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3813 - val_raw_multi_label_accuracy: 0.3296\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 4.8222e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3878 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 117/1000\n",
      " - 4s - loss: 4.7040e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.3951 - val_raw_multi_label_accuracy: 0.3272\n",
      "Epoch 118/1000\n",
      " - 4s - loss: 4.5438e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4004 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 119/1000\n",
      " - 4s - loss: 4.4334e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4059 - val_raw_multi_label_accuracy: 0.3272\n",
      "Epoch 120/1000\n",
      " - 4s - loss: 4.3249e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4118 - val_raw_multi_label_accuracy: 0.3263\n",
      "Epoch 121/1000\n",
      " - 4s - loss: 4.2149e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4159 - val_raw_multi_label_accuracy: 0.3272\n",
      "Epoch 122/1000\n",
      " - 5s - loss: 4.1034e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4224 - val_raw_multi_label_accuracy: 0.3263\n",
      "Epoch 123/1000\n",
      " - 5s - loss: 3.9950e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4293 - val_raw_multi_label_accuracy: 0.3277\n",
      "Epoch 124/1000\n",
      " - 5s - loss: 3.8865e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4342 - val_raw_multi_label_accuracy: 0.3300\n",
      "Epoch 125/1000\n",
      " - 5s - loss: 3.7918e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4387 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 126/1000\n",
      " - 5s - loss: 3.7032e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4448 - val_raw_multi_label_accuracy: 0.3305\n",
      "Epoch 127/1000\n",
      " - 5s - loss: 3.6208e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4501 - val_raw_multi_label_accuracy: 0.3310\n",
      "Epoch 128/1000\n",
      " - 4s - loss: 3.5106e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4567 - val_raw_multi_label_accuracy: 0.3286\n",
      "Epoch 129/1000\n",
      " - 4s - loss: 3.4168e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4602 - val_raw_multi_label_accuracy: 0.3314\n",
      "Epoch 130/1000\n",
      " - 4s - loss: 3.3429e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4657 - val_raw_multi_label_accuracy: 0.3286\n",
      "Epoch 131/1000\n",
      " - 4s - loss: 3.2750e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4719 - val_raw_multi_label_accuracy: 0.3314\n",
      "Epoch 132/1000\n",
      " - 4s - loss: 3.1960e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4757 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 133/1000\n",
      " - 4s - loss: 3.1343e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4824 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 134/1000\n",
      " - 4s - loss: 3.0475e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4869 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 135/1000\n",
      " - 4s - loss: 2.9518e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4905 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 136/1000\n",
      " - 4s - loss: 2.8953e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.4953 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 137/1000\n",
      " - 4s - loss: 2.8221e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5017 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 138/1000\n",
      " - 4s - loss: 2.7588e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5056 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 139/1000\n",
      " - 4s - loss: 2.7186e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5104 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 140/1000\n",
      " - 4s - loss: 2.6698e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5164 - val_raw_multi_label_accuracy: 0.3286\n",
      "Epoch 141/1000\n",
      " - 4s - loss: 2.5758e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5207 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 142/1000\n",
      " - 4s - loss: 2.5133e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5256 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 143/1000\n",
      " - 4s - loss: 2.4570e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5300 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 144/1000\n",
      " - 4s - loss: 2.4042e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5335 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 145/1000\n",
      " - 4s - loss: 2.3605e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5387 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 146/1000\n",
      " - 4s - loss: 2.3204e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5422 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 147/1000\n",
      " - 4s - loss: 2.2463e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5473 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 148/1000\n",
      " - 4s - loss: 2.2185e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5506 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 149/1000\n",
      " - 4s - loss: 2.1787e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5563 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 150/1000\n",
      " - 4s - loss: 2.1303e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5576 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 151/1000\n",
      " - 4s - loss: 2.0602e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5640 - val_raw_multi_label_accuracy: 0.3319\n",
      "Epoch 152/1000\n",
      " - 4s - loss: 2.0163e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5667 - val_raw_multi_label_accuracy: 0.3323\n",
      "Epoch 153/1000\n",
      " - 5s - loss: 1.9795e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5724 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 154/1000\n",
      " - 4s - loss: 1.9361e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5789 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 155/1000\n",
      " - 4s - loss: 1.9010e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5796 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 156/1000\n",
      " - 4s - loss: 1.8539e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5838 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 157/1000\n",
      " - 4s - loss: 1.8213e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5898 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 158/1000\n",
      " - 4s - loss: 1.8045e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5914 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 159/1000\n",
      " - 4s - loss: 1.7886e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.5973 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 160/1000\n",
      " - 4s - loss: 1.7151e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6008 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 161/1000\n",
      " - 4s - loss: 1.6739e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6017 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 162/1000\n",
      " - 4s - loss: 1.6418e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6086 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 163/1000\n",
      " - 4s - loss: 1.6013e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6131 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 164/1000\n",
      " - 5s - loss: 1.5961e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6150 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 165/1000\n",
      " - 5s - loss: 1.5388e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6196 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 166/1000\n",
      " - 5s - loss: 1.5137e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6257 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 167/1000\n",
      " - 4s - loss: 1.4819e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6262 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 168/1000\n",
      " - 4s - loss: 1.4548e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6293 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 169/1000\n",
      " - 4s - loss: 1.4169e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6347 - val_raw_multi_label_accuracy: 0.3323\n",
      "Epoch 170/1000\n",
      " - 4s - loss: 1.4037e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6364 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 171/1000\n",
      " - 4s - loss: 1.3718e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6409 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 172/1000\n",
      " - 4s - loss: 1.3448e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6450 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 173/1000\n",
      " - 4s - loss: 1.3118e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6483 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 174/1000\n",
      " - 4s - loss: 1.2885e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6523 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 175/1000\n",
      " - 4s - loss: 1.2624e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6528 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 176/1000\n",
      " - 4s - loss: 1.2402e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6585 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 177/1000\n",
      " - 4s - loss: 1.2152e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6625 - val_raw_multi_label_accuracy: 0.3342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000\n",
      " - 4s - loss: 1.1946e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6668 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 179/1000\n",
      " - 4s - loss: 1.1681e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6682 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 180/1000\n",
      " - 4s - loss: 1.1498e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6725 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 181/1000\n",
      " - 4s - loss: 1.1283e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6753 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 182/1000\n",
      " - 4s - loss: 1.1079e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6791 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 183/1000\n",
      " - 4s - loss: 1.0977e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6835 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 184/1000\n",
      " - 4s - loss: 1.0643e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6852 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 185/1000\n",
      " - 4s - loss: 1.0514e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6889 - val_raw_multi_label_accuracy: 0.3323\n",
      "Epoch 186/1000\n",
      " - 4s - loss: 1.0332e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6911 - val_raw_multi_label_accuracy: 0.3323\n",
      "Epoch 187/1000\n",
      " - 4s - loss: 1.0113e-05 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6950 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 188/1000\n",
      " - 4s - loss: 9.9929e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.6966 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 189/1000\n",
      " - 4s - loss: 9.7511e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7003 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 190/1000\n",
      " - 4s - loss: 9.5835e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7038 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 191/1000\n",
      " - 4s - loss: 9.4317e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7072 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 192/1000\n",
      " - 4s - loss: 9.3453e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7098 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 193/1000\n",
      " - 4s - loss: 9.0918e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7144 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 194/1000\n",
      " - 4s - loss: 8.9040e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7162 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 195/1000\n",
      " - 4s - loss: 8.7045e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7175 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 196/1000\n",
      " - 4s - loss: 8.6251e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7214 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 197/1000\n",
      " - 4s - loss: 8.5070e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7242 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 198/1000\n",
      " - 4s - loss: 8.4018e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7280 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 199/1000\n",
      " - 4s - loss: 8.2652e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7318 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 200/1000\n",
      " - 4s - loss: 7.9888e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7323 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 201/1000\n",
      " - 4s - loss: 7.8329e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7368 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 202/1000\n",
      " - 4s - loss: 7.7352e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7379 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 203/1000\n",
      " - 4s - loss: 7.5581e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7412 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 204/1000\n",
      " - 4s - loss: 7.4405e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7443 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 205/1000\n",
      " - 4s - loss: 7.3047e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7463 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 206/1000\n",
      " - 4s - loss: 7.2097e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7506 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 207/1000\n",
      " - 4s - loss: 7.0629e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7523 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 208/1000\n",
      " - 4s - loss: 6.9619e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7547 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 209/1000\n",
      " - 4s - loss: 6.9277e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7587 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 210/1000\n",
      " - 4s - loss: 6.7151e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7607 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 211/1000\n",
      " - 4s - loss: 6.6264e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7623 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 212/1000\n",
      " - 4s - loss: 6.5121e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7666 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 213/1000\n",
      " - 4s - loss: 6.3887e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7685 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 214/1000\n",
      " - 4s - loss: 6.3057e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7705 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 215/1000\n",
      " - 4s - loss: 6.2318e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7739 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 216/1000\n",
      " - 4s - loss: 6.1002e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7738 - val_raw_multi_label_accuracy: 0.3328\n",
      "Epoch 217/1000\n",
      " - 4s - loss: 5.9994e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7773 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 218/1000\n",
      " - 4s - loss: 5.8711e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7810 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 219/1000\n",
      " - 4s - loss: 5.7820e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7837 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 220/1000\n",
      " - 4s - loss: 5.6981e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7865 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 221/1000\n",
      " - 4s - loss: 5.5865e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7890 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 222/1000\n",
      " - 4s - loss: 5.5206e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7913 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 223/1000\n",
      " - 4s - loss: 5.4202e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7933 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 224/1000\n",
      " - 4s - loss: 5.3053e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7961 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 225/1000\n",
      " - 4s - loss: 5.2113e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.7990 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 226/1000\n",
      " - 4s - loss: 5.1466e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8020 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 227/1000\n",
      " - 4s - loss: 5.0664e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8039 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 228/1000\n",
      " - 4s - loss: 5.0025e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8065 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 229/1000\n",
      " - 4s - loss: 4.8930e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8079 - val_raw_multi_label_accuracy: 0.3342\n",
      "Epoch 230/1000\n",
      " - 4s - loss: 4.8541e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8119 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 231/1000\n",
      " - 4s - loss: 4.7446e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8140 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 232/1000\n",
      " - 4s - loss: 4.6490e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8156 - val_raw_multi_label_accuracy: 0.3361\n",
      "Epoch 233/1000\n",
      " - 4s - loss: 4.5915e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8175 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 234/1000\n",
      " - 4s - loss: 4.5219e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8213 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 235/1000\n",
      " - 4s - loss: 4.4284e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8232 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 236/1000\n",
      " - 4s - loss: 4.3589e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8270 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 237/1000\n",
      " - 4s - loss: 4.2954e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8271 - val_raw_multi_label_accuracy: 0.3337\n",
      "Epoch 238/1000\n",
      " - 4s - loss: 4.2243e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8308 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 239/1000\n",
      " - 4s - loss: 4.1539e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8330 - val_raw_multi_label_accuracy: 0.3351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000\n",
      " - 4s - loss: 4.1022e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8352 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 241/1000\n",
      " - 4s - loss: 4.0240e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8386 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 242/1000\n",
      " - 4s - loss: 3.9596e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8391 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 243/1000\n",
      " - 4s - loss: 3.9248e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8418 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 244/1000\n",
      " - 4s - loss: 3.8538e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8447 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 245/1000\n",
      " - 4s - loss: 3.8090e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8465 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 246/1000\n",
      " - 4s - loss: 3.7181e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8490 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 247/1000\n",
      " - 4s - loss: 3.6625e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8523 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 248/1000\n",
      " - 4s - loss: 3.5908e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8534 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 249/1000\n",
      " - 4s - loss: 3.5385e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8543 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 250/1000\n",
      " - 4s - loss: 3.4918e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8571 - val_raw_multi_label_accuracy: 0.3346\n",
      "Epoch 251/1000\n",
      " - 4s - loss: 3.4307e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8590 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 252/1000\n",
      " - 4s - loss: 3.3934e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8616 - val_raw_multi_label_accuracy: 0.3356\n",
      "Epoch 253/1000\n",
      " - 4s - loss: 3.3505e-06 - raw_multi_label_accuracy: 1.0000 - val_loss: 3.8635 - val_raw_multi_label_accuracy: 0.3342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13cbd66a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model_lstm = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=100, trainable=True)\n",
    "model_lstm.add(e)\n",
    "model_lstm.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_lstm.add(MaxPooling1D())\n",
    "model_lstm.add(LSTM(100))\n",
    "model_lstm.add(Dense(256, activation='relu'))\n",
    "model_lstm.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "print(model_lstm.summary())\n",
    "#model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
    "model_lstm.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 10, delay=250)], epochs=1000, batch_size=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_lstm.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3518807870370373"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4586086956521741"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5240740740740741"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 64.09143518518519\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.625\n",
      "Precision for Action-Adventure: 0.4425531914893617\n",
      "Recall for Action-Adventure: 0.5502645502645502\n",
      "\n",
      "Accuruacy for Romance: 0.7239583333333334\n",
      "Precision for Romance: 0.3135593220338983\n",
      "Recall for Romance: 0.3217391304347826\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.6388888888888888\n",
      "Precision for Horror-Thriller: 0.46859903381642515\n",
      "Recall for Horror-Thriller: 0.49743589743589745\n",
      "\n",
      "Accuruacy for Comedy: 0.5607638888888888\n",
      "Precision for Comedy: 0.38235294117647056\n",
      "Recall for Comedy: 0.4619289340101523\n",
      "\n",
      "Accuruacy for Science Fiction: 0.7395833333333334\n",
      "Precision for Science Fiction: 0.25510204081632654\n",
      "Recall for Science Fiction: 0.24509803921568626\n",
      "\n",
      "Accuruacy for Drama: 0.5572916666666666\n",
      "Precision for Drama: 0.547752808988764\n",
      "Recall for Drama: 0.6747404844290658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
