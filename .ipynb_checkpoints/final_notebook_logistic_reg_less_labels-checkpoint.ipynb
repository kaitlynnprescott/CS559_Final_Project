{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse each row to get label vectors from json\n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dictionary for genre to its index in label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "#genre_dict['Drama'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map original labels to more coarse grained labels\n",
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "#genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation, remove stopwords\n",
    "def cleanText(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    text = ' '.join(no_stopword_text)\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)\n",
    "all_data = all_data[all_data.genres_vect.map(sum) > 0] #remove rows that don't have labels anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split and getting text features and labels vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.cleanOverview\n",
    "X_test = test.cleanOverview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels from array of lists to numpy array\n",
    "\n",
    "train_targets_arr = train['genres_vect'].tolist()\n",
    "train_targets_arr = np.array(train_targets_arr)\n",
    "\n",
    "test_targets_arr = test['genres_vect'].tolist()\n",
    "test_targets_arr = np.array(test_targets_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define class that will do multilabel logistic regression by wrapping Pipelines of tfidf and OneVsRest Logistic Regression Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelLogisitcRegression():\n",
    "    def __init__(self, genre_dict):\n",
    "        self.genre_dict = genre_dict\n",
    "        self.pipelines = {}\n",
    "        for category in self.genre_dict.keys():\n",
    "            self.pipelines[category]=Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear', multi_class='ovr'), n_jobs=1)),\n",
    "            ])\n",
    "        \n",
    "    def fit(self, X_train, train_targets_arr):\n",
    "        start = time.time()\n",
    "        for category in self.genre_dict.keys():\n",
    "            print('Processing {}'.format(category))\n",
    "            self.pipelines[category].fit(X_train, train_targets_arr[:,genre_dict[category]])\n",
    "        end = time.time()\n",
    "        print('Time to train ' + str(end-start) + ' seconds')\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        Ret = np.zeros((X_test.shape[0],len(self.genre_dict.keys())), dtype='int')\n",
    "        for category in self.genre_dict.keys():\n",
    "            try:\n",
    "                prediction = self.pipelines[category].predict(X_test)\n",
    "            except: #exception we get is it was trained with data taht was only 0 label during cross validation\n",
    "                prediction = np.zeros(X_test.shape[0], dtype=int)\n",
    "            Ret[:,self.genre_dict[category]] = prediction\n",
    "        return Ret\n",
    "    \n",
    "    #unbalanced data so allow prediction with given threshold\n",
    "    def predict_threshold(self, X_test, threshold):\n",
    "        Ret = np.zeros((X_test.shape[0],len(self.genre_dict.keys())), dtype='int')\n",
    "        for category in self.genre_dict.keys():\n",
    "            try:\n",
    "                prediction = self.pipelines[category].predict_proba(X_test)[:,1]\n",
    "            except:#exception we get is it was trained with data taht was only 0 label during cross validation\n",
    "                prediction = np.zeros(X_test.shape[0], dtype=int)\n",
    "            prediction[prediction >=threshold] = 1\n",
    "            prediction[prediction < threshold] = 0\n",
    "            Ret[:,self.genre_dict[category]] = prediction\n",
    "        return Ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metric definitions and printing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(actual_labels, predictions):\n",
    "    print('Getting evaluation metrics for each label:')\n",
    "    get_per_label_metrics(actual_labels, predictions)\n",
    "    print('Getting evaluations for multilabel problem')\n",
    "    print('Multilabel accuracy: ' + str(multi_label_accuracy(actual_labels, predictions)))\n",
    "    print('Multilabel precision: ' + str(multi_label_precision(actual_labels, predictions)))\n",
    "    print('Multilabel recall: ' + str(multi_label_recall(actual_labels, predictions)))\n",
    "    print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(actual_labels, predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.2939398288726807 seconds\n"
     ]
    }
   ],
   "source": [
    "multi = MultiLabelLogisitcRegression(genre_dict)\n",
    "multi.fit(X_train, train_targets_arr)\n",
    "results = multi.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.7329192546583851\n",
      "Precision for Action-Adventure: 0.8452380952380952\n",
      "Recall for Action-Adventure: 0.37967914438502676\n",
      "\n",
      "Accuruacy for Romance: 0.7929606625258799\n",
      "Precision for Romance: 0.8\n",
      "Recall for Romance: 0.07547169811320754\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.7060041407867494\n",
      "Precision for Horror-Thriller: 0.8125\n",
      "Recall for Horror-Thriller: 0.3385416666666667\n",
      "\n",
      "Accuruacy for Comedy: 0.7163561076604554\n",
      "Precision for Comedy: 0.8275862068965517\n",
      "Recall for Comedy: 0.4507042253521127\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8840579710144928\n",
      "Precision for Science Fiction: 0.0\n",
      "Recall for Science Fiction: 0.0\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.32263630089717044\n",
      "Multilabel precision: 0.8287401574803149\n",
      "Multilabel recall: 0.33402346445824704\n",
      "Percent of correctly decided label decisions: 76.64596273291926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(test_targets_arr, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the poor multilabel metrics despite high accuracy on each label when considered alone. Do cross validation to find better threshold than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross validation with threshold\n",
    "def kFoldCrossValidation(X, y, folds, threshold):\n",
    "    print(\"Doing cross validation for threshold = \" + str(threshold))\n",
    "    held_out_size = len(X)//folds\n",
    "    multi_label_acc = 0\n",
    "    for i in range(folds):\n",
    "        print(\"Iteration \" + str(i+1) + \" of \" + str(folds) + \" fold cross validation\")\n",
    "        held_out_index = i*held_out_size\n",
    "        if i == folds-1:\n",
    "            held_out_data = X[held_out_index:]\n",
    "            held_out_y = y[held_out_index:]\n",
    "            iter_training_data = X[0:held_out_index]\n",
    "            iter_y = y[0:held_out_index]\n",
    "        else:\n",
    "            held_out_data = X[held_out_index:held_out_index+held_out_size]\n",
    "            held_out_y = y[held_out_index:held_out_index+held_out_size]\n",
    "            iter_training_data = np.append(X[0:held_out_index], X[held_out_index+held_out_size:], axis=0)\n",
    "            iter_y = np.append(y[0:held_out_index], y[held_out_index+held_out_size:], axis=0)\n",
    "        multi = MultiLabelLogisitcRegression(genre_dict)\n",
    "        multi.fit(iter_training_data, iter_y)\n",
    "        predictions = multi.predict_threshold(held_out_data, threshold)\n",
    "        multi_label_acc += multi_label_accuracy(held_out_y, predictions)\n",
    "    return multi_label_acc / folds #sum accross all folds and divide by number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing cross validation for threshold = 0.3\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.7646288871765137 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.383296251296997 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.1372418403625488 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.1141643524169922 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.1143434047698975 seconds\n",
      "Accuracy: 0.47339542937521173\n",
      "Doing cross validation for threshold = 0.35\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 0.9287738800048828 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.5149688720703125 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.46659517288208 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.4859998226165771 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.6424334049224854 seconds\n",
      "Accuracy: 0.5176524580239661\n",
      "Doing cross validation for threshold = 0.39999999999999997\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.543119192123413 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.804244041442871 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.4973127841949463 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.652686357498169 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.130579948425293 seconds\n",
      "Accuracy: 0.5099665260046652\n",
      "Doing cross validation for threshold = 0.44999999999999996\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.5697953701019287 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.405266523361206 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.396131992340088 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.389392614364624 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.564023733139038 seconds\n",
      "Accuracy: 0.40648603172907427\n",
      "Doing cross validation for threshold = 0.49999999999999994\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.4382638931274414 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.6410396099090576 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.4672725200653076 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.6176419258117676 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.715235710144043 seconds\n",
      "Accuracy: 0.2565588109609529\n",
      "Doing cross validation for threshold = 0.5499999999999999\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.6627109050750732 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.0550646781921387 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.6072158813476562 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.932636022567749 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.68949294090271 seconds\n",
      "Accuracy: 0.13215239570535764\n",
      "Doing cross validation for threshold = 0.6\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.87823486328125 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.144922971725464 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.8272790908813477 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.8798954486846924 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.203359842300415 seconds\n",
      "Accuracy: 0.06426072325196303\n",
      "Doing cross validation for threshold = 0.65\n",
      "Iteration 1 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.231496572494507 seconds\n",
      "Iteration 2 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.836209774017334 seconds\n",
      "Iteration 3 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.770569086074829 seconds\n",
      "Iteration 4 of 5 fold cross validation\n",
      "Processing Action-Adventure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.0791893005371094 seconds\n",
      "Iteration 5 of 5 fold cross validation\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 1.814835786819458 seconds\n",
      "Accuracy: 0.020619446966864304\n",
      "Time to run k fold cross validation to find best threshold 77.79013562202454\n"
     ]
    }
   ],
   "source": [
    "#find best threshold looking from .3 to .7 in ntervals of .05\n",
    "test_threshold = .3\n",
    "best_threshold_acc = 0\n",
    "best_threshold = .5 #default is .5\n",
    "start = time.time()\n",
    "while test_threshold <= .7:\n",
    "    acc = kFoldCrossValidation(X_train, train_targets_arr, 5, test_threshold)\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    if acc > best_threshold_acc:\n",
    "        best_threshold_acc = acc\n",
    "        best_threshold = test_threshold\n",
    "    test_threshold += .05\n",
    "end = time.time()\n",
    "print('Time to run k fold cross validation to find best threshold ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for multilabel accuracy: 0.35\n",
      "Processing Action-Adventure\n",
      "Processing Romance\n",
      "Processing Horror-Thriller\n",
      "Processing Comedy\n",
      "Processing Science Fiction\n",
      "Time to train 2.4129831790924072 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Best threshold for multilabel accuracy: ' + str(best_threshold))\n",
    "classifier = MultiLabelLogisitcRegression(genre_dict)\n",
    "classifier.fit(X_train, train_targets_arr)\n",
    "predictions = multi.predict_threshold(X_test, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.7204968944099379\n",
      "Precision for Action-Adventure: 0.5935251798561151\n",
      "Recall for Action-Adventure: 0.8823529411764706\n",
      "\n",
      "Accuruacy for Romance: 0.8115942028985508\n",
      "Precision for Romance: 0.6829268292682927\n",
      "Recall for Romance: 0.2641509433962264\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.7060041407867494\n",
      "Precision for Horror-Thriller: 0.5919117647058824\n",
      "Recall for Horror-Thriller: 0.8385416666666666\n",
      "\n",
      "Accuruacy for Comedy: 0.6542443064182195\n",
      "Precision for Comedy: 0.5701219512195121\n",
      "Recall for Comedy: 0.8779342723004695\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8861283643892339\n",
      "Precision for Science Fiction: 0.6666666666666666\n",
      "Recall for Science Fiction: 0.03571428571428571\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.5381297446514844\n",
      "Multilabel precision: 0.621968121968122\n",
      "Multilabel recall: 0.7555210489993098\n",
      "Percent of correctly decided label decisions: 75.56935817805383\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(test_targets_arr, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
