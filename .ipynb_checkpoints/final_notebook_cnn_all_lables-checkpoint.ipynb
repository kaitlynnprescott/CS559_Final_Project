{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'War': 0,\n",
       " 'Family': 1,\n",
       " 'Science Fiction': 2,\n",
       " 'Thriller': 3,\n",
       " 'Horror': 4,\n",
       " 'Romance': 5,\n",
       " 'Drama': 6,\n",
       " 'Foreign': 7,\n",
       " 'Documentary': 8,\n",
       " 'Fantasy': 9,\n",
       " 'Western': 10,\n",
       " 'History': 11,\n",
       " 'Comedy': 12,\n",
       " 'Action': 13,\n",
       " 'Adventure': 14,\n",
       " 'Animation': 15,\n",
       " 'Crime': 16,\n",
       " 'Music': 17,\n",
       " 'TV Movie': 18,\n",
       " 'Mystery': 19}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {'War': 0,\n",
    " 'Family': 1,\n",
    " 'Science Fiction': 2,\n",
    " 'Thriller': 3,\n",
    " 'Horror': 4,\n",
    " 'Romance': 5,\n",
    " 'Drama': 6,\n",
    " 'Foreign': 7,\n",
    " 'Documentary': 8,\n",
    " 'Fantasy': 9,\n",
    " 'Western': 10,\n",
    " 'History': 11,\n",
    " 'Comedy': 12,\n",
    " 'Action': 13,\n",
    " 'Adventure': 14,\n",
    " 'Animation': 15,\n",
    " 'Crime': 16,\n",
    " 'Music': 17,\n",
    " 'TV Movie': 18,\n",
    " 'Mystery': 19}\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mapping to coarse grained labels (in this situation we don't do that so labels map to self)\n",
    "genre_map = {'War': 'War',\n",
    " 'Family': 'Family',\n",
    " 'Science Fiction': 'Science Fiction',\n",
    " 'Thriller': 'Thriller',\n",
    " 'Horror': 'Horror',\n",
    " 'Romance': 'Romance',\n",
    " 'Drama': 'Drama',\n",
    " 'Foreign': 'Foreign',\n",
    " 'Documentary': 'Documentary',\n",
    " 'Fantasy': 'Fantasy',\n",
    " 'Western': 'Western',\n",
    " 'History': 'History',\n",
    " 'Comedy': 'Comedy',\n",
    " 'Action': 'Action',\n",
    " 'Adventure': 'Adventure',\n",
    " 'Animation': 'Animation',\n",
    " 'Crime': 'Crime',\n",
    " 'Music': 'Music',\n",
    " 'TV Movie': 'TV Movie',\n",
    " 'Mystery': 'Mystery'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    text = ' '.join(no_stopword_text)\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN STUFF here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 2, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 150\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 1.9547 - raw_multi_label_accuracy: 0.1290 - val_loss: 1.4882 - val_raw_multi_label_accuracy: 0.0580\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 1.3078 - raw_multi_label_accuracy: 0.1388 - val_loss: 0.9984 - val_raw_multi_label_accuracy: 0.1164\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 0.9113 - raw_multi_label_accuracy: 0.1282 - val_loss: 0.7192 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 0.6759 - raw_multi_label_accuracy: 0.1285 - val_loss: 0.5543 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.5361 - raw_multi_label_accuracy: 0.1221 - val_loss: 0.4538 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 0.4524 - raw_multi_label_accuracy: 0.1290 - val_loss: 0.3974 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 0.4052 - raw_multi_label_accuracy: 0.1099 - val_loss: 0.3649 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.3764 - raw_multi_label_accuracy: 0.1079 - val_loss: 0.3467 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.3589 - raw_multi_label_accuracy: 0.1150 - val_loss: 0.3368 - val_raw_multi_label_accuracy: 0.1643\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.3491 - raw_multi_label_accuracy: 0.1051 - val_loss: 0.3304 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.3428 - raw_multi_label_accuracy: 0.1120 - val_loss: 0.3271 - val_raw_multi_label_accuracy: 0.1643\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 0.3377 - raw_multi_label_accuracy: 0.0985 - val_loss: 0.3245 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 13/1000\n",
      " - 2s - loss: 0.3347 - raw_multi_label_accuracy: 0.1145 - val_loss: 0.3235 - val_raw_multi_label_accuracy: 0.1704\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 0.3329 - raw_multi_label_accuracy: 0.0914 - val_loss: 0.3228 - val_raw_multi_label_accuracy: 0.1702\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.3316 - raw_multi_label_accuracy: 0.1178 - val_loss: 0.3214 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.3289 - raw_multi_label_accuracy: 0.0905 - val_loss: 0.3206 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.3265 - raw_multi_label_accuracy: 0.1180 - val_loss: 0.3201 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.3271 - raw_multi_label_accuracy: 0.0969 - val_loss: 0.3200 - val_raw_multi_label_accuracy: 0.1702\n",
      "Epoch 19/1000\n",
      " - 2s - loss: 0.3255 - raw_multi_label_accuracy: 0.1158 - val_loss: 0.3196 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 0.3235 - raw_multi_label_accuracy: 0.1044 - val_loss: 0.3195 - val_raw_multi_label_accuracy: 0.1250\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.3212 - raw_multi_label_accuracy: 0.1119 - val_loss: 0.3197 - val_raw_multi_label_accuracy: 0.1700\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.3202 - raw_multi_label_accuracy: 0.1122 - val_loss: 0.3203 - val_raw_multi_label_accuracy: 0.1702\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.3192 - raw_multi_label_accuracy: 0.1182 - val_loss: 0.3203 - val_raw_multi_label_accuracy: 0.1675\n",
      "Epoch 24/1000\n",
      " - 2s - loss: 0.3155 - raw_multi_label_accuracy: 0.1039 - val_loss: 0.3215 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 25/1000\n",
      " - 2s - loss: 0.3138 - raw_multi_label_accuracy: 0.1286 - val_loss: 0.3226 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 26/1000\n",
      " - 2s - loss: 0.3112 - raw_multi_label_accuracy: 0.1291 - val_loss: 0.3231 - val_raw_multi_label_accuracy: 0.1686\n",
      "Epoch 27/1000\n",
      " - 2s - loss: 0.3082 - raw_multi_label_accuracy: 0.1333 - val_loss: 0.3233 - val_raw_multi_label_accuracy: 0.1672\n",
      "Epoch 28/1000\n",
      " - 2s - loss: 0.3068 - raw_multi_label_accuracy: 0.1334 - val_loss: 0.3270 - val_raw_multi_label_accuracy: 0.1686\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.3051 - raw_multi_label_accuracy: 0.1426 - val_loss: 0.3254 - val_raw_multi_label_accuracy: 0.1672\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.3031 - raw_multi_label_accuracy: 0.1354 - val_loss: 0.3268 - val_raw_multi_label_accuracy: 0.1649\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.3025 - raw_multi_label_accuracy: 0.1349 - val_loss: 0.3254 - val_raw_multi_label_accuracy: 0.1619\n",
      "Epoch 32/1000\n",
      " - 2s - loss: 0.3004 - raw_multi_label_accuracy: 0.1364 - val_loss: 0.3275 - val_raw_multi_label_accuracy: 0.1559\n",
      "Epoch 33/1000\n",
      " - 2s - loss: 0.2990 - raw_multi_label_accuracy: 0.1371 - val_loss: 0.3280 - val_raw_multi_label_accuracy: 0.1524\n",
      "Epoch 34/1000\n",
      " - 2s - loss: 0.2987 - raw_multi_label_accuracy: 0.1339 - val_loss: 0.3299 - val_raw_multi_label_accuracy: 0.1602\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.2960 - raw_multi_label_accuracy: 0.1363 - val_loss: 0.3333 - val_raw_multi_label_accuracy: 0.1605\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.2945 - raw_multi_label_accuracy: 0.1368 - val_loss: 0.3332 - val_raw_multi_label_accuracy: 0.1530\n",
      "Epoch 37/1000\n",
      " - 2s - loss: 0.2923 - raw_multi_label_accuracy: 0.1396 - val_loss: 0.3355 - val_raw_multi_label_accuracy: 0.1464\n",
      "Epoch 38/1000\n",
      " - 2s - loss: 0.2925 - raw_multi_label_accuracy: 0.1332 - val_loss: 0.3318 - val_raw_multi_label_accuracy: 0.1425\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.2905 - raw_multi_label_accuracy: 0.1432 - val_loss: 0.3333 - val_raw_multi_label_accuracy: 0.1348\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.2901 - raw_multi_label_accuracy: 0.1381 - val_loss: 0.3365 - val_raw_multi_label_accuracy: 0.1445\n",
      "Epoch 41/1000\n",
      " - 2s - loss: 0.2890 - raw_multi_label_accuracy: 0.1378 - val_loss: 0.3381 - val_raw_multi_label_accuracy: 0.1460\n",
      "Epoch 42/1000\n",
      " - 2s - loss: 0.2870 - raw_multi_label_accuracy: 0.1443 - val_loss: 0.3361 - val_raw_multi_label_accuracy: 0.1377\n",
      "Epoch 43/1000\n",
      " - 2s - loss: 0.2850 - raw_multi_label_accuracy: 0.1499 - val_loss: 0.3408 - val_raw_multi_label_accuracy: 0.1471\n",
      "Epoch 44/1000\n",
      " - 2s - loss: 0.2845 - raw_multi_label_accuracy: 0.1568 - val_loss: 0.3377 - val_raw_multi_label_accuracy: 0.1444\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.2846 - raw_multi_label_accuracy: 0.1482 - val_loss: 0.3392 - val_raw_multi_label_accuracy: 0.1386\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.2827 - raw_multi_label_accuracy: 0.1565 - val_loss: 0.3354 - val_raw_multi_label_accuracy: 0.1390\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.2824 - raw_multi_label_accuracy: 0.1622 - val_loss: 0.3502 - val_raw_multi_label_accuracy: 0.1573\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.2820 - raw_multi_label_accuracy: 0.1700 - val_loss: 0.3442 - val_raw_multi_label_accuracy: 0.1486\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.2796 - raw_multi_label_accuracy: 0.1729 - val_loss: 0.3376 - val_raw_multi_label_accuracy: 0.1378\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.2792 - raw_multi_label_accuracy: 0.1657 - val_loss: 0.3392 - val_raw_multi_label_accuracy: 0.1395\n",
      "Epoch 51/1000\n",
      " - 2s - loss: 0.2773 - raw_multi_label_accuracy: 0.1777 - val_loss: 0.3403 - val_raw_multi_label_accuracy: 0.1499\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.2773 - raw_multi_label_accuracy: 0.1791 - val_loss: 0.3516 - val_raw_multi_label_accuracy: 0.1504\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.2758 - raw_multi_label_accuracy: 0.1815 - val_loss: 0.3410 - val_raw_multi_label_accuracy: 0.1374\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.2754 - raw_multi_label_accuracy: 0.1746 - val_loss: 0.3421 - val_raw_multi_label_accuracy: 0.1363\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 0.2751 - raw_multi_label_accuracy: 0.1764 - val_loss: 0.3604 - val_raw_multi_label_accuracy: 0.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      " - 2s - loss: 0.2738 - raw_multi_label_accuracy: 0.1803 - val_loss: 0.3402 - val_raw_multi_label_accuracy: 0.1338\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.2730 - raw_multi_label_accuracy: 0.1826 - val_loss: 0.3482 - val_raw_multi_label_accuracy: 0.1364\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 0.2729 - raw_multi_label_accuracy: 0.1860 - val_loss: 0.3529 - val_raw_multi_label_accuracy: 0.1495\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 0.2710 - raw_multi_label_accuracy: 0.1863 - val_loss: 0.3499 - val_raw_multi_label_accuracy: 0.1353\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.2706 - raw_multi_label_accuracy: 0.1831 - val_loss: 0.3566 - val_raw_multi_label_accuracy: 0.1470\n",
      "Epoch 61/1000\n",
      " - 2s - loss: 0.2710 - raw_multi_label_accuracy: 0.1888 - val_loss: 0.3438 - val_raw_multi_label_accuracy: 0.1240\n",
      "Epoch 62/1000\n",
      " - 2s - loss: 0.2696 - raw_multi_label_accuracy: 0.1914 - val_loss: 0.3535 - val_raw_multi_label_accuracy: 0.1391\n",
      "Epoch 63/1000\n",
      " - 2s - loss: 0.2691 - raw_multi_label_accuracy: 0.1871 - val_loss: 0.3572 - val_raw_multi_label_accuracy: 0.1404\n",
      "Epoch 64/1000\n",
      " - 2s - loss: 0.2700 - raw_multi_label_accuracy: 0.1848 - val_loss: 0.3572 - val_raw_multi_label_accuracy: 0.1440\n",
      "Epoch 65/1000\n",
      " - 2s - loss: 0.2675 - raw_multi_label_accuracy: 0.1938 - val_loss: 0.3546 - val_raw_multi_label_accuracy: 0.1442\n",
      "Epoch 66/1000\n",
      " - 2s - loss: 0.2681 - raw_multi_label_accuracy: 0.1836 - val_loss: 0.3597 - val_raw_multi_label_accuracy: 0.1415\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 0.2672 - raw_multi_label_accuracy: 0.1901 - val_loss: 0.3600 - val_raw_multi_label_accuracy: 0.1384\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.2657 - raw_multi_label_accuracy: 0.1920 - val_loss: 0.3615 - val_raw_multi_label_accuracy: 0.1360\n",
      "Epoch 69/1000\n",
      " - 2s - loss: 0.2662 - raw_multi_label_accuracy: 0.1881 - val_loss: 0.3640 - val_raw_multi_label_accuracy: 0.1426\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.2646 - raw_multi_label_accuracy: 0.1889 - val_loss: 0.3646 - val_raw_multi_label_accuracy: 0.1371\n",
      "Epoch 71/1000\n",
      " - 2s - loss: 0.2639 - raw_multi_label_accuracy: 0.1981 - val_loss: 0.3553 - val_raw_multi_label_accuracy: 0.1321\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.2635 - raw_multi_label_accuracy: 0.1881 - val_loss: 0.3668 - val_raw_multi_label_accuracy: 0.1389\n",
      "Epoch 73/1000\n",
      " - 2s - loss: 0.2638 - raw_multi_label_accuracy: 0.1849 - val_loss: 0.3693 - val_raw_multi_label_accuracy: 0.1401\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.2640 - raw_multi_label_accuracy: 0.1887 - val_loss: 0.3625 - val_raw_multi_label_accuracy: 0.1346\n",
      "Epoch 75/1000\n",
      " - 2s - loss: 0.2639 - raw_multi_label_accuracy: 0.1927 - val_loss: 0.3671 - val_raw_multi_label_accuracy: 0.1308\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 0.2618 - raw_multi_label_accuracy: 0.1868 - val_loss: 0.3650 - val_raw_multi_label_accuracy: 0.1306\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 0.2620 - raw_multi_label_accuracy: 0.1853 - val_loss: 0.3727 - val_raw_multi_label_accuracy: 0.1433\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 0.2615 - raw_multi_label_accuracy: 0.1947 - val_loss: 0.3666 - val_raw_multi_label_accuracy: 0.1344\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.2623 - raw_multi_label_accuracy: 0.1928 - val_loss: 0.3840 - val_raw_multi_label_accuracy: 0.1378\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.2611 - raw_multi_label_accuracy: 0.1823 - val_loss: 0.3832 - val_raw_multi_label_accuracy: 0.1416\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.2599 - raw_multi_label_accuracy: 0.1855 - val_loss: 0.3761 - val_raw_multi_label_accuracy: 0.1325\n",
      "Epoch 82/1000\n",
      " - 2s - loss: 0.2601 - raw_multi_label_accuracy: 0.1929 - val_loss: 0.3695 - val_raw_multi_label_accuracy: 0.1320\n",
      "Epoch 83/1000\n",
      " - 2s - loss: 0.2578 - raw_multi_label_accuracy: 0.1890 - val_loss: 0.3750 - val_raw_multi_label_accuracy: 0.1323\n",
      "Epoch 84/1000\n",
      " - 2s - loss: 0.2593 - raw_multi_label_accuracy: 0.1919 - val_loss: 0.3817 - val_raw_multi_label_accuracy: 0.1343\n",
      "Epoch 85/1000\n",
      " - 2s - loss: 0.2589 - raw_multi_label_accuracy: 0.1990 - val_loss: 0.3687 - val_raw_multi_label_accuracy: 0.1309\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.2594 - raw_multi_label_accuracy: 0.1956 - val_loss: 0.3787 - val_raw_multi_label_accuracy: 0.1334\n",
      "Epoch 87/1000\n",
      " - 2s - loss: 0.2574 - raw_multi_label_accuracy: 0.1973 - val_loss: 0.3801 - val_raw_multi_label_accuracy: 0.1350\n",
      "Epoch 88/1000\n",
      " - 2s - loss: 0.2567 - raw_multi_label_accuracy: 0.1979 - val_loss: 0.3814 - val_raw_multi_label_accuracy: 0.1353\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.2572 - raw_multi_label_accuracy: 0.1976 - val_loss: 0.3728 - val_raw_multi_label_accuracy: 0.1329\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 0.2583 - raw_multi_label_accuracy: 0.2033 - val_loss: 0.3892 - val_raw_multi_label_accuracy: 0.1333\n",
      "Epoch 91/1000\n",
      " - 2s - loss: 0.2562 - raw_multi_label_accuracy: 0.2057 - val_loss: 0.3885 - val_raw_multi_label_accuracy: 0.1424\n",
      "Epoch 92/1000\n",
      " - 2s - loss: 0.2560 - raw_multi_label_accuracy: 0.2061 - val_loss: 0.3944 - val_raw_multi_label_accuracy: 0.1390\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 0.2555 - raw_multi_label_accuracy: 0.2083 - val_loss: 0.3865 - val_raw_multi_label_accuracy: 0.1393\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 0.2553 - raw_multi_label_accuracy: 0.2103 - val_loss: 0.3850 - val_raw_multi_label_accuracy: 0.1360\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.2551 - raw_multi_label_accuracy: 0.2193 - val_loss: 0.3968 - val_raw_multi_label_accuracy: 0.1513\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.2549 - raw_multi_label_accuracy: 0.2225 - val_loss: 0.3857 - val_raw_multi_label_accuracy: 0.1490\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 0.2548 - raw_multi_label_accuracy: 0.2222 - val_loss: 0.3878 - val_raw_multi_label_accuracy: 0.1434\n",
      "Epoch 98/1000\n",
      " - 1s - loss: 0.2532 - raw_multi_label_accuracy: 0.2321 - val_loss: 0.4009 - val_raw_multi_label_accuracy: 0.1529\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.2530 - raw_multi_label_accuracy: 0.2233 - val_loss: 0.4114 - val_raw_multi_label_accuracy: 0.1556\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.2528 - raw_multi_label_accuracy: 0.2347 - val_loss: 0.3750 - val_raw_multi_label_accuracy: 0.1346\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.2524 - raw_multi_label_accuracy: 0.2369 - val_loss: 0.4115 - val_raw_multi_label_accuracy: 0.1542\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.2521 - raw_multi_label_accuracy: 0.2391 - val_loss: 0.3816 - val_raw_multi_label_accuracy: 0.1428\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.2532 - raw_multi_label_accuracy: 0.2386 - val_loss: 0.4171 - val_raw_multi_label_accuracy: 0.1611\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.2526 - raw_multi_label_accuracy: 0.2352 - val_loss: 0.3988 - val_raw_multi_label_accuracy: 0.1551\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 0.2515 - raw_multi_label_accuracy: 0.2466 - val_loss: 0.3956 - val_raw_multi_label_accuracy: 0.1533\n",
      "Epoch 106/1000\n",
      " - 2s - loss: 0.2506 - raw_multi_label_accuracy: 0.2527 - val_loss: 0.4134 - val_raw_multi_label_accuracy: 0.1656\n",
      "Epoch 107/1000\n",
      " - 2s - loss: 0.2488 - raw_multi_label_accuracy: 0.2579 - val_loss: 0.3927 - val_raw_multi_label_accuracy: 0.1561\n",
      "Epoch 108/1000\n",
      " - 2s - loss: 0.2486 - raw_multi_label_accuracy: 0.2488 - val_loss: 0.3950 - val_raw_multi_label_accuracy: 0.1575\n",
      "Epoch 109/1000\n",
      " - 2s - loss: 0.2461 - raw_multi_label_accuracy: 0.2548 - val_loss: 0.4095 - val_raw_multi_label_accuracy: 0.1603\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.2472 - raw_multi_label_accuracy: 0.2629 - val_loss: 0.3941 - val_raw_multi_label_accuracy: 0.1607\n",
      "Epoch 111/1000\n",
      " - 2s - loss: 0.2472 - raw_multi_label_accuracy: 0.2681 - val_loss: 0.4143 - val_raw_multi_label_accuracy: 0.1661\n",
      "Epoch 112/1000\n",
      " - 2s - loss: 0.2479 - raw_multi_label_accuracy: 0.2604 - val_loss: 0.4142 - val_raw_multi_label_accuracy: 0.1636\n",
      "Epoch 113/1000\n",
      " - 2s - loss: 0.2470 - raw_multi_label_accuracy: 0.2721 - val_loss: 0.4039 - val_raw_multi_label_accuracy: 0.1586\n",
      "Epoch 114/1000\n",
      " - 2s - loss: 0.2455 - raw_multi_label_accuracy: 0.2750 - val_loss: 0.4015 - val_raw_multi_label_accuracy: 0.1658\n",
      "Epoch 115/1000\n",
      " - 2s - loss: 0.2448 - raw_multi_label_accuracy: 0.2735 - val_loss: 0.4137 - val_raw_multi_label_accuracy: 0.1771\n",
      "Epoch 116/1000\n",
      " - 2s - loss: 0.2442 - raw_multi_label_accuracy: 0.2821 - val_loss: 0.4166 - val_raw_multi_label_accuracy: 0.1712\n",
      "Epoch 117/1000\n",
      " - 2s - loss: 0.2445 - raw_multi_label_accuracy: 0.2756 - val_loss: 0.4239 - val_raw_multi_label_accuracy: 0.1766\n",
      "Epoch 118/1000\n",
      " - 2s - loss: 0.2433 - raw_multi_label_accuracy: 0.2867 - val_loss: 0.4107 - val_raw_multi_label_accuracy: 0.1693\n",
      "Epoch 119/1000\n",
      " - 2s - loss: 0.2432 - raw_multi_label_accuracy: 0.2805 - val_loss: 0.4287 - val_raw_multi_label_accuracy: 0.1695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      " - 2s - loss: 0.2427 - raw_multi_label_accuracy: 0.2848 - val_loss: 0.4160 - val_raw_multi_label_accuracy: 0.1852\n",
      "Epoch 121/1000\n",
      " - 2s - loss: 0.2423 - raw_multi_label_accuracy: 0.2888 - val_loss: 0.4088 - val_raw_multi_label_accuracy: 0.1664\n",
      "Epoch 122/1000\n",
      " - 2s - loss: 0.2431 - raw_multi_label_accuracy: 0.2855 - val_loss: 0.4176 - val_raw_multi_label_accuracy: 0.1767\n",
      "Epoch 123/1000\n",
      " - 2s - loss: 0.2421 - raw_multi_label_accuracy: 0.2886 - val_loss: 0.4221 - val_raw_multi_label_accuracy: 0.1803\n",
      "Epoch 124/1000\n",
      " - 2s - loss: 0.2415 - raw_multi_label_accuracy: 0.2927 - val_loss: 0.4448 - val_raw_multi_label_accuracy: 0.1819\n",
      "Epoch 125/1000\n",
      " - 2s - loss: 0.2413 - raw_multi_label_accuracy: 0.2883 - val_loss: 0.4253 - val_raw_multi_label_accuracy: 0.1771\n",
      "Epoch 126/1000\n",
      " - 2s - loss: 0.2398 - raw_multi_label_accuracy: 0.2949 - val_loss: 0.4126 - val_raw_multi_label_accuracy: 0.1790\n",
      "Epoch 127/1000\n",
      " - 2s - loss: 0.2408 - raw_multi_label_accuracy: 0.2921 - val_loss: 0.4464 - val_raw_multi_label_accuracy: 0.1846\n",
      "Epoch 128/1000\n",
      " - 2s - loss: 0.2393 - raw_multi_label_accuracy: 0.2978 - val_loss: 0.4303 - val_raw_multi_label_accuracy: 0.1789\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.2387 - raw_multi_label_accuracy: 0.2986 - val_loss: 0.4377 - val_raw_multi_label_accuracy: 0.1791\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.2390 - raw_multi_label_accuracy: 0.3021 - val_loss: 0.4411 - val_raw_multi_label_accuracy: 0.1797\n",
      "Epoch 131/1000\n",
      " - 2s - loss: 0.2376 - raw_multi_label_accuracy: 0.2954 - val_loss: 0.4250 - val_raw_multi_label_accuracy: 0.1750\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.2375 - raw_multi_label_accuracy: 0.3043 - val_loss: 0.4361 - val_raw_multi_label_accuracy: 0.1807\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.2362 - raw_multi_label_accuracy: 0.3042 - val_loss: 0.4311 - val_raw_multi_label_accuracy: 0.1823\n",
      "Epoch 134/1000\n",
      " - 2s - loss: 0.2367 - raw_multi_label_accuracy: 0.3055 - val_loss: 0.4471 - val_raw_multi_label_accuracy: 0.1907\n",
      "Epoch 135/1000\n",
      " - 2s - loss: 0.2362 - raw_multi_label_accuracy: 0.3080 - val_loss: 0.4428 - val_raw_multi_label_accuracy: 0.1806\n",
      "Epoch 136/1000\n",
      " - 2s - loss: 0.2352 - raw_multi_label_accuracy: 0.3072 - val_loss: 0.4192 - val_raw_multi_label_accuracy: 0.1733\n",
      "Epoch 137/1000\n",
      " - 2s - loss: 0.2345 - raw_multi_label_accuracy: 0.3125 - val_loss: 0.4461 - val_raw_multi_label_accuracy: 0.1896\n",
      "Epoch 138/1000\n",
      " - 1s - loss: 0.2333 - raw_multi_label_accuracy: 0.3109 - val_loss: 0.4482 - val_raw_multi_label_accuracy: 0.1830\n",
      "Epoch 139/1000\n",
      " - 1s - loss: 0.2332 - raw_multi_label_accuracy: 0.3192 - val_loss: 0.4545 - val_raw_multi_label_accuracy: 0.1873\n",
      "Epoch 140/1000\n",
      " - 2s - loss: 0.2337 - raw_multi_label_accuracy: 0.3178 - val_loss: 0.4733 - val_raw_multi_label_accuracy: 0.1845\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 0.2335 - raw_multi_label_accuracy: 0.3205 - val_loss: 0.4378 - val_raw_multi_label_accuracy: 0.1818\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.2329 - raw_multi_label_accuracy: 0.3179 - val_loss: 0.4523 - val_raw_multi_label_accuracy: 0.1806\n",
      "Epoch 143/1000\n",
      " - 2s - loss: 0.2322 - raw_multi_label_accuracy: 0.3170 - val_loss: 0.4442 - val_raw_multi_label_accuracy: 0.1812\n",
      "Epoch 144/1000\n",
      " - 1s - loss: 0.2309 - raw_multi_label_accuracy: 0.3224 - val_loss: 0.4410 - val_raw_multi_label_accuracy: 0.1847\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 0.2315 - raw_multi_label_accuracy: 0.3223 - val_loss: 0.4445 - val_raw_multi_label_accuracy: 0.1860\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.2306 - raw_multi_label_accuracy: 0.3242 - val_loss: 0.4615 - val_raw_multi_label_accuracy: 0.1921\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 0.2298 - raw_multi_label_accuracy: 0.3185 - val_loss: 0.4560 - val_raw_multi_label_accuracy: 0.1861\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 0.2301 - raw_multi_label_accuracy: 0.3214 - val_loss: 0.4491 - val_raw_multi_label_accuracy: 0.1990\n",
      "Epoch 149/1000\n",
      " - 2s - loss: 0.2294 - raw_multi_label_accuracy: 0.3316 - val_loss: 0.4560 - val_raw_multi_label_accuracy: 0.1888\n",
      "Epoch 150/1000\n",
      " - 1s - loss: 0.2293 - raw_multi_label_accuracy: 0.3302 - val_loss: 0.4475 - val_raw_multi_label_accuracy: 0.1925\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 0.2283 - raw_multi_label_accuracy: 0.3318 - val_loss: 0.4574 - val_raw_multi_label_accuracy: 0.1839\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 0.2271 - raw_multi_label_accuracy: 0.3330 - val_loss: 0.4553 - val_raw_multi_label_accuracy: 0.1771\n",
      "Epoch 153/1000\n",
      " - 2s - loss: 0.2268 - raw_multi_label_accuracy: 0.3312 - val_loss: 0.4804 - val_raw_multi_label_accuracy: 0.1839\n",
      "Epoch 154/1000\n",
      " - 1s - loss: 0.2277 - raw_multi_label_accuracy: 0.3347 - val_loss: 0.4689 - val_raw_multi_label_accuracy: 0.1851\n",
      "Epoch 155/1000\n",
      " - 2s - loss: 0.2278 - raw_multi_label_accuracy: 0.3329 - val_loss: 0.4822 - val_raw_multi_label_accuracy: 0.1954\n",
      "Epoch 156/1000\n",
      " - 1s - loss: 0.2263 - raw_multi_label_accuracy: 0.3329 - val_loss: 0.4674 - val_raw_multi_label_accuracy: 0.1899\n",
      "Epoch 157/1000\n",
      " - 2s - loss: 0.2265 - raw_multi_label_accuracy: 0.3426 - val_loss: 0.4605 - val_raw_multi_label_accuracy: 0.1851\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 0.2255 - raw_multi_label_accuracy: 0.3423 - val_loss: 0.4714 - val_raw_multi_label_accuracy: 0.1864\n",
      "Epoch 159/1000\n",
      " - 2s - loss: 0.2256 - raw_multi_label_accuracy: 0.3367 - val_loss: 0.4809 - val_raw_multi_label_accuracy: 0.1996\n",
      "Epoch 160/1000\n",
      " - 2s - loss: 0.2239 - raw_multi_label_accuracy: 0.3432 - val_loss: 0.4674 - val_raw_multi_label_accuracy: 0.1857\n",
      "Epoch 161/1000\n",
      " - 2s - loss: 0.2255 - raw_multi_label_accuracy: 0.3324 - val_loss: 0.4643 - val_raw_multi_label_accuracy: 0.1925\n",
      "Epoch 162/1000\n",
      " - 2s - loss: 0.2238 - raw_multi_label_accuracy: 0.3399 - val_loss: 0.4643 - val_raw_multi_label_accuracy: 0.1995\n",
      "Epoch 163/1000\n",
      " - 2s - loss: 0.2250 - raw_multi_label_accuracy: 0.3453 - val_loss: 0.4669 - val_raw_multi_label_accuracy: 0.2011\n",
      "Epoch 164/1000\n",
      " - 2s - loss: 0.2241 - raw_multi_label_accuracy: 0.3474 - val_loss: 0.4850 - val_raw_multi_label_accuracy: 0.2036\n",
      "Epoch 165/1000\n",
      " - 2s - loss: 0.2226 - raw_multi_label_accuracy: 0.3480 - val_loss: 0.4737 - val_raw_multi_label_accuracy: 0.1943\n",
      "Epoch 166/1000\n",
      " - 2s - loss: 0.2219 - raw_multi_label_accuracy: 0.3483 - val_loss: 0.4688 - val_raw_multi_label_accuracy: 0.1968\n",
      "Epoch 167/1000\n",
      " - 2s - loss: 0.2218 - raw_multi_label_accuracy: 0.3478 - val_loss: 0.4720 - val_raw_multi_label_accuracy: 0.1974\n",
      "Epoch 168/1000\n",
      " - 2s - loss: 0.2224 - raw_multi_label_accuracy: 0.3529 - val_loss: 0.4715 - val_raw_multi_label_accuracy: 0.1946\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 0.2227 - raw_multi_label_accuracy: 0.3463 - val_loss: 0.4818 - val_raw_multi_label_accuracy: 0.1999\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 0.2205 - raw_multi_label_accuracy: 0.3546 - val_loss: 0.4921 - val_raw_multi_label_accuracy: 0.1874\n",
      "Epoch 171/1000\n",
      " - 2s - loss: 0.2211 - raw_multi_label_accuracy: 0.3494 - val_loss: 0.4963 - val_raw_multi_label_accuracy: 0.1984\n",
      "Epoch 172/1000\n",
      " - 2s - loss: 0.2213 - raw_multi_label_accuracy: 0.3479 - val_loss: 0.4826 - val_raw_multi_label_accuracy: 0.1868\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 0.2225 - raw_multi_label_accuracy: 0.3453 - val_loss: 0.4906 - val_raw_multi_label_accuracy: 0.1997\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 0.2199 - raw_multi_label_accuracy: 0.3455 - val_loss: 0.4879 - val_raw_multi_label_accuracy: 0.1950\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 0.2205 - raw_multi_label_accuracy: 0.3465 - val_loss: 0.4919 - val_raw_multi_label_accuracy: 0.2044\n",
      "Epoch 176/1000\n",
      " - 1s - loss: 0.2194 - raw_multi_label_accuracy: 0.3514 - val_loss: 0.4743 - val_raw_multi_label_accuracy: 0.1953\n",
      "Epoch 177/1000\n",
      " - 2s - loss: 0.2195 - raw_multi_label_accuracy: 0.3568 - val_loss: 0.5020 - val_raw_multi_label_accuracy: 0.1947\n",
      "Epoch 178/1000\n",
      " - 1s - loss: 0.2187 - raw_multi_label_accuracy: 0.3552 - val_loss: 0.4863 - val_raw_multi_label_accuracy: 0.1962\n",
      "Epoch 179/1000\n",
      " - 2s - loss: 0.2184 - raw_multi_label_accuracy: 0.3504 - val_loss: 0.5097 - val_raw_multi_label_accuracy: 0.1942\n",
      "Epoch 180/1000\n",
      " - 2s - loss: 0.2182 - raw_multi_label_accuracy: 0.3539 - val_loss: 0.4918 - val_raw_multi_label_accuracy: 0.2022\n",
      "Epoch 181/1000\n",
      " - 2s - loss: 0.2177 - raw_multi_label_accuracy: 0.3538 - val_loss: 0.4936 - val_raw_multi_label_accuracy: 0.1983\n",
      "Epoch 182/1000\n",
      " - 2s - loss: 0.2188 - raw_multi_label_accuracy: 0.3465 - val_loss: 0.4784 - val_raw_multi_label_accuracy: 0.2019\n",
      "Epoch 183/1000\n",
      " - 1s - loss: 0.2189 - raw_multi_label_accuracy: 0.3535 - val_loss: 0.5036 - val_raw_multi_label_accuracy: 0.1922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      " - 2s - loss: 0.2179 - raw_multi_label_accuracy: 0.3538 - val_loss: 0.4971 - val_raw_multi_label_accuracy: 0.1916\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 0.2154 - raw_multi_label_accuracy: 0.3572 - val_loss: 0.4958 - val_raw_multi_label_accuracy: 0.1928\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 0.2165 - raw_multi_label_accuracy: 0.3568 - val_loss: 0.4885 - val_raw_multi_label_accuracy: 0.1902\n",
      "Epoch 187/1000\n",
      " - 2s - loss: 0.2163 - raw_multi_label_accuracy: 0.3518 - val_loss: 0.5252 - val_raw_multi_label_accuracy: 0.1899\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 0.2155 - raw_multi_label_accuracy: 0.3519 - val_loss: 0.4996 - val_raw_multi_label_accuracy: 0.1924\n",
      "Epoch 189/1000\n",
      " - 2s - loss: 0.2170 - raw_multi_label_accuracy: 0.3543 - val_loss: 0.5150 - val_raw_multi_label_accuracy: 0.1912\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 0.2149 - raw_multi_label_accuracy: 0.3574 - val_loss: 0.5166 - val_raw_multi_label_accuracy: 0.1983\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.2147 - raw_multi_label_accuracy: 0.3593 - val_loss: 0.4923 - val_raw_multi_label_accuracy: 0.2059\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 0.2150 - raw_multi_label_accuracy: 0.3545 - val_loss: 0.4994 - val_raw_multi_label_accuracy: 0.2016\n",
      "Epoch 193/1000\n",
      " - 2s - loss: 0.2158 - raw_multi_label_accuracy: 0.3508 - val_loss: 0.5007 - val_raw_multi_label_accuracy: 0.1930\n",
      "Epoch 194/1000\n",
      " - 2s - loss: 0.2137 - raw_multi_label_accuracy: 0.3601 - val_loss: 0.5100 - val_raw_multi_label_accuracy: 0.1965\n",
      "Epoch 195/1000\n",
      " - 2s - loss: 0.2146 - raw_multi_label_accuracy: 0.3521 - val_loss: 0.5055 - val_raw_multi_label_accuracy: 0.1987\n",
      "Epoch 196/1000\n",
      " - 2s - loss: 0.2123 - raw_multi_label_accuracy: 0.3604 - val_loss: 0.5214 - val_raw_multi_label_accuracy: 0.2001\n",
      "Epoch 197/1000\n",
      " - 1s - loss: 0.2127 - raw_multi_label_accuracy: 0.3612 - val_loss: 0.5083 - val_raw_multi_label_accuracy: 0.1898\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 0.2138 - raw_multi_label_accuracy: 0.3602 - val_loss: 0.5185 - val_raw_multi_label_accuracy: 0.1982\n",
      "Epoch 199/1000\n",
      " - 2s - loss: 0.2130 - raw_multi_label_accuracy: 0.3578 - val_loss: 0.5215 - val_raw_multi_label_accuracy: 0.1960\n",
      "Epoch 200/1000\n",
      " - 2s - loss: 0.2120 - raw_multi_label_accuracy: 0.3545 - val_loss: 0.5231 - val_raw_multi_label_accuracy: 0.2027\n",
      "Epoch 201/1000\n",
      " - 1s - loss: 0.2127 - raw_multi_label_accuracy: 0.3572 - val_loss: 0.5119 - val_raw_multi_label_accuracy: 0.1998\n",
      "Epoch 202/1000\n",
      " - 2s - loss: 0.2114 - raw_multi_label_accuracy: 0.3623 - val_loss: 0.5291 - val_raw_multi_label_accuracy: 0.1939\n",
      "Epoch 203/1000\n",
      " - 2s - loss: 0.2124 - raw_multi_label_accuracy: 0.3593 - val_loss: 0.5226 - val_raw_multi_label_accuracy: 0.1854\n",
      "Epoch 204/1000\n",
      " - 2s - loss: 0.2117 - raw_multi_label_accuracy: 0.3515 - val_loss: 0.5413 - val_raw_multi_label_accuracy: 0.1927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa491f27ef0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model_cnn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "#e = Embedding(num_words_kept, word_vec_len, input_length=max_seq_len, trainable=True)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(50, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "#model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
    "model_cnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=250)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24158823216612166"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5045395590142673"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29439259791018585"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 86.70854271356784\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for War: 0.964824120603015\n",
      "Precision for War: 0.0\n",
      "Recall for War: 0.0\n",
      "\n",
      "Accuruacy for Family: 0.9179229480737019\n",
      "Precision for Family: 0.2\n",
      "Recall for Family: 0.021739130434782608\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8961474036850922\n",
      "Precision for Science Fiction: 0.0\n",
      "Recall for Science Fiction: 0.0\n",
      "\n",
      "Accuruacy for Thriller: 0.6549413735343383\n",
      "Precision for Thriller: 0.39779005524861877\n",
      "Recall for Thriller: 0.4260355029585799\n",
      "\n",
      "Accuruacy for Horror: 0.9061976549413735\n",
      "Precision for Horror: 0.0\n",
      "Recall for Horror: 0.0\n",
      "\n",
      "Accuruacy for Romance: 0.7956448911222781\n",
      "Precision for Romance: 0.28\n",
      "Recall for Romance: 0.06306306306306306\n",
      "\n",
      "Accuruacy for Drama: 0.5695142378559463\n",
      "Precision for Drama: 0.5679824561403509\n",
      "Recall for Drama: 0.8119122257053292\n",
      "\n",
      "Accuruacy for Foreign: 0.9882747068676717\n",
      "Precision for Foreign: 0.0\n",
      "Recall for Foreign: 0.0\n",
      "\n",
      "Accuruacy for Documentary: 0.9731993299832495\n",
      "Precision for Documentary: 0.0\n",
      "Recall for Documentary: 0.0\n",
      "\n",
      "Accuruacy for Fantasy: 0.9229480737018425\n",
      "Precision for Fantasy: 0.0\n",
      "Recall for Fantasy: 0.0\n",
      "\n",
      "Accuruacy for Western: 0.983249581239531\n",
      "Precision for Western: 0.0\n",
      "Recall for Western: 0.0\n",
      "\n",
      "Accuruacy for History: 0.9614740368509213\n",
      "Precision for History: 0.0\n",
      "Recall for History: 0.0\n",
      "\n",
      "Accuruacy for Comedy: 0.6398659966499163\n",
      "Precision for Comedy: 0.5128205128205128\n",
      "Recall for Comedy: 0.09259259259259259\n",
      "\n",
      "Accuruacy for Action: 0.7051926298157454\n",
      "Precision for Action: 0.3956043956043956\n",
      "Recall for Action: 0.22929936305732485\n",
      "\n",
      "Accuruacy for Adventure: 0.8375209380234506\n",
      "Precision for Adventure: 0.0\n",
      "Recall for Adventure: 0.0\n",
      "\n",
      "Accuruacy for Animation: 0.9547738693467337\n",
      "Precision for Animation: 0.0\n",
      "Recall for Animation: 0.0\n",
      "\n",
      "Accuruacy for Crime: 0.7621440536013401\n",
      "Precision for Crime: 0.11475409836065574\n",
      "Recall for Crime: 0.07368421052631578\n",
      "\n",
      "Accuruacy for Music: 0.9748743718592965\n",
      "Precision for Music: 0.0\n",
      "Recall for Music: 0.0\n",
      "\n",
      "Accuruacy for TV Movie: 1.0\n",
      "Precision for TV Movie: 0.0\n",
      "Recall for TV Movie: 0.0\n",
      "\n",
      "Accuruacy for Mystery: 0.932998324958124\n",
      "Precision for Mystery: 0.0\n",
      "Recall for Mystery: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/matt/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN but with multiple filter sizes so we don't just filter on group of words at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "model_input = Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)(model_input)\n",
    "two_word_filter = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(e)\n",
    "two_word_filter = GlobalMaxPooling1D()(two_word_filter)\n",
    "three_word_filter = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(e)\n",
    "three_word_filter = GlobalMaxPooling1D()(three_word_filter)\n",
    "four_word_filter = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(e)\n",
    "four_word_filter = GlobalMaxPooling1D()(four_word_filter)\n",
    "merged = concatenate([two_word_filter, three_word_filter, four_word_filter], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(len(genre_dict))(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[model_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 2.6250 - raw_multi_label_accuracy: 0.1266 - val_loss: 1.8843 - val_raw_multi_label_accuracy: 0.1415\n",
      "Epoch 2/1000\n",
      " - 4s - loss: 1.4989 - raw_multi_label_accuracy: 0.1242 - val_loss: 1.0949 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 3/1000\n",
      " - 4s - loss: 0.8921 - raw_multi_label_accuracy: 0.1034 - val_loss: 0.6831 - val_raw_multi_label_accuracy: 0.0795\n",
      "Epoch 4/1000\n",
      " - 4s - loss: 0.5873 - raw_multi_label_accuracy: 0.1118 - val_loss: 0.4856 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 4s - loss: 0.4428 - raw_multi_label_accuracy: 0.0923 - val_loss: 0.3931 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 6/1000\n",
      " - 4s - loss: 0.3763 - raw_multi_label_accuracy: 0.1049 - val_loss: 0.3527 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 7/1000\n",
      " - 4s - loss: 0.3464 - raw_multi_label_accuracy: 0.0952 - val_loss: 0.3365 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 8/1000\n",
      " - 4s - loss: 0.3334 - raw_multi_label_accuracy: 0.1148 - val_loss: 0.3265 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 4s - loss: 0.3269 - raw_multi_label_accuracy: 0.1015 - val_loss: 0.3221 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 10/1000\n",
      " - 4s - loss: 0.3219 - raw_multi_label_accuracy: 0.1137 - val_loss: 0.3211 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      " - 4s - loss: 0.3206 - raw_multi_label_accuracy: 0.0989 - val_loss: 0.3196 - val_raw_multi_label_accuracy: 0.1693\n",
      "Epoch 12/1000\n",
      " - 4s - loss: 0.3182 - raw_multi_label_accuracy: 0.1095 - val_loss: 0.3185 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 13/1000\n",
      " - 4s - loss: 0.3146 - raw_multi_label_accuracy: 0.1170 - val_loss: 0.3181 - val_raw_multi_label_accuracy: 0.1648\n",
      "Epoch 14/1000\n",
      " - 4s - loss: 0.3103 - raw_multi_label_accuracy: 0.1274 - val_loss: 0.3203 - val_raw_multi_label_accuracy: 0.1648\n",
      "Epoch 15/1000\n",
      " - 4s - loss: 0.3045 - raw_multi_label_accuracy: 0.1221 - val_loss: 0.3203 - val_raw_multi_label_accuracy: 0.1620\n",
      "Epoch 16/1000\n",
      " - 4s - loss: 0.2983 - raw_multi_label_accuracy: 0.1345 - val_loss: 0.3202 - val_raw_multi_label_accuracy: 0.1017\n",
      "Epoch 17/1000\n",
      " - 4s - loss: 0.2938 - raw_multi_label_accuracy: 0.1370 - val_loss: 0.3203 - val_raw_multi_label_accuracy: 0.1376\n",
      "Epoch 18/1000\n",
      " - 4s - loss: 0.2884 - raw_multi_label_accuracy: 0.1417 - val_loss: 0.3216 - val_raw_multi_label_accuracy: 0.1242\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.2837 - raw_multi_label_accuracy: 0.1599 - val_loss: 0.3201 - val_raw_multi_label_accuracy: 0.0799\n",
      "Epoch 20/1000\n",
      " - 4s - loss: 0.2812 - raw_multi_label_accuracy: 0.1656 - val_loss: 0.3235 - val_raw_multi_label_accuracy: 0.1463\n",
      "Epoch 21/1000\n",
      " - 4s - loss: 0.2770 - raw_multi_label_accuracy: 0.1766 - val_loss: 0.3204 - val_raw_multi_label_accuracy: 0.1252\n",
      "Epoch 22/1000\n",
      " - 4s - loss: 0.2729 - raw_multi_label_accuracy: 0.1918 - val_loss: 0.3214 - val_raw_multi_label_accuracy: 0.1072\n",
      "Epoch 23/1000\n",
      " - 4s - loss: 0.2680 - raw_multi_label_accuracy: 0.2038 - val_loss: 0.3232 - val_raw_multi_label_accuracy: 0.1225\n",
      "Epoch 24/1000\n",
      " - 4s - loss: 0.2636 - raw_multi_label_accuracy: 0.2193 - val_loss: 0.3250 - val_raw_multi_label_accuracy: 0.1210\n",
      "Epoch 25/1000\n",
      " - 4s - loss: 0.2602 - raw_multi_label_accuracy: 0.2270 - val_loss: 0.3238 - val_raw_multi_label_accuracy: 0.1260\n",
      "Epoch 26/1000\n",
      " - 4s - loss: 0.2565 - raw_multi_label_accuracy: 0.2354 - val_loss: 0.3289 - val_raw_multi_label_accuracy: 0.1181\n",
      "Epoch 27/1000\n",
      " - 4s - loss: 0.2509 - raw_multi_label_accuracy: 0.2514 - val_loss: 0.3292 - val_raw_multi_label_accuracy: 0.1324\n",
      "Epoch 28/1000\n",
      " - 4s - loss: 0.2429 - raw_multi_label_accuracy: 0.2878 - val_loss: 0.3395 - val_raw_multi_label_accuracy: 0.1265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa471155e48>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=250)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18065725452660114"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.603305785123967"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18640823163436215"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 87.79731993299833\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for War: 0.964824120603015\n",
      "Precision for War: 0.0\n",
      "Recall for War: 0.0\n",
      "\n",
      "Accuruacy for Family: 0.9229480737018425\n",
      "Precision for Family: 0.0\n",
      "Recall for Family: 0.0\n",
      "\n",
      "Accuruacy for Science Fiction: 0.897822445561139\n",
      "Precision for Science Fiction: 1.0\n",
      "Recall for Science Fiction: 0.016129032258064516\n",
      "\n",
      "Accuruacy for Thriller: 0.7252931323283082\n",
      "Precision for Thriller: 0.6190476190476191\n",
      "Recall for Thriller: 0.07692307692307693\n",
      "\n",
      "Accuruacy for Horror: 0.9061976549413735\n",
      "Precision for Horror: 0.0\n",
      "Recall for Horror: 0.0\n",
      "\n",
      "Accuruacy for Romance: 0.8090452261306532\n",
      "Precision for Romance: 0.2857142857142857\n",
      "Recall for Romance: 0.018018018018018018\n",
      "\n",
      "Accuruacy for Drama: 0.5979899497487438\n",
      "Precision for Drama: 0.6207951070336392\n",
      "Recall for Drama: 0.6363636363636364\n",
      "\n",
      "Accuruacy for Foreign: 0.9882747068676717\n",
      "Precision for Foreign: 0.0\n",
      "Recall for Foreign: 0.0\n",
      "\n",
      "Accuruacy for Documentary: 0.9731993299832495\n",
      "Precision for Documentary: 0.0\n",
      "Recall for Documentary: 0.0\n",
      "\n",
      "Accuruacy for Fantasy: 0.9229480737018425\n",
      "Precision for Fantasy: 0.0\n",
      "Recall for Fantasy: 0.0\n",
      "\n",
      "Accuruacy for Western: 0.983249581239531\n",
      "Precision for Western: 0.0\n",
      "Recall for Western: 0.0\n",
      "\n",
      "Accuruacy for History: 0.9614740368509213\n",
      "Precision for History: 0.0\n",
      "Recall for History: 0.0\n",
      "\n",
      "Accuruacy for Comedy: 0.6314907872696818\n",
      "Precision for Comedy: 0.3\n",
      "Recall for Comedy: 0.013888888888888888\n",
      "\n",
      "Accuruacy for Action: 0.7336683417085427\n",
      "Precision for Action: 0.45\n",
      "Recall for Action: 0.05732484076433121\n",
      "\n",
      "Accuruacy for Adventure: 0.8375209380234506\n",
      "Precision for Adventure: 0.3333333333333333\n",
      "Recall for Adventure: 0.021052631578947368\n",
      "\n",
      "Accuruacy for Animation: 0.9547738693467337\n",
      "Precision for Animation: 0.0\n",
      "Recall for Animation: 0.0\n",
      "\n",
      "Accuruacy for Crime: 0.8408710217755444\n",
      "Precision for Crime: 0.0\n",
      "Recall for Crime: 0.0\n",
      "\n",
      "Accuruacy for Music: 0.9748743718592965\n",
      "Precision for Music: 0.0\n",
      "Recall for Music: 0.0\n",
      "\n",
      "Accuruacy for TV Movie: 1.0\n",
      "Precision for TV Movie: 0.0\n",
      "Recall for TV Movie: 0.0\n",
      "\n",
      "Accuruacy for Mystery: 0.932998324958124\n",
      "Precision for Mystery: 0.0\n",
      "Recall for Mystery: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 0.4002 - raw_multi_label_accuracy: 0.0808 - val_loss: 0.3392 - val_raw_multi_label_accuracy: 0.1100\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 0.3229 - raw_multi_label_accuracy: 0.1074 - val_loss: 0.3266 - val_raw_multi_label_accuracy: 0.0874\n",
      "Epoch 3/1000\n",
      " - 2s - loss: 0.3060 - raw_multi_label_accuracy: 0.1316 - val_loss: 0.3265 - val_raw_multi_label_accuracy: 0.1098\n",
      "Epoch 4/1000\n",
      " - 2s - loss: 0.2958 - raw_multi_label_accuracy: 0.1274 - val_loss: 0.3212 - val_raw_multi_label_accuracy: 0.0652\n",
      "Epoch 5/1000\n",
      " - 2s - loss: 0.2860 - raw_multi_label_accuracy: 0.1491 - val_loss: 0.3214 - val_raw_multi_label_accuracy: 0.0786\n",
      "Epoch 6/1000\n",
      " - 2s - loss: 0.2719 - raw_multi_label_accuracy: 0.1795 - val_loss: 0.3199 - val_raw_multi_label_accuracy: 0.1098\n",
      "Epoch 7/1000\n",
      " - 2s - loss: 0.2543 - raw_multi_label_accuracy: 0.2449 - val_loss: 0.3176 - val_raw_multi_label_accuracy: 0.1046\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 0.2304 - raw_multi_label_accuracy: 0.3275 - val_loss: 0.3174 - val_raw_multi_label_accuracy: 0.1439\n",
      "Epoch 9/1000\n",
      " - 2s - loss: 0.2060 - raw_multi_label_accuracy: 0.4198 - val_loss: 0.3198 - val_raw_multi_label_accuracy: 0.1538\n",
      "Epoch 10/1000\n",
      " - 2s - loss: 0.1828 - raw_multi_label_accuracy: 0.4944 - val_loss: 0.3207 - val_raw_multi_label_accuracy: 0.1800\n",
      "Epoch 11/1000\n",
      " - 2s - loss: 0.1597 - raw_multi_label_accuracy: 0.5891 - val_loss: 0.3335 - val_raw_multi_label_accuracy: 0.1131\n",
      "Epoch 12/1000\n",
      " - 2s - loss: 0.1385 - raw_multi_label_accuracy: 0.6485 - val_loss: 0.3366 - val_raw_multi_label_accuracy: 0.1426\n",
      "Epoch 13/1000\n",
      " - 2s - loss: 0.1201 - raw_multi_label_accuracy: 0.7068 - val_loss: 0.3494 - val_raw_multi_label_accuracy: 0.1508\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 0.1032 - raw_multi_label_accuracy: 0.7598 - val_loss: 0.3574 - val_raw_multi_label_accuracy: 0.1687\n",
      "Epoch 15/1000\n",
      " - 2s - loss: 0.0876 - raw_multi_label_accuracy: 0.8060 - val_loss: 0.3707 - val_raw_multi_label_accuracy: 0.1544\n",
      "Epoch 16/1000\n",
      " - 2s - loss: 0.0739 - raw_multi_label_accuracy: 0.8506 - val_loss: 0.3790 - val_raw_multi_label_accuracy: 0.1736\n",
      "Epoch 17/1000\n",
      " - 2s - loss: 0.0625 - raw_multi_label_accuracy: 0.8777 - val_loss: 0.3956 - val_raw_multi_label_accuracy: 0.1741\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 0.0523 - raw_multi_label_accuracy: 0.9098 - val_loss: 0.4126 - val_raw_multi_label_accuracy: 0.1637\n",
      "Epoch 19/1000\n",
      " - 2s - loss: 0.0444 - raw_multi_label_accuracy: 0.9306 - val_loss: 0.4157 - val_raw_multi_label_accuracy: 0.1753\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 0.0376 - raw_multi_label_accuracy: 0.9475 - val_loss: 0.4466 - val_raw_multi_label_accuracy: 0.1665\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 0.0318 - raw_multi_label_accuracy: 0.9576 - val_loss: 0.4523 - val_raw_multi_label_accuracy: 0.1779\n",
      "Epoch 22/1000\n",
      " - 2s - loss: 0.0270 - raw_multi_label_accuracy: 0.9700 - val_loss: 0.4780 - val_raw_multi_label_accuracy: 0.1763\n",
      "Epoch 23/1000\n",
      " - 2s - loss: 0.0230 - raw_multi_label_accuracy: 0.9752 - val_loss: 0.4807 - val_raw_multi_label_accuracy: 0.1712\n",
      "Epoch 24/1000\n",
      " - 2s - loss: 0.0197 - raw_multi_label_accuracy: 0.9812 - val_loss: 0.5038 - val_raw_multi_label_accuracy: 0.1752\n",
      "Epoch 25/1000\n",
      " - 2s - loss: 0.0168 - raw_multi_label_accuracy: 0.9846 - val_loss: 0.5131 - val_raw_multi_label_accuracy: 0.1805\n",
      "Epoch 26/1000\n",
      " - 2s - loss: 0.0145 - raw_multi_label_accuracy: 0.9886 - val_loss: 0.5327 - val_raw_multi_label_accuracy: 0.1748\n",
      "Epoch 27/1000\n",
      " - 2s - loss: 0.0125 - raw_multi_label_accuracy: 0.9909 - val_loss: 0.5437 - val_raw_multi_label_accuracy: 0.1738\n",
      "Epoch 28/1000\n",
      " - 2s - loss: 0.0110 - raw_multi_label_accuracy: 0.9926 - val_loss: 0.5444 - val_raw_multi_label_accuracy: 0.1796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa470dd7be0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_nn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "normal_nn.add(e)\n",
    "normal_nn.add(Flatten())\n",
    "normal_nn.add(Dense(256, activation='relu'))\n",
    "normal_nn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "normal_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "normal_nn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=250)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(normal_nn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2245313870942012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5557419835943325"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2560780090930844"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 87.72194304857621\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for War: 0.964824120603015\n",
      "Precision for War: 0.0\n",
      "Recall for War: 0.0\n",
      "\n",
      "Accuruacy for Family: 0.9212730318257957\n",
      "Precision for Family: 0.0\n",
      "Recall for Family: 0.0\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8927973199329984\n",
      "Precision for Science Fiction: 0.375\n",
      "Recall for Science Fiction: 0.04838709677419355\n",
      "\n",
      "Accuruacy for Thriller: 0.711892797319933\n",
      "Precision for Thriller: 0.4594594594594595\n",
      "Recall for Thriller: 0.10059171597633136\n",
      "\n",
      "Accuruacy for Horror: 0.9061976549413735\n",
      "Precision for Horror: 0.5\n",
      "Recall for Horror: 0.017857142857142856\n",
      "\n",
      "Accuruacy for Romance: 0.8224455611390284\n",
      "Precision for Romance: 0.5862068965517241\n",
      "Recall for Romance: 0.15315315315315314\n",
      "\n",
      "Accuruacy for Drama: 0.5963149078726968\n",
      "Precision for Drama: 0.6167664670658682\n",
      "Recall for Drama: 0.64576802507837\n",
      "\n",
      "Accuruacy for Foreign: 0.9882747068676717\n",
      "Precision for Foreign: 0.0\n",
      "Recall for Foreign: 0.0\n",
      "\n",
      "Accuruacy for Documentary: 0.9731993299832495\n",
      "Precision for Documentary: 0.0\n",
      "Recall for Documentary: 0.0\n",
      "\n",
      "Accuruacy for Fantasy: 0.9195979899497487\n",
      "Precision for Fantasy: 0.0\n",
      "Recall for Fantasy: 0.0\n",
      "\n",
      "Accuruacy for Western: 0.983249581239531\n",
      "Precision for Western: 0.0\n",
      "Recall for Western: 0.0\n",
      "\n",
      "Accuruacy for History: 0.9614740368509213\n",
      "Precision for History: 0.0\n",
      "Recall for History: 0.0\n",
      "\n",
      "Accuruacy for Comedy: 0.6314907872696818\n",
      "Precision for Comedy: 0.48412698412698413\n",
      "Recall for Comedy: 0.2824074074074074\n",
      "\n",
      "Accuruacy for Action: 0.7336683417085427\n",
      "Precision for Action: 0.4807692307692308\n",
      "Recall for Action: 0.1592356687898089\n",
      "\n",
      "Accuruacy for Adventure: 0.8391959798994975\n",
      "Precision for Adventure: 0.4666666666666667\n",
      "Recall for Adventure: 0.07368421052631578\n",
      "\n",
      "Accuruacy for Animation: 0.9547738693467337\n",
      "Precision for Animation: 0.0\n",
      "Recall for Animation: 0.0\n",
      "\n",
      "Accuruacy for Crime: 0.8375209380234506\n",
      "Precision for Crime: 0.375\n",
      "Recall for Crime: 0.031578947368421054\n",
      "\n",
      "Accuruacy for Music: 0.9748743718592965\n",
      "Precision for Music: 0.0\n",
      "Recall for Music: 0.0\n",
      "\n",
      "Accuruacy for TV Movie: 1.0\n",
      "Precision for TV Movie: 0.0\n",
      "Recall for TV Movie: 0.0\n",
      "\n",
      "Accuruacy for Mystery: 0.931323283082077\n",
      "Precision for Mystery: 0.0\n",
      "Recall for Mystery: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/1000\n",
      " - 10s - loss: 0.5200 - raw_multi_label_accuracy: 0.0882 - val_loss: 0.3444 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 2/1000\n",
      " - 8s - loss: 0.3209 - raw_multi_label_accuracy: 0.0806 - val_loss: 0.3171 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 3/1000\n",
      " - 8s - loss: 0.3132 - raw_multi_label_accuracy: 0.1301 - val_loss: 0.3151 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 8s - loss: 0.3124 - raw_multi_label_accuracy: 0.0839 - val_loss: 0.3148 - val_raw_multi_label_accuracy: 0.0243\n",
      "Epoch 5/1000\n",
      " - 8s - loss: 0.3119 - raw_multi_label_accuracy: 0.1274 - val_loss: 0.3148 - val_raw_multi_label_accuracy: 0.0225\n",
      "Epoch 6/1000\n",
      " - 8s - loss: 0.3115 - raw_multi_label_accuracy: 0.1166 - val_loss: 0.3150 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 8s - loss: 0.3113 - raw_multi_label_accuracy: 0.1097 - val_loss: 0.3149 - val_raw_multi_label_accuracy: 0.0338\n",
      "Epoch 8/1000\n",
      " - 8s - loss: 0.3111 - raw_multi_label_accuracy: 0.0723 - val_loss: 0.3143 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 9/1000\n",
      " - 8s - loss: 0.3107 - raw_multi_label_accuracy: 0.1153 - val_loss: 0.3147 - val_raw_multi_label_accuracy: 0.0291\n",
      "Epoch 10/1000\n",
      " - 8s - loss: 0.3098 - raw_multi_label_accuracy: 0.0951 - val_loss: 0.3145 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 11/1000\n",
      " - 8s - loss: 0.3093 - raw_multi_label_accuracy: 0.1043 - val_loss: 0.3150 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 12/1000\n",
      " - 8s - loss: 0.3085 - raw_multi_label_accuracy: 0.1128 - val_loss: 0.3146 - val_raw_multi_label_accuracy: 0.0415\n",
      "Epoch 13/1000\n",
      " - 8s - loss: 0.3073 - raw_multi_label_accuracy: 0.1201 - val_loss: 0.3142 - val_raw_multi_label_accuracy: 0.1695\n",
      "Epoch 14/1000\n",
      " - 8s - loss: 0.3056 - raw_multi_label_accuracy: 0.1306 - val_loss: 0.3140 - val_raw_multi_label_accuracy: 0.0679\n",
      "Epoch 15/1000\n",
      " - 8s - loss: 0.3033 - raw_multi_label_accuracy: 0.1550 - val_loss: 0.3142 - val_raw_multi_label_accuracy: 0.0543\n",
      "Epoch 16/1000\n",
      " - 8s - loss: 0.3007 - raw_multi_label_accuracy: 0.1421 - val_loss: 0.3139 - val_raw_multi_label_accuracy: 0.1228\n",
      "Epoch 17/1000\n",
      " - 8s - loss: 0.2981 - raw_multi_label_accuracy: 0.1537 - val_loss: 0.3143 - val_raw_multi_label_accuracy: 0.0689\n",
      "Epoch 18/1000\n",
      " - 8s - loss: 0.2939 - raw_multi_label_accuracy: 0.1604 - val_loss: 0.3140 - val_raw_multi_label_accuracy: 0.1158\n",
      "Epoch 19/1000\n",
      " - 8s - loss: 0.2888 - raw_multi_label_accuracy: 0.1724 - val_loss: 0.3137 - val_raw_multi_label_accuracy: 0.1414\n",
      "Epoch 20/1000\n",
      " - 8s - loss: 0.2814 - raw_multi_label_accuracy: 0.1875 - val_loss: 0.3121 - val_raw_multi_label_accuracy: 0.0994\n",
      "Epoch 21/1000\n",
      " - 8s - loss: 0.2723 - raw_multi_label_accuracy: 0.2455 - val_loss: 0.3133 - val_raw_multi_label_accuracy: 0.1006\n",
      "Epoch 22/1000\n",
      " - 8s - loss: 0.2600 - raw_multi_label_accuracy: 0.3018 - val_loss: 0.3182 - val_raw_multi_label_accuracy: 0.1801\n",
      "Epoch 23/1000\n",
      " - 9s - loss: 0.2491 - raw_multi_label_accuracy: 0.3317 - val_loss: 0.3145 - val_raw_multi_label_accuracy: 0.1505\n",
      "Epoch 24/1000\n",
      " - 8s - loss: 0.2372 - raw_multi_label_accuracy: 0.3693 - val_loss: 0.3172 - val_raw_multi_label_accuracy: 0.1677\n",
      "Epoch 25/1000\n",
      " - 8s - loss: 0.2263 - raw_multi_label_accuracy: 0.3936 - val_loss: 0.3227 - val_raw_multi_label_accuracy: 0.1867\n",
      "Epoch 26/1000\n",
      " - 8s - loss: 0.2190 - raw_multi_label_accuracy: 0.4043 - val_loss: 0.3262 - val_raw_multi_label_accuracy: 0.1778\n",
      "Epoch 27/1000\n",
      " - 8s - loss: 0.2115 - raw_multi_label_accuracy: 0.4222 - val_loss: 0.3303 - val_raw_multi_label_accuracy: 0.1910\n",
      "Epoch 28/1000\n",
      " - 8s - loss: 0.2049 - raw_multi_label_accuracy: 0.4482 - val_loss: 0.3372 - val_raw_multi_label_accuracy: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4705b3cf8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "lstm_model = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "lstm_model.add(e)\n",
    "lstm_model.add(LSTM(100, dropout=0.25, recurrent_dropout=0.25))\n",
    "lstm_model.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "lstm_model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=250)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(lstm_model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24510648480497746"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5620567375886524"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2793890085347372"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 87.66331658291458\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for War: 0.964824120603015\n",
      "Precision for War: 0.0\n",
      "Recall for War: 0.0\n",
      "\n",
      "Accuruacy for Family: 0.9229480737018425\n",
      "Precision for Family: 0.0\n",
      "Recall for Family: 0.0\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8961474036850922\n",
      "Precision for Science Fiction: 0.0\n",
      "Recall for Science Fiction: 0.0\n",
      "\n",
      "Accuruacy for Thriller: 0.7001675041876047\n",
      "Precision for Thriller: 0.4609375\n",
      "Recall for Thriller: 0.34911242603550297\n",
      "\n",
      "Accuruacy for Horror: 0.9061976549413735\n",
      "Precision for Horror: 0.0\n",
      "Recall for Horror: 0.0\n",
      "\n",
      "Accuruacy for Romance: 0.8257956448911222\n",
      "Precision for Romance: 0.5945945945945946\n",
      "Recall for Romance: 0.1981981981981982\n",
      "\n",
      "Accuruacy for Drama: 0.5845896147403685\n",
      "Precision for Drama: 0.60790273556231\n",
      "Recall for Drama: 0.6269592476489029\n",
      "\n",
      "Accuruacy for Foreign: 0.9882747068676717\n",
      "Precision for Foreign: 0.0\n",
      "Recall for Foreign: 0.0\n",
      "\n",
      "Accuruacy for Documentary: 0.9731993299832495\n",
      "Precision for Documentary: 0.0\n",
      "Recall for Documentary: 0.0\n",
      "\n",
      "Accuruacy for Fantasy: 0.9229480737018425\n",
      "Precision for Fantasy: 0.0\n",
      "Recall for Fantasy: 0.0\n",
      "\n",
      "Accuruacy for Western: 0.983249581239531\n",
      "Precision for Western: 0.0\n",
      "Recall for Western: 0.0\n",
      "\n",
      "Accuruacy for History: 0.9614740368509213\n",
      "Precision for History: 0.0\n",
      "Recall for History: 0.0\n",
      "\n",
      "Accuruacy for Comedy: 0.6432160804020101\n",
      "Precision for Comedy: 0.5145631067961165\n",
      "Recall for Comedy: 0.24537037037037038\n",
      "\n",
      "Accuruacy for Action: 0.7219430485762144\n",
      "Precision for Action: 0.4457831325301205\n",
      "Recall for Action: 0.2356687898089172\n",
      "\n",
      "Accuruacy for Adventure: 0.8341708542713567\n",
      "Precision for Adventure: 0.25\n",
      "Recall for Adventure: 0.021052631578947368\n",
      "\n",
      "Accuruacy for Animation: 0.9547738693467337\n",
      "Precision for Animation: 0.0\n",
      "Recall for Animation: 0.0\n",
      "\n",
      "Accuruacy for Crime: 0.8408710217755444\n",
      "Precision for Crime: 0.0\n",
      "Recall for Crime: 0.0\n",
      "\n",
      "Accuruacy for Music: 0.9748743718592965\n",
      "Precision for Music: 0.0\n",
      "Recall for Music: 0.0\n",
      "\n",
      "Accuruacy for TV Movie: 1.0\n",
      "Precision for TV Movie: 0.0\n",
      "Recall for TV Movie: 0.0\n",
      "\n",
      "Accuruacy for Mystery: 0.932998324958124\n",
      "Precision for Mystery: 0.0\n",
      "Recall for Mystery: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
