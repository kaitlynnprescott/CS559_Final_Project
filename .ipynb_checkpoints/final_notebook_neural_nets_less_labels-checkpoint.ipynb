{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, LSTM, SimpleRNN, Dense, Dropout, Flatten\n",
    "from keras.layers import Input, concatenate, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse each row to get label vectors from json\n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dictionary for genre to its index in label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure': 0,\n",
       " 'Romance': 1,\n",
       " 'Horror-Thriller': 2,\n",
       " 'Comedy': 3,\n",
       " 'Science Fiction': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "#genre_dict['Drama'] = 5\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map original labels to more coarse grained labels\n",
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "#genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation, remove stopwords\n",
    "def cleanText(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    text = ' '.join(no_stopword_text)\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0] #drop rows that now have no labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural net data only needs a few cols\n",
    "nn_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(nn_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract actual features and labels from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gettrian and test features for classification. Just need text and lables for this\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']\n",
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels from array of lists to numpy array\n",
    "\n",
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get initial word embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(ov) for ov in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "w2v = Word2Vec(tok, min_count = 2, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 150 #larger than averaage but not too large\n",
    "\n",
    "#get actual train features to feed into neural nets for training\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "#get actual test features to feed into neural nets for testing\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get word embeddings matrix for start input to neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation: This technique to get word embeddings comes, with some minor changes, mostly from: \n",
    "#https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "embeddings_index = {}\n",
    "for w in w2v.wv.vocab.keys():\n",
    "    embeddings_index[w] = w2v.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define evlaution metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better. Percent incorrectly chosen labels counting assignment and non-assignment equally\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "\n",
    "#K is what we imported keras backend as\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(actual_labels, predictions):\n",
    "    print('Getting evaluation metrics for each label:')\n",
    "    get_per_label_metrics(actual_labels, predictions)\n",
    "    print('Getting evaluations for multilabel problem')\n",
    "    print('Multilabel accuracy: ' + str(multi_label_accuracy(actual_labels, predictions)))\n",
    "    print('Multilabel precision: ' + str(multi_label_precision(actual_labels, predictions)))\n",
    "    print('Multilabel recall: ' + str(multi_label_recall(actual_labels, predictions)))\n",
    "    print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(actual_labels, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "#not same as patience. Want to not even start looking until delay is reached\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__(monitor=monitor, min_delta=min_delta, patience=patience,verbose=verbose, mode=mode)\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 0.7098 - raw_multi_label_accuracy: 0.1448 - val_loss: 0.6554 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 3s - loss: 0.6555 - raw_multi_label_accuracy: 0.0432 - val_loss: 0.6368 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 3s - loss: 0.6393 - raw_multi_label_accuracy: 0.0377 - val_loss: 0.6252 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 3s - loss: 0.6237 - raw_multi_label_accuracy: 0.0249 - val_loss: 0.6167 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 3s - loss: 0.6152 - raw_multi_label_accuracy: 0.0434 - val_loss: 0.6087 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 3s - loss: 0.6009 - raw_multi_label_accuracy: 0.0282 - val_loss: 0.6023 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 2s - loss: 0.5687 - raw_multi_label_accuracy: 0.1290 - val_loss: 0.5930 - val_raw_multi_label_accuracy: 0.0235\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 0.5038 - raw_multi_label_accuracy: 0.3885 - val_loss: 0.5799 - val_raw_multi_label_accuracy: 0.1191\n",
      "Epoch 9/1000\n",
      " - 3s - loss: 0.4287 - raw_multi_label_accuracy: 0.5276 - val_loss: 0.5770 - val_raw_multi_label_accuracy: 0.1528\n",
      "Epoch 10/1000\n",
      " - 4s - loss: 0.3865 - raw_multi_label_accuracy: 0.5556 - val_loss: 0.5892 - val_raw_multi_label_accuracy: 0.1784\n",
      "Epoch 11/1000\n",
      " - 3s - loss: 0.3489 - raw_multi_label_accuracy: 0.6111 - val_loss: 0.5872 - val_raw_multi_label_accuracy: 0.2141\n",
      "Epoch 12/1000\n",
      " - 3s - loss: 0.2996 - raw_multi_label_accuracy: 0.6971 - val_loss: 0.6045 - val_raw_multi_label_accuracy: 0.2253\n",
      "Epoch 13/1000\n",
      " - 3s - loss: 0.2485 - raw_multi_label_accuracy: 0.7815 - val_loss: 0.6112 - val_raw_multi_label_accuracy: 0.2520\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 0.2073 - raw_multi_label_accuracy: 0.8246 - val_loss: 0.6339 - val_raw_multi_label_accuracy: 0.2579\n",
      "Epoch 15/1000\n",
      " - 2s - loss: 0.1732 - raw_multi_label_accuracy: 0.8842 - val_loss: 0.6688 - val_raw_multi_label_accuracy: 0.2565\n",
      "Epoch 16/1000\n",
      " - 3s - loss: 0.1485 - raw_multi_label_accuracy: 0.9098 - val_loss: 0.6777 - val_raw_multi_label_accuracy: 0.2770\n",
      "Epoch 17/1000\n",
      " - 3s - loss: 0.1325 - raw_multi_label_accuracy: 0.9280 - val_loss: 0.7122 - val_raw_multi_label_accuracy: 0.2684\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 0.1199 - raw_multi_label_accuracy: 0.9398 - val_loss: 0.7411 - val_raw_multi_label_accuracy: 0.2629\n",
      "Epoch 19/1000\n",
      " - 3s - loss: 0.1092 - raw_multi_label_accuracy: 0.9453 - val_loss: 0.7532 - val_raw_multi_label_accuracy: 0.2615\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 0.1007 - raw_multi_label_accuracy: 0.9539 - val_loss: 0.7702 - val_raw_multi_label_accuracy: 0.2720\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 0.0958 - raw_multi_label_accuracy: 0.9527 - val_loss: 0.8057 - val_raw_multi_label_accuracy: 0.2831\n",
      "Epoch 22/1000\n",
      " - 3s - loss: 0.0900 - raw_multi_label_accuracy: 0.9581 - val_loss: 0.8120 - val_raw_multi_label_accuracy: 0.2550\n",
      "Epoch 23/1000\n",
      " - 3s - loss: 0.0820 - raw_multi_label_accuracy: 0.9701 - val_loss: 0.8030 - val_raw_multi_label_accuracy: 0.2661\n",
      "Epoch 24/1000\n",
      " - 2s - loss: 0.0782 - raw_multi_label_accuracy: 0.9727 - val_loss: 0.8098 - val_raw_multi_label_accuracy: 0.2466\n",
      "Epoch 25/1000\n",
      " - 2s - loss: 0.0717 - raw_multi_label_accuracy: 0.9760 - val_loss: 0.8349 - val_raw_multi_label_accuracy: 0.2698\n",
      "Epoch 26/1000\n",
      " - 2s - loss: 0.0685 - raw_multi_label_accuracy: 0.9772 - val_loss: 0.8153 - val_raw_multi_label_accuracy: 0.2634\n",
      "Epoch 27/1000\n",
      " - 3s - loss: 0.0652 - raw_multi_label_accuracy: 0.9825 - val_loss: 0.8295 - val_raw_multi_label_accuracy: 0.2656\n",
      "Epoch 28/1000\n",
      " - 3s - loss: 0.0618 - raw_multi_label_accuracy: 0.9783 - val_loss: 0.8749 - val_raw_multi_label_accuracy: 0.2742\n",
      "Epoch 29/1000\n",
      " - 3s - loss: 0.0598 - raw_multi_label_accuracy: 0.9817 - val_loss: 0.8514 - val_raw_multi_label_accuracy: 0.2618\n",
      "Epoch 30/1000\n",
      " - 3s - loss: 0.0563 - raw_multi_label_accuracy: 0.9860 - val_loss: 0.8628 - val_raw_multi_label_accuracy: 0.2636\n",
      "Epoch 31/1000\n",
      " - 3s - loss: 0.0540 - raw_multi_label_accuracy: 0.9886 - val_loss: 0.9140 - val_raw_multi_label_accuracy: 0.2545\n",
      "Epoch 32/1000\n",
      " - 2s - loss: 0.0515 - raw_multi_label_accuracy: 0.9887 - val_loss: 0.8757 - val_raw_multi_label_accuracy: 0.2539\n",
      "Epoch 33/1000\n",
      " - 2s - loss: 0.0489 - raw_multi_label_accuracy: 0.9910 - val_loss: 0.8964 - val_raw_multi_label_accuracy: 0.2601\n",
      "Time to train with cross validation for early stopping: 93.47670245170593 seconds\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "#e = Embedding(num_words_kept, word_vec_len, input_length=max_seq_len, trainable=True)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "start = time.time()\n",
    "model_cnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
    "end = time.time()\n",
    "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.6252587991718427\n",
      "Precision for Action-Adventure: 0.5138888888888888\n",
      "Recall for Action-Adventure: 0.5935828877005348\n",
      "\n",
      "Accuruacy for Romance: 0.7701863354037267\n",
      "Precision for Romance: 0.4074074074074074\n",
      "Recall for Romance: 0.10377358490566038\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.660455486542443\n",
      "Precision for Horror-Thriller: 0.6076923076923076\n",
      "Recall for Horror-Thriller: 0.4114583333333333\n",
      "\n",
      "Accuruacy for Comedy: 0.6356107660455487\n",
      "Precision for Comedy: 0.6209150326797386\n",
      "Recall for Comedy: 0.4460093896713615\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8799171842650103\n",
      "Precision for Science Fiction: 0.4\n",
      "Recall for Science Fiction: 0.07142857142857142\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.3459282263630091\n",
      "Multilabel precision: 0.5598705501618123\n",
      "Multilabel recall: 0.3947550034506555\n",
      "Percent of correctly decided label decisions: 71.42857142857143\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN but with multiple filter sizes so we don't just filter on group of words at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 9s - loss: 2.8665 - raw_multi_label_accuracy: 0.0761 - val_loss: 2.2728 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 8s - loss: 1.9097 - raw_multi_label_accuracy: 0.0394 - val_loss: 1.5235 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 8s - loss: 1.3106 - raw_multi_label_accuracy: 0.0652 - val_loss: 1.0855 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 8s - loss: 0.9693 - raw_multi_label_accuracy: 0.0284 - val_loss: 0.8446 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 8s - loss: 0.7826 - raw_multi_label_accuracy: 0.0139 - val_loss: 0.7149 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 8s - loss: 0.6848 - raw_multi_label_accuracy: 0.0155 - val_loss: 0.6475 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 8s - loss: 0.6356 - raw_multi_label_accuracy: 0.0139 - val_loss: 0.6154 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 8s - loss: 0.6068 - raw_multi_label_accuracy: 0.0174 - val_loss: 0.6002 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 8s - loss: 0.5832 - raw_multi_label_accuracy: 0.0657 - val_loss: 0.5957 - val_raw_multi_label_accuracy: 0.0821\n",
      "Epoch 10/1000\n",
      " - 8s - loss: 0.5322 - raw_multi_label_accuracy: 0.3134 - val_loss: 0.5979 - val_raw_multi_label_accuracy: 0.1466\n",
      "Epoch 11/1000\n",
      " - 8s - loss: 0.4528 - raw_multi_label_accuracy: 0.5124 - val_loss: 0.5983 - val_raw_multi_label_accuracy: 0.1844\n",
      "Epoch 12/1000\n",
      " - 8s - loss: 0.4012 - raw_multi_label_accuracy: 0.5694 - val_loss: 0.5866 - val_raw_multi_label_accuracy: 0.1734\n",
      "Epoch 13/1000\n",
      " - 8s - loss: 0.3528 - raw_multi_label_accuracy: 0.6547 - val_loss: 0.5863 - val_raw_multi_label_accuracy: 0.2004\n",
      "Epoch 14/1000\n",
      " - 8s - loss: 0.3049 - raw_multi_label_accuracy: 0.7297 - val_loss: 0.6018 - val_raw_multi_label_accuracy: 0.2007\n",
      "Epoch 15/1000\n",
      " - 8s - loss: 0.2670 - raw_multi_label_accuracy: 0.7793 - val_loss: 0.6221 - val_raw_multi_label_accuracy: 0.2090\n",
      "Epoch 16/1000\n",
      " - 8s - loss: 0.2429 - raw_multi_label_accuracy: 0.7976 - val_loss: 0.6404 - val_raw_multi_label_accuracy: 0.1793\n",
      "Epoch 17/1000\n",
      " - 8s - loss: 0.2209 - raw_multi_label_accuracy: 0.8158 - val_loss: 0.6244 - val_raw_multi_label_accuracy: 0.2242\n",
      "Epoch 18/1000\n",
      " - 8s - loss: 0.2004 - raw_multi_label_accuracy: 0.8395 - val_loss: 0.6444 - val_raw_multi_label_accuracy: 0.2292\n",
      "Epoch 19/1000\n",
      " - 8s - loss: 0.1848 - raw_multi_label_accuracy: 0.8526 - val_loss: 0.6789 - val_raw_multi_label_accuracy: 0.1890\n",
      "Epoch 20/1000\n",
      " - 8s - loss: 0.1689 - raw_multi_label_accuracy: 0.8720 - val_loss: 0.6669 - val_raw_multi_label_accuracy: 0.2458\n",
      "Epoch 21/1000\n",
      " - 8s - loss: 0.1575 - raw_multi_label_accuracy: 0.8790 - val_loss: 0.6876 - val_raw_multi_label_accuracy: 0.2467\n",
      "Epoch 22/1000\n",
      " - 8s - loss: 0.1484 - raw_multi_label_accuracy: 0.8831 - val_loss: 0.6682 - val_raw_multi_label_accuracy: 0.2659\n",
      "Epoch 23/1000\n",
      " - 8s - loss: 0.1394 - raw_multi_label_accuracy: 0.8845 - val_loss: 0.6901 - val_raw_multi_label_accuracy: 0.2788\n",
      "Epoch 24/1000\n",
      " - 8s - loss: 0.1284 - raw_multi_label_accuracy: 0.9089 - val_loss: 0.6968 - val_raw_multi_label_accuracy: 0.2782\n",
      "Epoch 25/1000\n",
      " - 8s - loss: 0.1231 - raw_multi_label_accuracy: 0.9065 - val_loss: 0.7165 - val_raw_multi_label_accuracy: 0.2948\n",
      "Epoch 26/1000\n",
      " - 8s - loss: 0.1138 - raw_multi_label_accuracy: 0.9163 - val_loss: 0.7567 - val_raw_multi_label_accuracy: 0.2808\n",
      "Epoch 27/1000\n",
      " - 8s - loss: 0.1105 - raw_multi_label_accuracy: 0.9252 - val_loss: 0.7482 - val_raw_multi_label_accuracy: 0.2840\n",
      "Epoch 28/1000\n",
      " - 8s - loss: 0.1028 - raw_multi_label_accuracy: 0.9311 - val_loss: 0.7443 - val_raw_multi_label_accuracy: 0.2905\n",
      "Epoch 29/1000\n",
      " - 8s - loss: 0.0958 - raw_multi_label_accuracy: 0.9349 - val_loss: 0.7537 - val_raw_multi_label_accuracy: 0.2961\n",
      "Epoch 30/1000\n",
      " - 8s - loss: 0.0906 - raw_multi_label_accuracy: 0.9452 - val_loss: 0.7764 - val_raw_multi_label_accuracy: 0.2828\n",
      "Epoch 31/1000\n",
      " - 8s - loss: 0.0869 - raw_multi_label_accuracy: 0.9491 - val_loss: 0.7900 - val_raw_multi_label_accuracy: 0.2977\n",
      "Epoch 32/1000\n",
      " - 8s - loss: 0.0830 - raw_multi_label_accuracy: 0.9496 - val_loss: 0.8140 - val_raw_multi_label_accuracy: 0.2876\n",
      "Epoch 33/1000\n",
      " - 10s - loss: 0.0788 - raw_multi_label_accuracy: 0.9542 - val_loss: 0.8378 - val_raw_multi_label_accuracy: 0.2953\n",
      "Epoch 34/1000\n",
      " - 9s - loss: 0.0761 - raw_multi_label_accuracy: 0.9574 - val_loss: 0.8448 - val_raw_multi_label_accuracy: 0.2891\n",
      "Epoch 35/1000\n",
      " - 11s - loss: 0.0726 - raw_multi_label_accuracy: 0.9626 - val_loss: 0.8403 - val_raw_multi_label_accuracy: 0.2902\n",
      "Epoch 36/1000\n",
      " - 8s - loss: 0.0696 - raw_multi_label_accuracy: 0.9635 - val_loss: 0.8370 - val_raw_multi_label_accuracy: 0.3052\n",
      "Epoch 37/1000\n",
      " - 8s - loss: 0.0678 - raw_multi_label_accuracy: 0.9639 - val_loss: 0.8573 - val_raw_multi_label_accuracy: 0.3018\n",
      "Epoch 38/1000\n",
      " - 8s - loss: 0.0663 - raw_multi_label_accuracy: 0.9645 - val_loss: 0.9248 - val_raw_multi_label_accuracy: 0.3059\n",
      "Epoch 39/1000\n",
      " - 8s - loss: 0.0661 - raw_multi_label_accuracy: 0.9643 - val_loss: 0.8900 - val_raw_multi_label_accuracy: 0.3011\n",
      "Epoch 40/1000\n",
      " - 8s - loss: 0.0627 - raw_multi_label_accuracy: 0.9673 - val_loss: 0.9075 - val_raw_multi_label_accuracy: 0.2994\n",
      "Epoch 41/1000\n",
      " - 8s - loss: 0.0595 - raw_multi_label_accuracy: 0.9699 - val_loss: 0.8611 - val_raw_multi_label_accuracy: 0.3019\n",
      "Epoch 42/1000\n",
      " - 8s - loss: 0.0584 - raw_multi_label_accuracy: 0.9712 - val_loss: 0.8815 - val_raw_multi_label_accuracy: 0.2851\n",
      "Epoch 43/1000\n",
      " - 8s - loss: 0.0562 - raw_multi_label_accuracy: 0.9759 - val_loss: 0.9154 - val_raw_multi_label_accuracy: 0.2905\n",
      "Time to train with cross validation for early stopping: 344.8250980377197 seconds\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(max_seq_len,), dtype='int32')\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)(model_input)\n",
    "two_word_filter = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(e)\n",
    "two_word_filter = GlobalMaxPooling1D()(two_word_filter)\n",
    "three_word_filter = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(e)\n",
    "three_word_filter = GlobalMaxPooling1D()(three_word_filter)\n",
    "four_word_filter = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(e)\n",
    "four_word_filter = GlobalMaxPooling1D()(four_word_filter)\n",
    "merged = concatenate([two_word_filter, three_word_filter, four_word_filter], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(len(genre_dict))(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[model_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "start = time.time()\n",
    "model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
    "end = time.time()\n",
    "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.639751552795031\n",
      "Precision for Action-Adventure: 0.5448275862068965\n",
      "Recall for Action-Adventure: 0.42245989304812837\n",
      "\n",
      "Accuruacy for Romance: 0.7577639751552795\n",
      "Precision for Romance: 0.39622641509433965\n",
      "Recall for Romance: 0.19811320754716982\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.6521739130434783\n",
      "Precision for Horror-Thriller: 0.5821917808219178\n",
      "Recall for Horror-Thriller: 0.4427083333333333\n",
      "\n",
      "Accuruacy for Comedy: 0.639751552795031\n",
      "Precision for Comedy: 0.5951219512195122\n",
      "Recall for Comedy: 0.5727699530516432\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8799171842650103\n",
      "Precision for Science Fiction: 0.375\n",
      "Recall for Science Fiction: 0.05357142857142857\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.3730158730158732\n",
      "Multilabel precision: 0.5688736681887367\n",
      "Multilabel recall: 0.43391994478951007\n",
      "Percent of correctly decided label decisions: 71.3871635610766\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.6183 - raw_multi_label_accuracy: 0.0487 - val_loss: 0.5903 - val_raw_multi_label_accuracy: 0.0262\n",
      "Epoch 2/1000\n",
      " - 4s - loss: 0.5781 - raw_multi_label_accuracy: 0.0736 - val_loss: 0.5860 - val_raw_multi_label_accuracy: 0.0819\n",
      "Epoch 3/1000\n",
      " - 5s - loss: 0.5569 - raw_multi_label_accuracy: 0.1473 - val_loss: 0.5840 - val_raw_multi_label_accuracy: 0.1050\n",
      "Epoch 4/1000\n",
      " - 3s - loss: 0.5247 - raw_multi_label_accuracy: 0.2209 - val_loss: 0.5943 - val_raw_multi_label_accuracy: 0.1416\n",
      "Epoch 5/1000\n",
      " - 3s - loss: 0.4761 - raw_multi_label_accuracy: 0.3563 - val_loss: 0.5967 - val_raw_multi_label_accuracy: 0.1436\n",
      "Epoch 6/1000\n",
      " - 3s - loss: 0.3878 - raw_multi_label_accuracy: 0.5509 - val_loss: 0.5846 - val_raw_multi_label_accuracy: 0.2541\n",
      "Epoch 7/1000\n",
      " - 3s - loss: 0.2825 - raw_multi_label_accuracy: 0.7105 - val_loss: 0.5835 - val_raw_multi_label_accuracy: 0.2423\n",
      "Epoch 8/1000\n",
      " - 3s - loss: 0.1941 - raw_multi_label_accuracy: 0.8348 - val_loss: 0.5988 - val_raw_multi_label_accuracy: 0.2392\n",
      "Epoch 9/1000\n",
      " - 3s - loss: 0.1295 - raw_multi_label_accuracy: 0.9135 - val_loss: 0.6423 - val_raw_multi_label_accuracy: 0.2630\n",
      "Epoch 10/1000\n",
      " - 3s - loss: 0.0867 - raw_multi_label_accuracy: 0.9504 - val_loss: 0.6531 - val_raw_multi_label_accuracy: 0.2185\n",
      "Epoch 11/1000\n",
      " - 3s - loss: 0.0585 - raw_multi_label_accuracy: 0.9721 - val_loss: 0.6805 - val_raw_multi_label_accuracy: 0.2404\n",
      "Epoch 12/1000\n",
      " - 3s - loss: 0.0402 - raw_multi_label_accuracy: 0.9843 - val_loss: 0.6814 - val_raw_multi_label_accuracy: 0.2636\n",
      "Epoch 13/1000\n",
      " - 3s - loss: 0.0288 - raw_multi_label_accuracy: 0.9907 - val_loss: 0.7228 - val_raw_multi_label_accuracy: 0.2477\n",
      "Epoch 14/1000\n",
      " - 3s - loss: 0.0214 - raw_multi_label_accuracy: 0.9945 - val_loss: 0.7354 - val_raw_multi_label_accuracy: 0.2472\n",
      "Epoch 15/1000\n",
      " - 3s - loss: 0.0162 - raw_multi_label_accuracy: 0.9963 - val_loss: 0.7532 - val_raw_multi_label_accuracy: 0.2586\n",
      "Epoch 16/1000\n",
      " - 3s - loss: 0.0128 - raw_multi_label_accuracy: 0.9974 - val_loss: 0.7565 - val_raw_multi_label_accuracy: 0.2568\n",
      "Epoch 17/1000\n",
      " - 3s - loss: 0.0104 - raw_multi_label_accuracy: 0.9981 - val_loss: 0.7972 - val_raw_multi_label_accuracy: 0.2417\n",
      "Epoch 18/1000\n",
      " - 3s - loss: 0.0087 - raw_multi_label_accuracy: 0.9989 - val_loss: 0.7949 - val_raw_multi_label_accuracy: 0.2574\n",
      "Epoch 19/1000\n",
      " - 3s - loss: 0.0072 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.8440 - val_raw_multi_label_accuracy: 0.2446\n",
      "Epoch 20/1000\n",
      " - 3s - loss: 0.0063 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.8236 - val_raw_multi_label_accuracy: 0.2405\n",
      "Epoch 21/1000\n",
      " - 3s - loss: 0.0054 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.8360 - val_raw_multi_label_accuracy: 0.2423\n",
      "Epoch 22/1000\n",
      " - 3s - loss: 0.0048 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.8501 - val_raw_multi_label_accuracy: 0.2419\n",
      "Epoch 23/1000\n",
      " - 3s - loss: 0.0043 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.8607 - val_raw_multi_label_accuracy: 0.2384\n",
      "Epoch 24/1000\n",
      " - 3s - loss: 0.0039 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.8584 - val_raw_multi_label_accuracy: 0.2438\n",
      "Epoch 25/1000\n",
      " - 3s - loss: 0.0035 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.8803 - val_raw_multi_label_accuracy: 0.2348\n",
      "Epoch 26/1000\n",
      " - 3s - loss: 0.0032 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.8930 - val_raw_multi_label_accuracy: 0.2362\n",
      "Epoch 27/1000\n",
      " - 3s - loss: 0.0029 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.8860 - val_raw_multi_label_accuracy: 0.2439\n",
      "Epoch 28/1000\n",
      " - 3s - loss: 0.0028 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.9077 - val_raw_multi_label_accuracy: 0.2371\n",
      "Epoch 29/1000\n",
      " - 3s - loss: 0.0025 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9092 - val_raw_multi_label_accuracy: 0.2361\n",
      "Epoch 30/1000\n",
      " - 3s - loss: 0.0024 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9147 - val_raw_multi_label_accuracy: 0.2402\n",
      "Epoch 31/1000\n",
      " - 3s - loss: 0.0022 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.9125 - val_raw_multi_label_accuracy: 0.2328\n",
      "Epoch 32/1000\n",
      " - 3s - loss: 0.0022 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9646 - val_raw_multi_label_accuracy: 0.2447\n",
      "Epoch 33/1000\n",
      " - 3s - loss: 0.0020 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9152 - val_raw_multi_label_accuracy: 0.2412\n",
      "Epoch 34/1000\n",
      " - 3s - loss: 0.0019 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9481 - val_raw_multi_label_accuracy: 0.2389\n",
      "Epoch 35/1000\n",
      " - 3s - loss: 0.0018 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.9548 - val_raw_multi_label_accuracy: 0.2356\n",
      "Epoch 36/1000\n",
      " - 3s - loss: 0.0017 - raw_multi_label_accuracy: 0.9993 - val_loss: 0.9613 - val_raw_multi_label_accuracy: 0.2353\n",
      "Epoch 37/1000\n",
      " - 3s - loss: 0.0017 - raw_multi_label_accuracy: 0.9992 - val_loss: 0.9413 - val_raw_multi_label_accuracy: 0.2404\n",
      "Time to train with cross validation for early stopping: 124.4597179889679 seconds\n"
     ]
    }
   ],
   "source": [
    "normal_nn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "normal_nn.add(e)\n",
    "normal_nn.add(Flatten())\n",
    "normal_nn.add(Dense(256, activation='relu'))\n",
    "normal_nn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "normal_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "start = time.time()\n",
    "normal_nn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
    "end = time.time()\n",
    "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(normal_nn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.6563146997929606\n",
      "Precision for Action-Adventure: 0.6129032258064516\n",
      "Recall for Action-Adventure: 0.3048128342245989\n",
      "\n",
      "Accuruacy for Romance: 0.7660455486542443\n",
      "Precision for Romance: 0.41025641025641024\n",
      "Recall for Romance: 0.1509433962264151\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.6231884057971014\n",
      "Precision for Horror-Thriller: 0.5581395348837209\n",
      "Recall for Horror-Thriller: 0.25\n",
      "\n",
      "Accuruacy for Comedy: 0.577639751552795\n",
      "Precision for Comedy: 0.5302013422818792\n",
      "Recall for Comedy: 0.37089201877934275\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8881987577639752\n",
      "Precision for Science Fiction: 0.6666666666666666\n",
      "Recall for Science Fiction: 0.07142857142857142\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.26104209799861966\n",
      "Multilabel precision: 0.5411585365853658\n",
      "Multilabel recall: 0.28209109730848864\n",
      "Percent of correctly decided label decisions: 70.22774327122153\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 18s - loss: 0.6365 - raw_multi_label_accuracy: 0.0555 - val_loss: 0.5856 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 17s - loss: 0.5950 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5837 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 16s - loss: 0.5891 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5815 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 15s - loss: 0.5863 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5850 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 16s - loss: 0.5849 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5806 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 15s - loss: 0.5814 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5771 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 16s - loss: 0.5696 - raw_multi_label_accuracy: 0.0550 - val_loss: 0.5709 - val_raw_multi_label_accuracy: 0.0367\n",
      "Epoch 8/1000\n",
      " - 15s - loss: 0.5329 - raw_multi_label_accuracy: 0.1794 - val_loss: 0.5566 - val_raw_multi_label_accuracy: 0.2374\n",
      "Epoch 9/1000\n",
      " - 15s - loss: 0.4694 - raw_multi_label_accuracy: 0.4015 - val_loss: 0.5229 - val_raw_multi_label_accuracy: 0.3224\n",
      "Epoch 10/1000\n",
      " - 15s - loss: 0.4152 - raw_multi_label_accuracy: 0.5023 - val_loss: 0.4885 - val_raw_multi_label_accuracy: 0.3548\n",
      "Epoch 11/1000\n",
      " - 16s - loss: 0.3770 - raw_multi_label_accuracy: 0.5399 - val_loss: 0.4802 - val_raw_multi_label_accuracy: 0.3870\n",
      "Epoch 12/1000\n",
      " - 16s - loss: 0.3485 - raw_multi_label_accuracy: 0.5825 - val_loss: 0.5042 - val_raw_multi_label_accuracy: 0.3812\n",
      "Epoch 13/1000\n",
      " - 15s - loss: 0.3143 - raw_multi_label_accuracy: 0.6202 - val_loss: 0.5090 - val_raw_multi_label_accuracy: 0.4081\n",
      "Epoch 14/1000\n",
      " - 16s - loss: 0.2769 - raw_multi_label_accuracy: 0.6622 - val_loss: 0.5159 - val_raw_multi_label_accuracy: 0.4157\n",
      "Epoch 15/1000\n",
      " - 16s - loss: 0.2459 - raw_multi_label_accuracy: 0.6924 - val_loss: 0.5400 - val_raw_multi_label_accuracy: 0.3990\n",
      "Epoch 16/1000\n",
      " - 16s - loss: 0.2188 - raw_multi_label_accuracy: 0.7342 - val_loss: 0.5782 - val_raw_multi_label_accuracy: 0.3882\n",
      "Epoch 17/1000\n",
      " - 16s - loss: 0.1810 - raw_multi_label_accuracy: 0.7789 - val_loss: 0.6500 - val_raw_multi_label_accuracy: 0.4010\n",
      "Epoch 18/1000\n",
      " - 16s - loss: 0.1541 - raw_multi_label_accuracy: 0.8119 - val_loss: 0.6952 - val_raw_multi_label_accuracy: 0.4038\n",
      "Epoch 19/1000\n",
      " - 17s - loss: 0.1326 - raw_multi_label_accuracy: 0.8383 - val_loss: 0.7373 - val_raw_multi_label_accuracy: 0.4012\n",
      "Epoch 20/1000\n",
      " - 16s - loss: 0.1151 - raw_multi_label_accuracy: 0.8625 - val_loss: 0.7850 - val_raw_multi_label_accuracy: 0.3917\n",
      "Epoch 21/1000\n",
      " - 16s - loss: 0.1001 - raw_multi_label_accuracy: 0.8831 - val_loss: 0.7972 - val_raw_multi_label_accuracy: 0.3867\n",
      "Epoch 22/1000\n",
      " - 18s - loss: 0.0841 - raw_multi_label_accuracy: 0.8966 - val_loss: 0.8580 - val_raw_multi_label_accuracy: 0.3830\n",
      "Epoch 23/1000\n",
      " - 16s - loss: 0.0737 - raw_multi_label_accuracy: 0.9130 - val_loss: 0.9454 - val_raw_multi_label_accuracy: 0.3760\n",
      "Epoch 24/1000\n",
      " - 16s - loss: 0.0683 - raw_multi_label_accuracy: 0.9171 - val_loss: 0.9227 - val_raw_multi_label_accuracy: 0.3808\n",
      "Epoch 25/1000\n",
      " - 16s - loss: 0.0603 - raw_multi_label_accuracy: 0.9296 - val_loss: 0.9918 - val_raw_multi_label_accuracy: 0.3855\n",
      "Epoch 26/1000\n",
      " - 16s - loss: 0.0535 - raw_multi_label_accuracy: 0.9343 - val_loss: 0.9779 - val_raw_multi_label_accuracy: 0.3809\n",
      "Epoch 27/1000\n",
      " - 17s - loss: 0.0479 - raw_multi_label_accuracy: 0.9494 - val_loss: 1.0009 - val_raw_multi_label_accuracy: 0.3950\n",
      "Epoch 28/1000\n",
      " - 16s - loss: 0.0434 - raw_multi_label_accuracy: 0.9562 - val_loss: 1.0431 - val_raw_multi_label_accuracy: 0.3991\n",
      "Epoch 29/1000\n",
      " - 16s - loss: 0.0419 - raw_multi_label_accuracy: 0.9532 - val_loss: 1.1047 - val_raw_multi_label_accuracy: 0.3896\n",
      "Epoch 30/1000\n",
      " - 16s - loss: 0.0357 - raw_multi_label_accuracy: 0.9660 - val_loss: 1.0820 - val_raw_multi_label_accuracy: 0.3941\n",
      "Epoch 31/1000\n",
      " - 16s - loss: 0.0327 - raw_multi_label_accuracy: 0.9641 - val_loss: 1.1490 - val_raw_multi_label_accuracy: 0.4100\n",
      "Epoch 32/1000\n",
      " - 16s - loss: 0.0307 - raw_multi_label_accuracy: 0.9649 - val_loss: 1.1713 - val_raw_multi_label_accuracy: 0.3990\n",
      "Epoch 33/1000\n",
      " - 16s - loss: 0.0291 - raw_multi_label_accuracy: 0.9689 - val_loss: 1.1971 - val_raw_multi_label_accuracy: 0.3974\n",
      "Epoch 34/1000\n",
      " - 17s - loss: 0.0268 - raw_multi_label_accuracy: 0.9715 - val_loss: 1.2376 - val_raw_multi_label_accuracy: 0.4129\n",
      "Epoch 35/1000\n",
      " - 16s - loss: 0.0260 - raw_multi_label_accuracy: 0.9721 - val_loss: 1.2771 - val_raw_multi_label_accuracy: 0.3960\n",
      "Epoch 36/1000\n",
      " - 16s - loss: 0.0244 - raw_multi_label_accuracy: 0.9746 - val_loss: 1.2591 - val_raw_multi_label_accuracy: 0.3928\n",
      "Epoch 37/1000\n",
      " - 16s - loss: 0.0221 - raw_multi_label_accuracy: 0.9758 - val_loss: 1.2765 - val_raw_multi_label_accuracy: 0.3955\n",
      "Epoch 38/1000\n",
      " - 16s - loss: 0.0203 - raw_multi_label_accuracy: 0.9801 - val_loss: 1.3295 - val_raw_multi_label_accuracy: 0.3940\n",
      "Epoch 39/1000\n",
      " - 16s - loss: 0.0191 - raw_multi_label_accuracy: 0.9810 - val_loss: 1.3203 - val_raw_multi_label_accuracy: 0.3976\n",
      "Time to train with cross validation for early stopping: 627.1249330043793 seconds\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "lstm_model.add(e)\n",
    "lstm_model.add(LSTM(100, dropout=0.25, recurrent_dropout=0.25))\n",
    "lstm_model.add(Dense(256, activation='relu'))\n",
    "lstm_model.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "start = time.time()\n",
    "lstm_model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
    "end = time.time()\n",
    "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(lstm_model.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.6211180124223602\n",
      "Precision for Action-Adventure: 0.5088495575221239\n",
      "Recall for Action-Adventure: 0.6149732620320856\n",
      "\n",
      "Accuruacy for Romance: 0.7660455486542443\n",
      "Precision for Romance: 0.45569620253164556\n",
      "Recall for Romance: 0.33962264150943394\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.6583850931677019\n",
      "Precision for Horror-Thriller: 0.5551020408163265\n",
      "Recall for Horror-Thriller: 0.7083333333333334\n",
      "\n",
      "Accuruacy for Comedy: 0.7039337474120083\n",
      "Precision for Comedy: 0.63671875\n",
      "Recall for Comedy: 0.7652582159624414\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8695652173913043\n",
      "Precision for Science Fiction: 0.36\n",
      "Recall for Science Fiction: 0.16071428571428573\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.4722912353347138\n",
      "Multilabel precision: 0.5798826777087646\n",
      "Multilabel recall: 0.6378536922015182\n",
      "Percent of correctly decided label decisions: 72.38095238095238\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.6386 - raw_multi_label_accuracy: 0.0576 - val_loss: 0.5895 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 3s - loss: 0.5938 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5858 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 3s - loss: 0.5811 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5830 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 3s - loss: 0.5659 - raw_multi_label_accuracy: 0.0000e+00 - val_loss: 0.5828 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 3s - loss: 0.5431 - raw_multi_label_accuracy: 3.4046e-04 - val_loss: 0.5754 - val_raw_multi_label_accuracy: 0.0033\n",
      "Epoch 6/1000\n",
      " - 3s - loss: 0.4942 - raw_multi_label_accuracy: 0.1308 - val_loss: 0.5847 - val_raw_multi_label_accuracy: 0.0353\n",
      "Epoch 7/1000\n",
      " - 3s - loss: 0.4102 - raw_multi_label_accuracy: 0.4509 - val_loss: 0.5972 - val_raw_multi_label_accuracy: 0.0935\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 0.3167 - raw_multi_label_accuracy: 0.6290 - val_loss: 0.6449 - val_raw_multi_label_accuracy: 0.1394\n",
      "Epoch 9/1000\n",
      " - 3s - loss: 0.2278 - raw_multi_label_accuracy: 0.7468 - val_loss: 0.7228 - val_raw_multi_label_accuracy: 0.1236\n",
      "Epoch 10/1000\n",
      " - 3s - loss: 0.1484 - raw_multi_label_accuracy: 0.8343 - val_loss: 0.8496 - val_raw_multi_label_accuracy: 0.1806\n",
      "Epoch 11/1000\n",
      " - 2s - loss: 0.1442 - raw_multi_label_accuracy: 0.8545 - val_loss: 0.7828 - val_raw_multi_label_accuracy: 0.2054\n",
      "Epoch 12/1000\n",
      " - 3s - loss: 0.1534 - raw_multi_label_accuracy: 0.8439 - val_loss: 0.7637 - val_raw_multi_label_accuracy: 0.1849\n",
      "Epoch 13/1000\n",
      " - 3s - loss: 0.0916 - raw_multi_label_accuracy: 0.9144 - val_loss: 0.8956 - val_raw_multi_label_accuracy: 0.1963\n",
      "Epoch 14/1000\n",
      " - 3s - loss: 0.0603 - raw_multi_label_accuracy: 0.9475 - val_loss: 1.0406 - val_raw_multi_label_accuracy: 0.2185\n",
      "Epoch 15/1000\n",
      " - 3s - loss: 0.0431 - raw_multi_label_accuracy: 0.9669 - val_loss: 1.1862 - val_raw_multi_label_accuracy: 0.2202\n",
      "Epoch 16/1000\n",
      " - 2s - loss: 0.0303 - raw_multi_label_accuracy: 0.9758 - val_loss: 1.2502 - val_raw_multi_label_accuracy: 0.2230\n",
      "Epoch 17/1000\n",
      " - 3s - loss: 0.0222 - raw_multi_label_accuracy: 0.9850 - val_loss: 1.3296 - val_raw_multi_label_accuracy: 0.2323\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 0.0161 - raw_multi_label_accuracy: 0.9884 - val_loss: 1.3970 - val_raw_multi_label_accuracy: 0.2557\n",
      "Epoch 19/1000\n",
      " - 2s - loss: 0.0121 - raw_multi_label_accuracy: 0.9937 - val_loss: 1.4593 - val_raw_multi_label_accuracy: 0.2407\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 0.0082 - raw_multi_label_accuracy: 0.9952 - val_loss: 1.5681 - val_raw_multi_label_accuracy: 0.2568\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 0.0058 - raw_multi_label_accuracy: 0.9975 - val_loss: 1.6380 - val_raw_multi_label_accuracy: 0.2585\n",
      "Epoch 22/1000\n",
      " - 2s - loss: 0.0045 - raw_multi_label_accuracy: 0.9965 - val_loss: 1.6586 - val_raw_multi_label_accuracy: 0.2401\n",
      "Epoch 23/1000\n",
      " - 3s - loss: 0.0035 - raw_multi_label_accuracy: 0.9977 - val_loss: 1.7584 - val_raw_multi_label_accuracy: 0.2590\n",
      "Epoch 24/1000\n",
      " - 3s - loss: 0.0028 - raw_multi_label_accuracy: 0.9982 - val_loss: 1.7646 - val_raw_multi_label_accuracy: 0.2546\n",
      "Epoch 25/1000\n",
      " - 2s - loss: 0.0023 - raw_multi_label_accuracy: 0.9982 - val_loss: 1.8250 - val_raw_multi_label_accuracy: 0.2622\n",
      "Epoch 26/1000\n",
      " - 2s - loss: 0.0019 - raw_multi_label_accuracy: 0.9993 - val_loss: 1.8477 - val_raw_multi_label_accuracy: 0.2488\n",
      "Epoch 27/1000\n",
      " - 2s - loss: 0.0018 - raw_multi_label_accuracy: 0.9982 - val_loss: 1.9746 - val_raw_multi_label_accuracy: 0.2589\n",
      "Epoch 28/1000\n",
      " - 3s - loss: 0.0017 - raw_multi_label_accuracy: 0.9985 - val_loss: 1.9446 - val_raw_multi_label_accuracy: 0.2540\n",
      "Epoch 29/1000\n",
      " - 3s - loss: 0.0017 - raw_multi_label_accuracy: 0.9981 - val_loss: 1.9652 - val_raw_multi_label_accuracy: 0.2537\n",
      "Epoch 30/1000\n",
      " - 3s - loss: 0.0014 - raw_multi_label_accuracy: 0.9985 - val_loss: 2.0074 - val_raw_multi_label_accuracy: 0.2539\n",
      "Epoch 31/1000\n",
      " - 2s - loss: 0.0015 - raw_multi_label_accuracy: 0.9986 - val_loss: 2.0802 - val_raw_multi_label_accuracy: 0.2473\n",
      "Epoch 32/1000\n",
      " - 3s - loss: 0.0012 - raw_multi_label_accuracy: 0.9993 - val_loss: 2.1282 - val_raw_multi_label_accuracy: 0.2738\n",
      "Epoch 33/1000\n",
      " - 2s - loss: 0.0012 - raw_multi_label_accuracy: 0.9989 - val_loss: 2.0910 - val_raw_multi_label_accuracy: 0.2502\n",
      "Epoch 34/1000\n",
      " - 2s - loss: 0.0010 - raw_multi_label_accuracy: 0.9993 - val_loss: 2.1838 - val_raw_multi_label_accuracy: 0.2614\n",
      "Epoch 35/1000\n",
      " - 3s - loss: 0.0010 - raw_multi_label_accuracy: 0.9989 - val_loss: 2.1493 - val_raw_multi_label_accuracy: 0.2453\n",
      "Epoch 36/1000\n",
      " - 2s - loss: 9.0611e-04 - raw_multi_label_accuracy: 0.9997 - val_loss: 2.2594 - val_raw_multi_label_accuracy: 0.2445\n",
      "Epoch 37/1000\n",
      " - 3s - loss: 0.0011 - raw_multi_label_accuracy: 0.9989 - val_loss: 2.2527 - val_raw_multi_label_accuracy: 0.2487\n",
      "Time to train with cross validation for early stopping: 98.11795949935913 seconds\n"
     ]
    }
   ],
   "source": [
    "rnn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "rnn.add(e)\n",
    "rnn.add(SimpleRNN(32, activation = 'relu'))\n",
    "rnn.add(Dense(256, activation='relu'))\n",
    "rnn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "start = time.time()\n",
    "rnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
    "end = time.time()\n",
    "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(rnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting evaluation metrics for each label:\n",
      "Accuruacy for Action-Adventure: 0.5631469979296067\n",
      "Precision for Action-Adventure: 0.4375\n",
      "Recall for Action-Adventure: 0.44919786096256686\n",
      "\n",
      "Accuruacy for Romance: 0.7370600414078675\n",
      "Precision for Romance: 0.29411764705882354\n",
      "Recall for Romance: 0.14150943396226415\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.5631469979296067\n",
      "Precision for Horror-Thriller: 0.45320197044334976\n",
      "Recall for Horror-Thriller: 0.4791666666666667\n",
      "\n",
      "Accuruacy for Comedy: 0.5134575569358178\n",
      "Precision for Comedy: 0.46099290780141844\n",
      "Recall for Comedy: 0.6103286384976526\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8819875776397516\n",
      "Precision for Science Fiction: 0.4\n",
      "Recall for Science Fiction: 0.03571428571428571\n",
      "\n",
      "Getting evaluations for multilabel problem\n",
      "Multilabel accuracy: 0.32349896480331264\n",
      "Multilabel precision: 0.43768115942029\n",
      "Multilabel recall: 0.4428916494133886\n",
      "Percent of correctly decided label decisions: 65.175983436853\n"
     ]
    }
   ],
   "source": [
    "get_all_metrics(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
