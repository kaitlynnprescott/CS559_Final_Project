{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading in data properly\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "all_data = all_data.dropna(subset=['overview', 'genres']) #drop cols without overview or genre (data we use or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "def parse_json(x):\n",
    "    try:\n",
    "        return json.loads(x.replace(\"'\", '\"'))[0]['name']\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def parse_genres_json(x):\n",
    "    try:\n",
    "        json_genres = json.loads(x.replace(\"'\", '\"'))\n",
    "        numElems = len(json_genres)\n",
    "        ret = [0]*len(genre_dict) #number of genres we are looking at\n",
    "        for i in range(numElems):\n",
    "            genre_str = (json_genres[i]['name'])\n",
    "            if genre_str in genre_map.keys():\n",
    "                ret[genre_dict[genre_map[genre_str]]] = 1\n",
    "        return ret\n",
    "    except Exception as excep:\n",
    "        print('Exception' + str(excep))\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure': 0,\n",
       " 'Romance': 1,\n",
       " 'Horror-Thriller': 2,\n",
       " 'Comedy': 3,\n",
       " 'Science Fiction': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {}\n",
    "genre_dict['Action-Adventure'] = 0\n",
    "genre_dict['Romance'] = 1\n",
    "genre_dict['Horror-Thriller'] = 2\n",
    "genre_dict['Comedy'] = 3\n",
    "genre_dict['Science Fiction'] = 4\n",
    "#genre_dict['Drama'] = 5\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_map = {}\n",
    "genre_map['Adventure'] = 'Action-Adventure'\n",
    "genre_map['Romance'] = 'Romance'\n",
    "genre_map['Horror'] = 'Horror-Thriller'\n",
    "genre_map['Thriller'] = 'Horror-Thriller'\n",
    "genre_map['Comedy'] = 'Comedy'\n",
    "#genre_map['War'] = 'Action-Adventure'#not sure about this\n",
    "genre_map['Action'] = 'Action-Adventure'\n",
    "genre_map['Science Fiction'] = 'Science Fiction'\n",
    "#genre_map['Drama'] = 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenresVects():\n",
    "    y = all_data['genres']\n",
    "    ret = y.apply(parse_genres_json)\n",
    "    all_data['genres_vect'] = ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vects = getGenresVects() #get label vectors for genres indexed by indexes in genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put to lower case, remove punctation\n",
    "def cleanText(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    text = ' '.join(no_stopword_text)\n",
    "    text = re.sub(r'[^a-z A-Z0-9]', \"\", text) #maybe shouldn't remove punction between words here?\n",
    "    text = text.lower()\n",
    "    return text\n",
    "all_data['cleanOverview'] = all_data['overview'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.genres_vect.map(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression data\n",
    "lr_data = all_data[['cleanOverview', 'genres_vect', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(lr_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN STUFF here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word embeddings\n",
    "x = train['cleanOverview'].values.tolist()\n",
    "y = train['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['cleanOverview'].values.tolist()\n",
    "y_test = test['genres_vect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.tolist()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = [word_tokenize(sent) for sent in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_len = 32\n",
    "model = Word2Vec(tok, min_count = 2, size=word_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
    "\n",
    "tokenizer = Tokenizer(num_words_kept)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_seq_len = 150\n",
    "\n",
    "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model.wv.vocab.keys():\n",
    "    embeddings_index[w] = model.wv[w]\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words_kept:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
    "    for genre in genre_dict.keys():\n",
    "        index = genre_dict[genre]\n",
    "        real_labels_vect = real_labels_matrix[:, index]\n",
    "        prediction_vect = predictions_labels_matrix[:,index]\n",
    "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
    "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of intersection of predicted and actual labels divided by size of their union for each datapoint tested on\n",
    "#sum those and then divide by number of datapoints\n",
    "#vectorized for speed\n",
    "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    union = real_labels_matrix | predictions_labels_matrix\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
    "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
    "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    precision_sum = 0\n",
    "    num_rows = 0\n",
    "    for row in range(intersection.shape[0]):\n",
    "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
    "            num_rows += 1\n",
    "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
    "    if num_rows == 0:\n",
    "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
    "    return precision_sum / num_rows\n",
    "\n",
    "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
    "#sum those and divide by number of datapoints\n",
    "#all datapoints should have at least 1 real label in this data set\n",
    "#vectorized for speed\n",
    "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
    "    #binary so set intersection is and operator\n",
    "    intersection = real_labels_matrix & predictions_labels_matrix\n",
    "    #set union for binary is same as or operator\n",
    "    #sum(array.T) gets number of 1s in row\n",
    "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
    "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
    "\n",
    "#lower is better\n",
    "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
    "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#metric for keras for early stopping\n",
    "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
    "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
    "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
    "def raw_multi_label_accuracy(y_true, y_pred):\n",
    "    positives = K.greater_equal(y_pred, 0.5)\n",
    "    positives = K.cast(positives, K.floatx())\n",
    "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
    "    intersection = y_true * new_y_pred\n",
    "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
    "    accuracy = K.sum(intersection) / K.sum(union)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
    "class DelayedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
    "        super(DelayedEarlyStopping, self).__init__()\n",
    "        self.delay = delay\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.delay:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matt/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 2.0752 - raw_multi_label_accuracy: 0.1131 - val_loss: 1.7520 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 1.5738 - raw_multi_label_accuracy: 0.0873 - val_loss: 1.3526 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 1.2372 - raw_multi_label_accuracy: 0.0800 - val_loss: 1.0825 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 1.0080 - raw_multi_label_accuracy: 0.0626 - val_loss: 0.9024 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.8559 - raw_multi_label_accuracy: 0.0500 - val_loss: 0.7847 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 0.7589 - raw_multi_label_accuracy: 0.0370 - val_loss: 0.7092 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 0.6971 - raw_multi_label_accuracy: 0.0271 - val_loss: 0.6612 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.6559 - raw_multi_label_accuracy: 0.0268 - val_loss: 0.6315 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.6320 - raw_multi_label_accuracy: 0.0203 - val_loss: 0.6149 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.6168 - raw_multi_label_accuracy: 0.0218 - val_loss: 0.6028 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.6090 - raw_multi_label_accuracy: 0.0160 - val_loss: 0.5980 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      " - 2s - loss: 0.6016 - raw_multi_label_accuracy: 0.0125 - val_loss: 0.5925 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      " - 2s - loss: 0.5967 - raw_multi_label_accuracy: 0.0110 - val_loss: 0.5914 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 0.5939 - raw_multi_label_accuracy: 0.0056 - val_loss: 0.5904 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.5906 - raw_multi_label_accuracy: 0.0059 - val_loss: 0.5903 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.5849 - raw_multi_label_accuracy: 0.0120 - val_loss: 0.5915 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.5754 - raw_multi_label_accuracy: 0.0128 - val_loss: 0.5975 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.5632 - raw_multi_label_accuracy: 0.0136 - val_loss: 0.6027 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 0.5536 - raw_multi_label_accuracy: 0.0400 - val_loss: 0.6057 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.5447 - raw_multi_label_accuracy: 0.0503 - val_loss: 0.6094 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.5376 - raw_multi_label_accuracy: 0.0602 - val_loss: 0.6128 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.5346 - raw_multi_label_accuracy: 0.0733 - val_loss: 0.6206 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.5286 - raw_multi_label_accuracy: 0.0773 - val_loss: 0.6217 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 0.5232 - raw_multi_label_accuracy: 0.0996 - val_loss: 0.6230 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.5171 - raw_multi_label_accuracy: 0.1034 - val_loss: 0.6321 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.5104 - raw_multi_label_accuracy: 0.1419 - val_loss: 0.6413 - val_raw_multi_label_accuracy: 0.0133\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 0.5082 - raw_multi_label_accuracy: 0.1668 - val_loss: 0.6386 - val_raw_multi_label_accuracy: 0.0165\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.5007 - raw_multi_label_accuracy: 0.1815 - val_loss: 0.6535 - val_raw_multi_label_accuracy: 0.0166\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.4921 - raw_multi_label_accuracy: 0.2165 - val_loss: 0.6688 - val_raw_multi_label_accuracy: 0.0571\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.4882 - raw_multi_label_accuracy: 0.2470 - val_loss: 0.6675 - val_raw_multi_label_accuracy: 0.1287\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.4878 - raw_multi_label_accuracy: 0.2560 - val_loss: 0.6755 - val_raw_multi_label_accuracy: 0.1396\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.4775 - raw_multi_label_accuracy: 0.2823 - val_loss: 0.7000 - val_raw_multi_label_accuracy: 0.1398\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.4756 - raw_multi_label_accuracy: 0.2896 - val_loss: 0.7102 - val_raw_multi_label_accuracy: 0.1510\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.4713 - raw_multi_label_accuracy: 0.3156 - val_loss: 0.7043 - val_raw_multi_label_accuracy: 0.1584\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.4674 - raw_multi_label_accuracy: 0.3278 - val_loss: 0.7024 - val_raw_multi_label_accuracy: 0.1527\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.4619 - raw_multi_label_accuracy: 0.3424 - val_loss: 0.7293 - val_raw_multi_label_accuracy: 0.1575\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.4593 - raw_multi_label_accuracy: 0.3546 - val_loss: 0.7603 - val_raw_multi_label_accuracy: 0.1578\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.4543 - raw_multi_label_accuracy: 0.3769 - val_loss: 0.7838 - val_raw_multi_label_accuracy: 0.1548\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.4544 - raw_multi_label_accuracy: 0.3924 - val_loss: 0.7655 - val_raw_multi_label_accuracy: 0.1516\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.4460 - raw_multi_label_accuracy: 0.4129 - val_loss: 0.7746 - val_raw_multi_label_accuracy: 0.1694\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 0.4403 - raw_multi_label_accuracy: 0.4375 - val_loss: 0.7958 - val_raw_multi_label_accuracy: 0.1551\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.4339 - raw_multi_label_accuracy: 0.4455 - val_loss: 0.8057 - val_raw_multi_label_accuracy: 0.1724\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 0.4331 - raw_multi_label_accuracy: 0.4610 - val_loss: 0.8289 - val_raw_multi_label_accuracy: 0.1928\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.4292 - raw_multi_label_accuracy: 0.4460 - val_loss: 0.8135 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.4250 - raw_multi_label_accuracy: 0.4752 - val_loss: 0.8597 - val_raw_multi_label_accuracy: 0.1859\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.4180 - raw_multi_label_accuracy: 0.4774 - val_loss: 0.8631 - val_raw_multi_label_accuracy: 0.1697\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.4166 - raw_multi_label_accuracy: 0.4928 - val_loss: 0.8590 - val_raw_multi_label_accuracy: 0.1703\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.4115 - raw_multi_label_accuracy: 0.5010 - val_loss: 0.8789 - val_raw_multi_label_accuracy: 0.1828\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.4058 - raw_multi_label_accuracy: 0.5072 - val_loss: 0.9101 - val_raw_multi_label_accuracy: 0.1847\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.3996 - raw_multi_label_accuracy: 0.5243 - val_loss: 0.9032 - val_raw_multi_label_accuracy: 0.1771\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.3974 - raw_multi_label_accuracy: 0.5191 - val_loss: 0.9094 - val_raw_multi_label_accuracy: 0.1857\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.3923 - raw_multi_label_accuracy: 0.5322 - val_loss: 0.9465 - val_raw_multi_label_accuracy: 0.1963\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.3908 - raw_multi_label_accuracy: 0.5366 - val_loss: 0.9011 - val_raw_multi_label_accuracy: 0.1762\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.3859 - raw_multi_label_accuracy: 0.5231 - val_loss: 0.9022 - val_raw_multi_label_accuracy: 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      " - 1s - loss: 0.3791 - raw_multi_label_accuracy: 0.5398 - val_loss: 0.9258 - val_raw_multi_label_accuracy: 0.1735\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 0.3751 - raw_multi_label_accuracy: 0.5533 - val_loss: 0.9231 - val_raw_multi_label_accuracy: 0.1720\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.3703 - raw_multi_label_accuracy: 0.5565 - val_loss: 0.9055 - val_raw_multi_label_accuracy: 0.1724\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 0.3712 - raw_multi_label_accuracy: 0.5601 - val_loss: 0.9049 - val_raw_multi_label_accuracy: 0.1814\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 0.3668 - raw_multi_label_accuracy: 0.5695 - val_loss: 0.9118 - val_raw_multi_label_accuracy: 0.1679\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.3638 - raw_multi_label_accuracy: 0.5927 - val_loss: 0.9553 - val_raw_multi_label_accuracy: 0.1896\n",
      "Epoch 61/1000\n",
      " - 1s - loss: 0.3579 - raw_multi_label_accuracy: 0.5992 - val_loss: 0.9422 - val_raw_multi_label_accuracy: 0.1627\n",
      "Epoch 62/1000\n",
      " - 1s - loss: 0.3573 - raw_multi_label_accuracy: 0.5983 - val_loss: 0.9226 - val_raw_multi_label_accuracy: 0.1873\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 0.3565 - raw_multi_label_accuracy: 0.5946 - val_loss: 0.9141 - val_raw_multi_label_accuracy: 0.1785\n",
      "Epoch 64/1000\n",
      " - 1s - loss: 0.3490 - raw_multi_label_accuracy: 0.6133 - val_loss: 0.9455 - val_raw_multi_label_accuracy: 0.1991\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 0.3506 - raw_multi_label_accuracy: 0.6094 - val_loss: 0.9655 - val_raw_multi_label_accuracy: 0.1865\n",
      "Epoch 66/1000\n",
      " - 1s - loss: 0.3469 - raw_multi_label_accuracy: 0.6043 - val_loss: 0.9445 - val_raw_multi_label_accuracy: 0.1810\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 0.3418 - raw_multi_label_accuracy: 0.6226 - val_loss: 0.9102 - val_raw_multi_label_accuracy: 0.1899\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.3348 - raw_multi_label_accuracy: 0.6208 - val_loss: 0.9298 - val_raw_multi_label_accuracy: 0.2046\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.3343 - raw_multi_label_accuracy: 0.6211 - val_loss: 0.9525 - val_raw_multi_label_accuracy: 0.1963\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.3294 - raw_multi_label_accuracy: 0.6315 - val_loss: 0.9686 - val_raw_multi_label_accuracy: 0.1905\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 0.3332 - raw_multi_label_accuracy: 0.6256 - val_loss: 0.9967 - val_raw_multi_label_accuracy: 0.2026\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.3227 - raw_multi_label_accuracy: 0.6342 - val_loss: 0.9582 - val_raw_multi_label_accuracy: 0.1948\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.3214 - raw_multi_label_accuracy: 0.6337 - val_loss: 0.9317 - val_raw_multi_label_accuracy: 0.1875\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.3235 - raw_multi_label_accuracy: 0.6395 - val_loss: 0.9751 - val_raw_multi_label_accuracy: 0.1880\n",
      "Epoch 75/1000\n",
      " - 1s - loss: 0.3169 - raw_multi_label_accuracy: 0.6332 - val_loss: 0.9448 - val_raw_multi_label_accuracy: 0.2152\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 0.3122 - raw_multi_label_accuracy: 0.6490 - val_loss: 1.0303 - val_raw_multi_label_accuracy: 0.2213\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 0.3099 - raw_multi_label_accuracy: 0.6520 - val_loss: 0.9975 - val_raw_multi_label_accuracy: 0.2157\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 0.3038 - raw_multi_label_accuracy: 0.6578 - val_loss: 0.9919 - val_raw_multi_label_accuracy: 0.1995\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.3074 - raw_multi_label_accuracy: 0.6604 - val_loss: 1.0562 - val_raw_multi_label_accuracy: 0.2175\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.2990 - raw_multi_label_accuracy: 0.6755 - val_loss: 1.0547 - val_raw_multi_label_accuracy: 0.2008\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.2958 - raw_multi_label_accuracy: 0.6754 - val_loss: 1.0570 - val_raw_multi_label_accuracy: 0.2275\n",
      "Epoch 82/1000\n",
      " - 1s - loss: 0.2917 - raw_multi_label_accuracy: 0.6869 - val_loss: 1.0683 - val_raw_multi_label_accuracy: 0.2209\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 0.2930 - raw_multi_label_accuracy: 0.6753 - val_loss: 1.0081 - val_raw_multi_label_accuracy: 0.2203\n",
      "Epoch 84/1000\n",
      " - 1s - loss: 0.2925 - raw_multi_label_accuracy: 0.6842 - val_loss: 1.0450 - val_raw_multi_label_accuracy: 0.2092\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.2836 - raw_multi_label_accuracy: 0.6951 - val_loss: 1.1005 - val_raw_multi_label_accuracy: 0.2196\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.2808 - raw_multi_label_accuracy: 0.7074 - val_loss: 1.0477 - val_raw_multi_label_accuracy: 0.2246\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 0.2776 - raw_multi_label_accuracy: 0.7066 - val_loss: 1.1012 - val_raw_multi_label_accuracy: 0.2290\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.2737 - raw_multi_label_accuracy: 0.7133 - val_loss: 1.0961 - val_raw_multi_label_accuracy: 0.2295\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.2727 - raw_multi_label_accuracy: 0.7185 - val_loss: 1.1184 - val_raw_multi_label_accuracy: 0.2106\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 0.2723 - raw_multi_label_accuracy: 0.7157 - val_loss: 1.0881 - val_raw_multi_label_accuracy: 0.2257\n",
      "Epoch 91/1000\n",
      " - 1s - loss: 0.2688 - raw_multi_label_accuracy: 0.7220 - val_loss: 1.0919 - val_raw_multi_label_accuracy: 0.2342\n",
      "Epoch 92/1000\n",
      " - 1s - loss: 0.2691 - raw_multi_label_accuracy: 0.7233 - val_loss: 1.0526 - val_raw_multi_label_accuracy: 0.2505\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 0.2630 - raw_multi_label_accuracy: 0.7251 - val_loss: 1.1366 - val_raw_multi_label_accuracy: 0.2381\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 0.2596 - raw_multi_label_accuracy: 0.7367 - val_loss: 1.1291 - val_raw_multi_label_accuracy: 0.2264\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.2568 - raw_multi_label_accuracy: 0.7430 - val_loss: 1.0792 - val_raw_multi_label_accuracy: 0.2295\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.2580 - raw_multi_label_accuracy: 0.7379 - val_loss: 1.1292 - val_raw_multi_label_accuracy: 0.2250\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 0.2525 - raw_multi_label_accuracy: 0.7457 - val_loss: 1.2285 - val_raw_multi_label_accuracy: 0.2297\n",
      "Epoch 98/1000\n",
      " - 1s - loss: 0.2641 - raw_multi_label_accuracy: 0.7394 - val_loss: 1.1252 - val_raw_multi_label_accuracy: 0.2392\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.2532 - raw_multi_label_accuracy: 0.7582 - val_loss: 1.0844 - val_raw_multi_label_accuracy: 0.2327\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.2512 - raw_multi_label_accuracy: 0.7475 - val_loss: 1.0898 - val_raw_multi_label_accuracy: 0.2283\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.2523 - raw_multi_label_accuracy: 0.7543 - val_loss: 1.1620 - val_raw_multi_label_accuracy: 0.2304\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.2496 - raw_multi_label_accuracy: 0.7592 - val_loss: 1.0912 - val_raw_multi_label_accuracy: 0.2369\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.2491 - raw_multi_label_accuracy: 0.7537 - val_loss: 1.1029 - val_raw_multi_label_accuracy: 0.2297\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.2453 - raw_multi_label_accuracy: 0.7552 - val_loss: 1.0567 - val_raw_multi_label_accuracy: 0.2364\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 0.2471 - raw_multi_label_accuracy: 0.7531 - val_loss: 1.2088 - val_raw_multi_label_accuracy: 0.2267\n",
      "Epoch 106/1000\n",
      " - 1s - loss: 0.2399 - raw_multi_label_accuracy: 0.7629 - val_loss: 1.1074 - val_raw_multi_label_accuracy: 0.2270\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 0.2356 - raw_multi_label_accuracy: 0.7660 - val_loss: 1.1616 - val_raw_multi_label_accuracy: 0.2396\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 0.2345 - raw_multi_label_accuracy: 0.7630 - val_loss: 1.1205 - val_raw_multi_label_accuracy: 0.2355\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 0.2355 - raw_multi_label_accuracy: 0.7694 - val_loss: 1.1121 - val_raw_multi_label_accuracy: 0.2391\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.2330 - raw_multi_label_accuracy: 0.7755 - val_loss: 1.0778 - val_raw_multi_label_accuracy: 0.2413\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 0.2313 - raw_multi_label_accuracy: 0.7741 - val_loss: 1.1959 - val_raw_multi_label_accuracy: 0.2409\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.2259 - raw_multi_label_accuracy: 0.7761 - val_loss: 1.2264 - val_raw_multi_label_accuracy: 0.2507\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 0.2317 - raw_multi_label_accuracy: 0.7727 - val_loss: 1.2311 - val_raw_multi_label_accuracy: 0.2415\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.2340 - raw_multi_label_accuracy: 0.7684 - val_loss: 1.1097 - val_raw_multi_label_accuracy: 0.2407\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 0.2267 - raw_multi_label_accuracy: 0.7913 - val_loss: 1.1601 - val_raw_multi_label_accuracy: 0.2425\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.2229 - raw_multi_label_accuracy: 0.7758 - val_loss: 1.2264 - val_raw_multi_label_accuracy: 0.2489\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.2218 - raw_multi_label_accuracy: 0.7756 - val_loss: 1.1998 - val_raw_multi_label_accuracy: 0.2501\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.2267 - raw_multi_label_accuracy: 0.7761 - val_loss: 1.1637 - val_raw_multi_label_accuracy: 0.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      " - 1s - loss: 0.2228 - raw_multi_label_accuracy: 0.7810 - val_loss: 1.1959 - val_raw_multi_label_accuracy: 0.2436\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.2175 - raw_multi_label_accuracy: 0.7942 - val_loss: 1.2211 - val_raw_multi_label_accuracy: 0.2426\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 0.2200 - raw_multi_label_accuracy: 0.7794 - val_loss: 1.0904 - val_raw_multi_label_accuracy: 0.2492\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 0.2164 - raw_multi_label_accuracy: 0.7905 - val_loss: 1.2383 - val_raw_multi_label_accuracy: 0.2397\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 0.2161 - raw_multi_label_accuracy: 0.7831 - val_loss: 1.2586 - val_raw_multi_label_accuracy: 0.2502\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 0.2134 - raw_multi_label_accuracy: 0.7843 - val_loss: 1.1895 - val_raw_multi_label_accuracy: 0.2438\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 0.2145 - raw_multi_label_accuracy: 0.7868 - val_loss: 1.1768 - val_raw_multi_label_accuracy: 0.2432\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 0.2136 - raw_multi_label_accuracy: 0.7947 - val_loss: 1.2283 - val_raw_multi_label_accuracy: 0.2542\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 0.2153 - raw_multi_label_accuracy: 0.7904 - val_loss: 1.2163 - val_raw_multi_label_accuracy: 0.2424\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.2120 - raw_multi_label_accuracy: 0.7967 - val_loss: 1.1997 - val_raw_multi_label_accuracy: 0.2517\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.2064 - raw_multi_label_accuracy: 0.7923 - val_loss: 1.2743 - val_raw_multi_label_accuracy: 0.2516\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.2067 - raw_multi_label_accuracy: 0.7951 - val_loss: 1.2911 - val_raw_multi_label_accuracy: 0.2517\n",
      "Epoch 131/1000\n",
      " - 1s - loss: 0.2116 - raw_multi_label_accuracy: 0.7985 - val_loss: 1.2703 - val_raw_multi_label_accuracy: 0.2516\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.2069 - raw_multi_label_accuracy: 0.7960 - val_loss: 1.2548 - val_raw_multi_label_accuracy: 0.2545\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.2044 - raw_multi_label_accuracy: 0.7937 - val_loss: 1.2747 - val_raw_multi_label_accuracy: 0.2506\n",
      "Epoch 134/1000\n",
      " - 1s - loss: 0.2039 - raw_multi_label_accuracy: 0.8015 - val_loss: 1.1637 - val_raw_multi_label_accuracy: 0.2529\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 0.2045 - raw_multi_label_accuracy: 0.7876 - val_loss: 1.2409 - val_raw_multi_label_accuracy: 0.2539\n",
      "Epoch 136/1000\n",
      " - 1s - loss: 0.2038 - raw_multi_label_accuracy: 0.8016 - val_loss: 1.2833 - val_raw_multi_label_accuracy: 0.2553\n",
      "Epoch 137/1000\n",
      " - 1s - loss: 0.2003 - raw_multi_label_accuracy: 0.8003 - val_loss: 1.3019 - val_raw_multi_label_accuracy: 0.2563\n",
      "Epoch 138/1000\n",
      " - 1s - loss: 0.1979 - raw_multi_label_accuracy: 0.7984 - val_loss: 1.2270 - val_raw_multi_label_accuracy: 0.2562\n",
      "Epoch 139/1000\n",
      " - 1s - loss: 0.2050 - raw_multi_label_accuracy: 0.7987 - val_loss: 1.2475 - val_raw_multi_label_accuracy: 0.2565\n",
      "Epoch 140/1000\n",
      " - 1s - loss: 0.1965 - raw_multi_label_accuracy: 0.8099 - val_loss: 1.3660 - val_raw_multi_label_accuracy: 0.2595\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 0.1962 - raw_multi_label_accuracy: 0.8100 - val_loss: 1.3570 - val_raw_multi_label_accuracy: 0.2528\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.1969 - raw_multi_label_accuracy: 0.8047 - val_loss: 1.2971 - val_raw_multi_label_accuracy: 0.2523\n",
      "Epoch 143/1000\n",
      " - 1s - loss: 0.1939 - raw_multi_label_accuracy: 0.8081 - val_loss: 1.3132 - val_raw_multi_label_accuracy: 0.2535\n",
      "Epoch 144/1000\n",
      " - 1s - loss: 0.1930 - raw_multi_label_accuracy: 0.8186 - val_loss: 1.2791 - val_raw_multi_label_accuracy: 0.2535\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 0.1935 - raw_multi_label_accuracy: 0.8078 - val_loss: 1.3588 - val_raw_multi_label_accuracy: 0.2552\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.1914 - raw_multi_label_accuracy: 0.8116 - val_loss: 1.2829 - val_raw_multi_label_accuracy: 0.2611\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 0.1862 - raw_multi_label_accuracy: 0.8174 - val_loss: 1.3486 - val_raw_multi_label_accuracy: 0.2528\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 0.1855 - raw_multi_label_accuracy: 0.8195 - val_loss: 1.3053 - val_raw_multi_label_accuracy: 0.2531\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 0.1891 - raw_multi_label_accuracy: 0.8097 - val_loss: 1.2798 - val_raw_multi_label_accuracy: 0.2586\n",
      "Epoch 150/1000\n",
      " - 1s - loss: 0.1863 - raw_multi_label_accuracy: 0.8133 - val_loss: 1.3367 - val_raw_multi_label_accuracy: 0.2556\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 0.1857 - raw_multi_label_accuracy: 0.8185 - val_loss: 1.3217 - val_raw_multi_label_accuracy: 0.2611\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 0.1825 - raw_multi_label_accuracy: 0.8209 - val_loss: 1.3399 - val_raw_multi_label_accuracy: 0.2574\n",
      "Epoch 153/1000\n",
      " - 1s - loss: 0.1818 - raw_multi_label_accuracy: 0.8266 - val_loss: 1.3770 - val_raw_multi_label_accuracy: 0.2638\n",
      "Epoch 154/1000\n",
      " - 1s - loss: 0.1855 - raw_multi_label_accuracy: 0.8171 - val_loss: 1.3096 - val_raw_multi_label_accuracy: 0.2602\n",
      "Epoch 155/1000\n",
      " - 1s - loss: 0.1856 - raw_multi_label_accuracy: 0.8231 - val_loss: 1.3757 - val_raw_multi_label_accuracy: 0.2647\n",
      "Epoch 156/1000\n",
      " - 1s - loss: 0.1833 - raw_multi_label_accuracy: 0.8159 - val_loss: 1.3761 - val_raw_multi_label_accuracy: 0.2592\n",
      "Epoch 157/1000\n",
      " - 1s - loss: 0.1813 - raw_multi_label_accuracy: 0.8242 - val_loss: 1.2573 - val_raw_multi_label_accuracy: 0.2600\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 0.1810 - raw_multi_label_accuracy: 0.8283 - val_loss: 1.2537 - val_raw_multi_label_accuracy: 0.2636\n",
      "Epoch 159/1000\n",
      " - 1s - loss: 0.1821 - raw_multi_label_accuracy: 0.8199 - val_loss: 1.3720 - val_raw_multi_label_accuracy: 0.2681\n",
      "Epoch 160/1000\n",
      " - 1s - loss: 0.1773 - raw_multi_label_accuracy: 0.8271 - val_loss: 1.4100 - val_raw_multi_label_accuracy: 0.2677\n",
      "Epoch 161/1000\n",
      " - 1s - loss: 0.1763 - raw_multi_label_accuracy: 0.8367 - val_loss: 1.3502 - val_raw_multi_label_accuracy: 0.2626\n",
      "Epoch 162/1000\n",
      " - 1s - loss: 0.1735 - raw_multi_label_accuracy: 0.8313 - val_loss: 1.4301 - val_raw_multi_label_accuracy: 0.2654\n",
      "Epoch 163/1000\n",
      " - 1s - loss: 0.1792 - raw_multi_label_accuracy: 0.8255 - val_loss: 1.3987 - val_raw_multi_label_accuracy: 0.2681\n",
      "Epoch 164/1000\n",
      " - 1s - loss: 0.1752 - raw_multi_label_accuracy: 0.8271 - val_loss: 1.4134 - val_raw_multi_label_accuracy: 0.2667\n",
      "Epoch 165/1000\n",
      " - 1s - loss: 0.1801 - raw_multi_label_accuracy: 0.8277 - val_loss: 1.3372 - val_raw_multi_label_accuracy: 0.2690\n",
      "Epoch 166/1000\n",
      " - 1s - loss: 0.1741 - raw_multi_label_accuracy: 0.8245 - val_loss: 1.3409 - val_raw_multi_label_accuracy: 0.2683\n",
      "Epoch 167/1000\n",
      " - 1s - loss: 0.1749 - raw_multi_label_accuracy: 0.8309 - val_loss: 1.4180 - val_raw_multi_label_accuracy: 0.2775\n",
      "Epoch 168/1000\n",
      " - 1s - loss: 0.1752 - raw_multi_label_accuracy: 0.8324 - val_loss: 1.4785 - val_raw_multi_label_accuracy: 0.2672\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 0.1705 - raw_multi_label_accuracy: 0.8330 - val_loss: 1.3932 - val_raw_multi_label_accuracy: 0.2576\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 0.1712 - raw_multi_label_accuracy: 0.8380 - val_loss: 1.4038 - val_raw_multi_label_accuracy: 0.2603\n",
      "Epoch 171/1000\n",
      " - 1s - loss: 0.1695 - raw_multi_label_accuracy: 0.8363 - val_loss: 1.4197 - val_raw_multi_label_accuracy: 0.2651\n",
      "Epoch 172/1000\n",
      " - 1s - loss: 0.1735 - raw_multi_label_accuracy: 0.8255 - val_loss: 1.4905 - val_raw_multi_label_accuracy: 0.2621\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 0.1692 - raw_multi_label_accuracy: 0.8334 - val_loss: 1.4374 - val_raw_multi_label_accuracy: 0.2691\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 0.1727 - raw_multi_label_accuracy: 0.8291 - val_loss: 1.3589 - val_raw_multi_label_accuracy: 0.2722\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 0.1732 - raw_multi_label_accuracy: 0.8283 - val_loss: 1.3807 - val_raw_multi_label_accuracy: 0.2678\n",
      "Epoch 176/1000\n",
      " - 1s - loss: 0.1691 - raw_multi_label_accuracy: 0.8323 - val_loss: 1.4148 - val_raw_multi_label_accuracy: 0.2682\n",
      "Epoch 177/1000\n",
      " - 1s - loss: 0.1684 - raw_multi_label_accuracy: 0.8373 - val_loss: 1.4436 - val_raw_multi_label_accuracy: 0.2604\n",
      "Epoch 178/1000\n",
      " - 1s - loss: 0.1679 - raw_multi_label_accuracy: 0.8362 - val_loss: 1.4450 - val_raw_multi_label_accuracy: 0.2553\n",
      "Epoch 179/1000\n",
      " - 1s - loss: 0.1700 - raw_multi_label_accuracy: 0.8361 - val_loss: 1.4230 - val_raw_multi_label_accuracy: 0.2623\n",
      "Epoch 180/1000\n",
      " - 1s - loss: 0.1655 - raw_multi_label_accuracy: 0.8418 - val_loss: 1.4114 - val_raw_multi_label_accuracy: 0.2654\n",
      "Epoch 181/1000\n",
      " - 1s - loss: 0.1661 - raw_multi_label_accuracy: 0.8425 - val_loss: 1.4524 - val_raw_multi_label_accuracy: 0.2635\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 0.1633 - raw_multi_label_accuracy: 0.8405 - val_loss: 1.5327 - val_raw_multi_label_accuracy: 0.2635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      " - 1s - loss: 0.1666 - raw_multi_label_accuracy: 0.8393 - val_loss: 1.5177 - val_raw_multi_label_accuracy: 0.2627\n",
      "Epoch 184/1000\n",
      " - 1s - loss: 0.1624 - raw_multi_label_accuracy: 0.8407 - val_loss: 1.4433 - val_raw_multi_label_accuracy: 0.2613\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 0.1626 - raw_multi_label_accuracy: 0.8424 - val_loss: 1.4950 - val_raw_multi_label_accuracy: 0.2701\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 0.1595 - raw_multi_label_accuracy: 0.8442 - val_loss: 1.4621 - val_raw_multi_label_accuracy: 0.2696\n",
      "Epoch 187/1000\n",
      " - 1s - loss: 0.1628 - raw_multi_label_accuracy: 0.8436 - val_loss: 1.4097 - val_raw_multi_label_accuracy: 0.2581\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 0.1616 - raw_multi_label_accuracy: 0.8435 - val_loss: 1.4413 - val_raw_multi_label_accuracy: 0.2646\n",
      "Epoch 189/1000\n",
      " - 1s - loss: 0.1610 - raw_multi_label_accuracy: 0.8449 - val_loss: 1.5293 - val_raw_multi_label_accuracy: 0.2759\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 0.1616 - raw_multi_label_accuracy: 0.8459 - val_loss: 1.5658 - val_raw_multi_label_accuracy: 0.2720\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.1581 - raw_multi_label_accuracy: 0.8409 - val_loss: 1.5049 - val_raw_multi_label_accuracy: 0.2611\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 0.1581 - raw_multi_label_accuracy: 0.8457 - val_loss: 1.5653 - val_raw_multi_label_accuracy: 0.2720\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 0.1641 - raw_multi_label_accuracy: 0.8389 - val_loss: 1.5287 - val_raw_multi_label_accuracy: 0.2659\n",
      "Epoch 194/1000\n",
      " - 1s - loss: 0.1569 - raw_multi_label_accuracy: 0.8423 - val_loss: 1.5580 - val_raw_multi_label_accuracy: 0.2717\n",
      "Epoch 195/1000\n",
      " - 1s - loss: 0.1591 - raw_multi_label_accuracy: 0.8416 - val_loss: 1.5019 - val_raw_multi_label_accuracy: 0.2716\n",
      "Epoch 196/1000\n",
      " - 1s - loss: 0.1522 - raw_multi_label_accuracy: 0.8507 - val_loss: 1.4975 - val_raw_multi_label_accuracy: 0.2647\n",
      "Epoch 197/1000\n",
      " - 1s - loss: 0.1557 - raw_multi_label_accuracy: 0.8520 - val_loss: 1.4644 - val_raw_multi_label_accuracy: 0.2640\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 0.1544 - raw_multi_label_accuracy: 0.8497 - val_loss: 1.4959 - val_raw_multi_label_accuracy: 0.2713\n",
      "Epoch 199/1000\n",
      " - 1s - loss: 0.1589 - raw_multi_label_accuracy: 0.8437 - val_loss: 1.5451 - val_raw_multi_label_accuracy: 0.2702\n",
      "Epoch 200/1000\n",
      " - 1s - loss: 0.1508 - raw_multi_label_accuracy: 0.8471 - val_loss: 1.4642 - val_raw_multi_label_accuracy: 0.2695\n",
      "Epoch 201/1000\n",
      " - 1s - loss: 0.1501 - raw_multi_label_accuracy: 0.8544 - val_loss: 1.5818 - val_raw_multi_label_accuracy: 0.2732\n",
      "Epoch 202/1000\n",
      " - 1s - loss: 0.1540 - raw_multi_label_accuracy: 0.8532 - val_loss: 1.5502 - val_raw_multi_label_accuracy: 0.2780\n",
      "Epoch 203/1000\n",
      " - 1s - loss: 0.1545 - raw_multi_label_accuracy: 0.8505 - val_loss: 1.5022 - val_raw_multi_label_accuracy: 0.2730\n",
      "Epoch 204/1000\n",
      " - 1s - loss: 0.1529 - raw_multi_label_accuracy: 0.8505 - val_loss: 1.5649 - val_raw_multi_label_accuracy: 0.2811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9b9a35f98>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model_cnn = Sequential()\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
    "#e = Embedding(num_words_kept, word_vec_len, input_length=max_seq_len, trainable=True)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(50, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(len(genre_dict), activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
    "#model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
    "model_cnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=200)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_output_to_predictions(res):\n",
    "    label_predictions = []\n",
    "    for i in range(res.shape[0]):\n",
    "        pred = [0]*len(genre_dict)\n",
    "        for j in range(res.shape[1]):\n",
    "            if res[i][j] >= .5:\n",
    "                pred[j] = 1\n",
    "        label_predictions.append(pred)\n",
    "    return np.array(label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3321256038647344"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42822636300897177"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4366804692891649"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 64.59627329192547\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.5755693581780539\n",
      "Precision for Action-Adventure: 0.46484375\n",
      "Recall for Action-Adventure: 0.6363636363636364\n",
      "\n",
      "Accuruacy for Romance: 0.722567287784679\n",
      "Precision for Romance: 0.3157894736842105\n",
      "Recall for Romance: 0.22641509433962265\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.505175983436853\n",
      "Precision for Horror-Thriller: 0.41637010676156583\n",
      "Recall for Horror-Thriller: 0.609375\n",
      "\n",
      "Accuruacy for Comedy: 0.5631469979296067\n",
      "Precision for Comedy: 0.5083333333333333\n",
      "Recall for Comedy: 0.2863849765258216\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8633540372670807\n",
      "Precision for Science Fiction: 0.25\n",
      "Recall for Science Fiction: 0.08928571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN but with multiple filter sizes so we don't just filter on group of words at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "model_input = Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)(model_input)\n",
    "two_word_filter = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(e)\n",
    "two_word_filter = GlobalMaxPooling1D()(two_word_filter)\n",
    "three_word_filter = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(e)\n",
    "three_word_filter = GlobalMaxPooling1D()(three_word_filter)\n",
    "four_word_filter = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(e)\n",
    "four_word_filter = GlobalMaxPooling1D()(four_word_filter)\n",
    "merged = concatenate([two_word_filter, three_word_filter, four_word_filter], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(len(genre_dict))(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[model_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1738 samples, validate on 194 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 2.8990 - raw_multi_label_accuracy: 0.0838 - val_loss: 2.2934 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 4s - loss: 1.9273 - raw_multi_label_accuracy: 0.0526 - val_loss: 1.5416 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 4s - loss: 1.3211 - raw_multi_label_accuracy: 0.0315 - val_loss: 1.0943 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 4s - loss: 0.9764 - raw_multi_label_accuracy: 0.0274 - val_loss: 0.8450 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 4s - loss: 0.7841 - raw_multi_label_accuracy: 0.0235 - val_loss: 0.7215 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 4s - loss: 0.6850 - raw_multi_label_accuracy: 0.0255 - val_loss: 0.6478 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 4s - loss: 0.6351 - raw_multi_label_accuracy: 0.0510 - val_loss: 0.6192 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 4s - loss: 0.5987 - raw_multi_label_accuracy: 0.0664 - val_loss: 0.6035 - val_raw_multi_label_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 4s - loss: 0.5524 - raw_multi_label_accuracy: 0.2285 - val_loss: 0.6015 - val_raw_multi_label_accuracy: 0.1009\n",
      "Epoch 10/1000\n",
      " - 4s - loss: 0.4748 - raw_multi_label_accuracy: 0.4656 - val_loss: 0.5990 - val_raw_multi_label_accuracy: 0.1450\n",
      "Epoch 11/1000\n",
      " - 4s - loss: 0.4174 - raw_multi_label_accuracy: 0.5332 - val_loss: 0.5847 - val_raw_multi_label_accuracy: 0.1922\n",
      "Epoch 12/1000\n",
      " - 4s - loss: 0.3741 - raw_multi_label_accuracy: 0.6027 - val_loss: 0.5812 - val_raw_multi_label_accuracy: 0.2199\n",
      "Epoch 13/1000\n",
      " - 4s - loss: 0.3308 - raw_multi_label_accuracy: 0.6790 - val_loss: 0.5971 - val_raw_multi_label_accuracy: 0.2515\n",
      "Epoch 14/1000\n",
      " - 4s - loss: 0.2853 - raw_multi_label_accuracy: 0.7505 - val_loss: 0.5991 - val_raw_multi_label_accuracy: 0.2334\n",
      "Epoch 15/1000\n",
      " - 4s - loss: 0.2419 - raw_multi_label_accuracy: 0.8038 - val_loss: 0.6051 - val_raw_multi_label_accuracy: 0.3175\n",
      "Epoch 16/1000\n",
      " - 4s - loss: 0.2099 - raw_multi_label_accuracy: 0.8384 - val_loss: 0.6187 - val_raw_multi_label_accuracy: 0.2860\n",
      "Epoch 17/1000\n",
      " - 4s - loss: 0.1889 - raw_multi_label_accuracy: 0.8568 - val_loss: 0.6228 - val_raw_multi_label_accuracy: 0.3133\n",
      "Epoch 18/1000\n",
      " - 4s - loss: 0.1694 - raw_multi_label_accuracy: 0.8712 - val_loss: 0.6461 - val_raw_multi_label_accuracy: 0.3039\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.1554 - raw_multi_label_accuracy: 0.8880 - val_loss: 0.6598 - val_raw_multi_label_accuracy: 0.3079\n",
      "Epoch 20/1000\n",
      " - 4s - loss: 0.1441 - raw_multi_label_accuracy: 0.8959 - val_loss: 0.6578 - val_raw_multi_label_accuracy: 0.3139\n",
      "Epoch 21/1000\n",
      " - 4s - loss: 0.1313 - raw_multi_label_accuracy: 0.9130 - val_loss: 0.6951 - val_raw_multi_label_accuracy: 0.3254\n",
      "Epoch 22/1000\n",
      " - 4s - loss: 0.1263 - raw_multi_label_accuracy: 0.9178 - val_loss: 0.6962 - val_raw_multi_label_accuracy: 0.3226\n",
      "Epoch 23/1000\n",
      " - 4s - loss: 0.1194 - raw_multi_label_accuracy: 0.9227 - val_loss: 0.7115 - val_raw_multi_label_accuracy: 0.2750\n",
      "Epoch 24/1000\n",
      " - 5s - loss: 0.1135 - raw_multi_label_accuracy: 0.9256 - val_loss: 0.7159 - val_raw_multi_label_accuracy: 0.3216\n",
      "Epoch 25/1000\n",
      " - 5s - loss: 0.1055 - raw_multi_label_accuracy: 0.9380 - val_loss: 0.7170 - val_raw_multi_label_accuracy: 0.3325\n",
      "Epoch 26/1000\n",
      " - 5s - loss: 0.0998 - raw_multi_label_accuracy: 0.9414 - val_loss: 0.7528 - val_raw_multi_label_accuracy: 0.3351\n",
      "Epoch 27/1000\n",
      " - 5s - loss: 0.0931 - raw_multi_label_accuracy: 0.9447 - val_loss: 0.7426 - val_raw_multi_label_accuracy: 0.2968\n",
      "Epoch 28/1000\n",
      " - 4s - loss: 0.0870 - raw_multi_label_accuracy: 0.9499 - val_loss: 0.7499 - val_raw_multi_label_accuracy: 0.3120\n",
      "Epoch 29/1000\n",
      " - 4s - loss: 0.0840 - raw_multi_label_accuracy: 0.9555 - val_loss: 0.7336 - val_raw_multi_label_accuracy: 0.3227\n",
      "Epoch 30/1000\n",
      " - 4s - loss: 0.0804 - raw_multi_label_accuracy: 0.9550 - val_loss: 0.7446 - val_raw_multi_label_accuracy: 0.3113\n",
      "Epoch 31/1000\n",
      " - 4s - loss: 0.0769 - raw_multi_label_accuracy: 0.9610 - val_loss: 0.7549 - val_raw_multi_label_accuracy: 0.3236\n",
      "Epoch 32/1000\n",
      " - 4s - loss: 0.0746 - raw_multi_label_accuracy: 0.9594 - val_loss: 0.7886 - val_raw_multi_label_accuracy: 0.3190\n",
      "Epoch 33/1000\n",
      " - 4s - loss: 0.0742 - raw_multi_label_accuracy: 0.9582 - val_loss: 0.7921 - val_raw_multi_label_accuracy: 0.3448\n",
      "Epoch 34/1000\n",
      " - 4s - loss: 0.0684 - raw_multi_label_accuracy: 0.9683 - val_loss: 0.7899 - val_raw_multi_label_accuracy: 0.3217\n",
      "Epoch 35/1000\n",
      " - 4s - loss: 0.0664 - raw_multi_label_accuracy: 0.9713 - val_loss: 0.7970 - val_raw_multi_label_accuracy: 0.3147\n",
      "Epoch 36/1000\n",
      " - 4s - loss: 0.0646 - raw_multi_label_accuracy: 0.9690 - val_loss: 0.7875 - val_raw_multi_label_accuracy: 0.3429\n",
      "Epoch 37/1000\n",
      " - 4s - loss: 0.0608 - raw_multi_label_accuracy: 0.9745 - val_loss: 0.8163 - val_raw_multi_label_accuracy: 0.3562\n",
      "Epoch 38/1000\n",
      " - 4s - loss: 0.0575 - raw_multi_label_accuracy: 0.9757 - val_loss: 0.8310 - val_raw_multi_label_accuracy: 0.3335\n",
      "Epoch 39/1000\n",
      " - 4s - loss: 0.0588 - raw_multi_label_accuracy: 0.9712 - val_loss: 0.8624 - val_raw_multi_label_accuracy: 0.3403\n",
      "Epoch 40/1000\n",
      " - 4s - loss: 0.0563 - raw_multi_label_accuracy: 0.9725 - val_loss: 0.8322 - val_raw_multi_label_accuracy: 0.3408\n",
      "Epoch 41/1000\n",
      " - 4s - loss: 0.0534 - raw_multi_label_accuracy: 0.9790 - val_loss: 0.8374 - val_raw_multi_label_accuracy: 0.3331\n",
      "Epoch 42/1000\n",
      " - 4s - loss: 0.0516 - raw_multi_label_accuracy: 0.9761 - val_loss: 0.8391 - val_raw_multi_label_accuracy: 0.3333\n",
      "Epoch 43/1000\n",
      " - 4s - loss: 0.0510 - raw_multi_label_accuracy: 0.9784 - val_loss: 0.8635 - val_raw_multi_label_accuracy: 0.3075\n",
      "Epoch 44/1000\n",
      " - 4s - loss: 0.0480 - raw_multi_label_accuracy: 0.9802 - val_loss: 0.8786 - val_raw_multi_label_accuracy: 0.3298\n",
      "Epoch 45/1000\n",
      " - 5s - loss: 0.0497 - raw_multi_label_accuracy: 0.9753 - val_loss: 0.8371 - val_raw_multi_label_accuracy: 0.3436\n",
      "Epoch 46/1000\n",
      " - 4s - loss: 0.0534 - raw_multi_label_accuracy: 0.9746 - val_loss: 0.8870 - val_raw_multi_label_accuracy: 0.3429\n",
      "Epoch 47/1000\n",
      " - 4s - loss: 0.0494 - raw_multi_label_accuracy: 0.9758 - val_loss: 0.8926 - val_raw_multi_label_accuracy: 0.3399\n",
      "Epoch 48/1000\n",
      " - 4s - loss: 0.0500 - raw_multi_label_accuracy: 0.9756 - val_loss: 0.8878 - val_raw_multi_label_accuracy: 0.3396\n",
      "Epoch 49/1000\n",
      " - 4s - loss: 0.0493 - raw_multi_label_accuracy: 0.9770 - val_loss: 0.9049 - val_raw_multi_label_accuracy: 0.3200\n",
      "Epoch 50/1000\n",
      " - 4s - loss: 0.0442 - raw_multi_label_accuracy: 0.9831 - val_loss: 0.9018 - val_raw_multi_label_accuracy: 0.3299\n",
      "Epoch 51/1000\n",
      " - 4s - loss: 0.0447 - raw_multi_label_accuracy: 0.9762 - val_loss: 0.8873 - val_raw_multi_label_accuracy: 0.3322\n",
      "Epoch 52/1000\n",
      " - 4s - loss: 0.0424 - raw_multi_label_accuracy: 0.9779 - val_loss: 0.9449 - val_raw_multi_label_accuracy: 0.3348\n",
      "Epoch 53/1000\n",
      " - 4s - loss: 0.0409 - raw_multi_label_accuracy: 0.9776 - val_loss: 0.8767 - val_raw_multi_label_accuracy: 0.3246\n",
      "Epoch 54/1000\n",
      " - 4s - loss: 0.0404 - raw_multi_label_accuracy: 0.9824 - val_loss: 0.9137 - val_raw_multi_label_accuracy: 0.3347\n",
      "Epoch 55/1000\n",
      " - 4s - loss: 0.0447 - raw_multi_label_accuracy: 0.9763 - val_loss: 0.9456 - val_raw_multi_label_accuracy: 0.3472\n",
      "Epoch 56/1000\n",
      " - 5s - loss: 0.0442 - raw_multi_label_accuracy: 0.9767 - val_loss: 0.9336 - val_raw_multi_label_accuracy: 0.3432\n",
      "Epoch 57/1000\n",
      " - 4s - loss: 0.0413 - raw_multi_label_accuracy: 0.9826 - val_loss: 0.9601 - val_raw_multi_label_accuracy: 0.3378\n",
      "Epoch 58/1000\n",
      " - 4s - loss: 0.0397 - raw_multi_label_accuracy: 0.9809 - val_loss: 0.9420 - val_raw_multi_label_accuracy: 0.3210\n",
      "Epoch 59/1000\n",
      " - 4s - loss: 0.0383 - raw_multi_label_accuracy: 0.9812 - val_loss: 0.9346 - val_raw_multi_label_accuracy: 0.3445\n",
      "Epoch 60/1000\n",
      " - 4s - loss: 0.0360 - raw_multi_label_accuracy: 0.9811 - val_loss: 0.9493 - val_raw_multi_label_accuracy: 0.3485\n",
      "Epoch 61/1000\n",
      " - 4s - loss: 0.0400 - raw_multi_label_accuracy: 0.9781 - val_loss: 1.0020 - val_raw_multi_label_accuracy: 0.3538\n",
      "Epoch 62/1000\n",
      " - 4s - loss: 0.0395 - raw_multi_label_accuracy: 0.9809 - val_loss: 0.9748 - val_raw_multi_label_accuracy: 0.3422\n",
      "Epoch 63/1000\n",
      " - 4s - loss: 0.0365 - raw_multi_label_accuracy: 0.9805 - val_loss: 1.0084 - val_raw_multi_label_accuracy: 0.3377\n",
      "Epoch 64/1000\n",
      " - 4s - loss: 0.0365 - raw_multi_label_accuracy: 0.9825 - val_loss: 0.9932 - val_raw_multi_label_accuracy: 0.3205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      " - 4s - loss: 0.0366 - raw_multi_label_accuracy: 0.9825 - val_loss: 0.9537 - val_raw_multi_label_accuracy: 0.3329\n",
      "Epoch 66/1000\n",
      " - 4s - loss: 0.0355 - raw_multi_label_accuracy: 0.9815 - val_loss: 0.9386 - val_raw_multi_label_accuracy: 0.3520\n",
      "Epoch 67/1000\n",
      " - 4s - loss: 0.0320 - raw_multi_label_accuracy: 0.9857 - val_loss: 0.9994 - val_raw_multi_label_accuracy: 0.3306\n",
      "Epoch 68/1000\n",
      " - 4s - loss: 0.0357 - raw_multi_label_accuracy: 0.9792 - val_loss: 0.9313 - val_raw_multi_label_accuracy: 0.3296\n",
      "Epoch 69/1000\n",
      " - 4s - loss: 0.0326 - raw_multi_label_accuracy: 0.9867 - val_loss: 0.9982 - val_raw_multi_label_accuracy: 0.3266\n",
      "Epoch 70/1000\n",
      " - 4s - loss: 0.0321 - raw_multi_label_accuracy: 0.9840 - val_loss: 0.9896 - val_raw_multi_label_accuracy: 0.3387\n",
      "Epoch 71/1000\n",
      " - 4s - loss: 0.0310 - raw_multi_label_accuracy: 0.9861 - val_loss: 0.9713 - val_raw_multi_label_accuracy: 0.3315\n",
      "Epoch 72/1000\n",
      " - 4s - loss: 0.0305 - raw_multi_label_accuracy: 0.9874 - val_loss: 1.0366 - val_raw_multi_label_accuracy: 0.3296\n",
      "Epoch 73/1000\n",
      " - 4s - loss: 0.0324 - raw_multi_label_accuracy: 0.9835 - val_loss: 1.0003 - val_raw_multi_label_accuracy: 0.3274\n",
      "Epoch 74/1000\n",
      " - 4s - loss: 0.0312 - raw_multi_label_accuracy: 0.9856 - val_loss: 1.0006 - val_raw_multi_label_accuracy: 0.3566\n",
      "Epoch 75/1000\n",
      " - 4s - loss: 0.0319 - raw_multi_label_accuracy: 0.9829 - val_loss: 0.9987 - val_raw_multi_label_accuracy: 0.3237\n",
      "Epoch 76/1000\n",
      " - 4s - loss: 0.0344 - raw_multi_label_accuracy: 0.9802 - val_loss: 1.0014 - val_raw_multi_label_accuracy: 0.3443\n",
      "Epoch 77/1000\n",
      " - 4s - loss: 0.0341 - raw_multi_label_accuracy: 0.9852 - val_loss: 1.0788 - val_raw_multi_label_accuracy: 0.3208\n",
      "Epoch 78/1000\n",
      " - 4s - loss: 0.0331 - raw_multi_label_accuracy: 0.9827 - val_loss: 1.0158 - val_raw_multi_label_accuracy: 0.3284\n",
      "Epoch 79/1000\n",
      " - 4s - loss: 0.0320 - raw_multi_label_accuracy: 0.9842 - val_loss: 1.0716 - val_raw_multi_label_accuracy: 0.3359\n",
      "Epoch 80/1000\n",
      " - 4s - loss: 0.0315 - raw_multi_label_accuracy: 0.9851 - val_loss: 1.0305 - val_raw_multi_label_accuracy: 0.3430\n",
      "Epoch 81/1000\n",
      " - 4s - loss: 0.0308 - raw_multi_label_accuracy: 0.9852 - val_loss: 1.0138 - val_raw_multi_label_accuracy: 0.3235\n",
      "Epoch 82/1000\n",
      " - 4s - loss: 0.0319 - raw_multi_label_accuracy: 0.9830 - val_loss: 1.0437 - val_raw_multi_label_accuracy: 0.3214\n",
      "Epoch 83/1000\n",
      " - 4s - loss: 0.0304 - raw_multi_label_accuracy: 0.9852 - val_loss: 1.0099 - val_raw_multi_label_accuracy: 0.3341\n",
      "Epoch 84/1000\n",
      " - 4s - loss: 0.0296 - raw_multi_label_accuracy: 0.9879 - val_loss: 1.1113 - val_raw_multi_label_accuracy: 0.3368\n",
      "Epoch 85/1000\n",
      " - 4s - loss: 0.0310 - raw_multi_label_accuracy: 0.9830 - val_loss: 1.0937 - val_raw_multi_label_accuracy: 0.3378\n",
      "Epoch 86/1000\n",
      " - 4s - loss: 0.0287 - raw_multi_label_accuracy: 0.9883 - val_loss: 1.0906 - val_raw_multi_label_accuracy: 0.3431\n",
      "Epoch 87/1000\n",
      " - 4s - loss: 0.0300 - raw_multi_label_accuracy: 0.9853 - val_loss: 1.1322 - val_raw_multi_label_accuracy: 0.3175\n",
      "Epoch 88/1000\n",
      " - 4s - loss: 0.0289 - raw_multi_label_accuracy: 0.9863 - val_loss: 1.0615 - val_raw_multi_label_accuracy: 0.3535\n",
      "Epoch 89/1000\n",
      " - 4s - loss: 0.0251 - raw_multi_label_accuracy: 0.9893 - val_loss: 1.1005 - val_raw_multi_label_accuracy: 0.3310\n",
      "Epoch 90/1000\n",
      " - 4s - loss: 0.0286 - raw_multi_label_accuracy: 0.9835 - val_loss: 1.0552 - val_raw_multi_label_accuracy: 0.3208\n",
      "Epoch 91/1000\n",
      " - 4s - loss: 0.0289 - raw_multi_label_accuracy: 0.9850 - val_loss: 1.0869 - val_raw_multi_label_accuracy: 0.3189\n",
      "Epoch 92/1000\n",
      " - 4s - loss: 0.0290 - raw_multi_label_accuracy: 0.9856 - val_loss: 1.0531 - val_raw_multi_label_accuracy: 0.3409\n",
      "Epoch 93/1000\n",
      " - 4s - loss: 0.0277 - raw_multi_label_accuracy: 0.9875 - val_loss: 1.1303 - val_raw_multi_label_accuracy: 0.3053\n",
      "Epoch 94/1000\n",
      " - 4s - loss: 0.0250 - raw_multi_label_accuracy: 0.9892 - val_loss: 1.0728 - val_raw_multi_label_accuracy: 0.3559\n",
      "Epoch 95/1000\n",
      " - 4s - loss: 0.0238 - raw_multi_label_accuracy: 0.9896 - val_loss: 1.1043 - val_raw_multi_label_accuracy: 0.3282\n",
      "Epoch 96/1000\n",
      " - 4s - loss: 0.0260 - raw_multi_label_accuracy: 0.9851 - val_loss: 1.1350 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 97/1000\n",
      " - 4s - loss: 0.0246 - raw_multi_label_accuracy: 0.9897 - val_loss: 1.1081 - val_raw_multi_label_accuracy: 0.3317\n",
      "Epoch 98/1000\n",
      " - 4s - loss: 0.0272 - raw_multi_label_accuracy: 0.9878 - val_loss: 1.1593 - val_raw_multi_label_accuracy: 0.3147\n",
      "Epoch 99/1000\n",
      " - 4s - loss: 0.0282 - raw_multi_label_accuracy: 0.9874 - val_loss: 1.1942 - val_raw_multi_label_accuracy: 0.3315\n",
      "Epoch 100/1000\n",
      " - 4s - loss: 0.0291 - raw_multi_label_accuracy: 0.9864 - val_loss: 1.1508 - val_raw_multi_label_accuracy: 0.3452\n",
      "Epoch 101/1000\n",
      " - 4s - loss: 0.0273 - raw_multi_label_accuracy: 0.9918 - val_loss: 1.2541 - val_raw_multi_label_accuracy: 0.3230\n",
      "Epoch 102/1000\n",
      " - 4s - loss: 0.0250 - raw_multi_label_accuracy: 0.9912 - val_loss: 1.1444 - val_raw_multi_label_accuracy: 0.3408\n",
      "Epoch 103/1000\n",
      " - 4s - loss: 0.0239 - raw_multi_label_accuracy: 0.9909 - val_loss: 1.1241 - val_raw_multi_label_accuracy: 0.3268\n",
      "Epoch 104/1000\n",
      " - 4s - loss: 0.0242 - raw_multi_label_accuracy: 0.9894 - val_loss: 1.1322 - val_raw_multi_label_accuracy: 0.3127\n",
      "Epoch 105/1000\n",
      " - 4s - loss: 0.0263 - raw_multi_label_accuracy: 0.9856 - val_loss: 1.2004 - val_raw_multi_label_accuracy: 0.3414\n",
      "Epoch 106/1000\n",
      " - 4s - loss: 0.0263 - raw_multi_label_accuracy: 0.9885 - val_loss: 1.1689 - val_raw_multi_label_accuracy: 0.3537\n",
      "Epoch 107/1000\n",
      " - 4s - loss: 0.0275 - raw_multi_label_accuracy: 0.9879 - val_loss: 1.1669 - val_raw_multi_label_accuracy: 0.3536\n",
      "Epoch 108/1000\n",
      " - 4s - loss: 0.0269 - raw_multi_label_accuracy: 0.9838 - val_loss: 1.1313 - val_raw_multi_label_accuracy: 0.3246\n",
      "Epoch 109/1000\n",
      " - 4s - loss: 0.0246 - raw_multi_label_accuracy: 0.9896 - val_loss: 1.2078 - val_raw_multi_label_accuracy: 0.3168\n",
      "Epoch 110/1000\n",
      " - 4s - loss: 0.0238 - raw_multi_label_accuracy: 0.9891 - val_loss: 1.1602 - val_raw_multi_label_accuracy: 0.3386\n",
      "Epoch 111/1000\n",
      " - 4s - loss: 0.0242 - raw_multi_label_accuracy: 0.9890 - val_loss: 1.1462 - val_raw_multi_label_accuracy: 0.3429\n",
      "Epoch 112/1000\n",
      " - 4s - loss: 0.0259 - raw_multi_label_accuracy: 0.9877 - val_loss: 1.1407 - val_raw_multi_label_accuracy: 0.3330\n",
      "Epoch 113/1000\n",
      " - 5s - loss: 0.0268 - raw_multi_label_accuracy: 0.9854 - val_loss: 1.1617 - val_raw_multi_label_accuracy: 0.3592\n",
      "Epoch 114/1000\n",
      " - 4s - loss: 0.0281 - raw_multi_label_accuracy: 0.9868 - val_loss: 1.2693 - val_raw_multi_label_accuracy: 0.3168\n",
      "Epoch 115/1000\n",
      " - 4s - loss: 0.0275 - raw_multi_label_accuracy: 0.9874 - val_loss: 1.2892 - val_raw_multi_label_accuracy: 0.3410\n",
      "Epoch 116/1000\n",
      " - 4s - loss: 0.0249 - raw_multi_label_accuracy: 0.9898 - val_loss: 1.2469 - val_raw_multi_label_accuracy: 0.3417\n",
      "Epoch 117/1000\n",
      " - 4s - loss: 0.0279 - raw_multi_label_accuracy: 0.9848 - val_loss: 1.2223 - val_raw_multi_label_accuracy: 0.3389\n",
      "Epoch 118/1000\n",
      " - 4s - loss: 0.0261 - raw_multi_label_accuracy: 0.9878 - val_loss: 1.1810 - val_raw_multi_label_accuracy: 0.3539\n",
      "Epoch 119/1000\n",
      " - 4s - loss: 0.0270 - raw_multi_label_accuracy: 0.9890 - val_loss: 1.2492 - val_raw_multi_label_accuracy: 0.3358\n",
      "Epoch 120/1000\n",
      " - 4s - loss: 0.0245 - raw_multi_label_accuracy: 0.9892 - val_loss: 1.2029 - val_raw_multi_label_accuracy: 0.3447\n",
      "Epoch 121/1000\n",
      " - 4s - loss: 0.0243 - raw_multi_label_accuracy: 0.9899 - val_loss: 1.2490 - val_raw_multi_label_accuracy: 0.3331\n",
      "Epoch 122/1000\n",
      " - 4s - loss: 0.0261 - raw_multi_label_accuracy: 0.9882 - val_loss: 1.2554 - val_raw_multi_label_accuracy: 0.3375\n",
      "Epoch 123/1000\n",
      " - 4s - loss: 0.0279 - raw_multi_label_accuracy: 0.9860 - val_loss: 1.3847 - val_raw_multi_label_accuracy: 0.3343\n",
      "Epoch 124/1000\n",
      " - 4s - loss: 0.0267 - raw_multi_label_accuracy: 0.9878 - val_loss: 1.3146 - val_raw_multi_label_accuracy: 0.3376\n",
      "Epoch 125/1000\n",
      " - 4s - loss: 0.0283 - raw_multi_label_accuracy: 0.9856 - val_loss: 1.2722 - val_raw_multi_label_accuracy: 0.3431\n",
      "Epoch 126/1000\n",
      " - 4s - loss: 0.0242 - raw_multi_label_accuracy: 0.9906 - val_loss: 1.3342 - val_raw_multi_label_accuracy: 0.3188\n",
      "Epoch 127/1000\n",
      " - 4s - loss: 0.0264 - raw_multi_label_accuracy: 0.9856 - val_loss: 1.3882 - val_raw_multi_label_accuracy: 0.3414\n",
      "Epoch 128/1000\n",
      " - 4s - loss: 0.0228 - raw_multi_label_accuracy: 0.9927 - val_loss: 1.3195 - val_raw_multi_label_accuracy: 0.3258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/1000\n",
      " - 4s - loss: 0.0242 - raw_multi_label_accuracy: 0.9885 - val_loss: 1.2798 - val_raw_multi_label_accuracy: 0.3217\n",
      "Epoch 130/1000\n",
      " - 4s - loss: 0.0218 - raw_multi_label_accuracy: 0.9934 - val_loss: 1.3802 - val_raw_multi_label_accuracy: 0.2890\n",
      "Epoch 131/1000\n",
      " - 4s - loss: 0.0222 - raw_multi_label_accuracy: 0.9892 - val_loss: 1.2538 - val_raw_multi_label_accuracy: 0.3293\n",
      "Epoch 132/1000\n",
      " - 4s - loss: 0.0288 - raw_multi_label_accuracy: 0.9840 - val_loss: 1.3560 - val_raw_multi_label_accuracy: 0.3060\n",
      "Epoch 133/1000\n",
      " - 4s - loss: 0.0266 - raw_multi_label_accuracy: 0.9910 - val_loss: 1.3333 - val_raw_multi_label_accuracy: 0.3256\n",
      "Epoch 134/1000\n",
      " - 4s - loss: 0.0238 - raw_multi_label_accuracy: 0.9930 - val_loss: 1.3119 - val_raw_multi_label_accuracy: 0.3492\n",
      "Epoch 135/1000\n",
      " - 4s - loss: 0.0215 - raw_multi_label_accuracy: 0.9927 - val_loss: 1.2455 - val_raw_multi_label_accuracy: 0.3542\n",
      "Epoch 136/1000\n",
      " - 4s - loss: 0.0210 - raw_multi_label_accuracy: 0.9922 - val_loss: 1.3654 - val_raw_multi_label_accuracy: 0.3174\n",
      "Epoch 137/1000\n",
      " - 4s - loss: 0.0222 - raw_multi_label_accuracy: 0.9904 - val_loss: 1.2177 - val_raw_multi_label_accuracy: 0.3455\n",
      "Epoch 138/1000\n",
      " - 4s - loss: 0.0206 - raw_multi_label_accuracy: 0.9921 - val_loss: 1.3170 - val_raw_multi_label_accuracy: 0.3247\n",
      "Epoch 139/1000\n",
      " - 4s - loss: 0.0216 - raw_multi_label_accuracy: 0.9921 - val_loss: 1.3690 - val_raw_multi_label_accuracy: 0.3175\n",
      "Epoch 140/1000\n",
      " - 4s - loss: 0.0237 - raw_multi_label_accuracy: 0.9891 - val_loss: 1.2775 - val_raw_multi_label_accuracy: 0.3243\n",
      "Epoch 141/1000\n",
      " - 4s - loss: 0.0244 - raw_multi_label_accuracy: 0.9903 - val_loss: 1.2694 - val_raw_multi_label_accuracy: 0.3594\n",
      "Epoch 142/1000\n",
      " - 4s - loss: 0.0269 - raw_multi_label_accuracy: 0.9875 - val_loss: 1.3671 - val_raw_multi_label_accuracy: 0.3341\n",
      "Epoch 143/1000\n",
      " - 4s - loss: 0.0260 - raw_multi_label_accuracy: 0.9908 - val_loss: 1.3403 - val_raw_multi_label_accuracy: 0.3467\n",
      "Epoch 144/1000\n",
      " - 4s - loss: 0.0246 - raw_multi_label_accuracy: 0.9908 - val_loss: 1.3459 - val_raw_multi_label_accuracy: 0.3264\n",
      "Epoch 145/1000\n",
      " - 4s - loss: 0.0193 - raw_multi_label_accuracy: 0.9960 - val_loss: 1.3262 - val_raw_multi_label_accuracy: 0.3458\n",
      "Epoch 146/1000\n",
      " - 4s - loss: 0.0190 - raw_multi_label_accuracy: 0.9935 - val_loss: 1.2662 - val_raw_multi_label_accuracy: 0.3382\n",
      "Epoch 147/1000\n",
      " - 4s - loss: 0.0198 - raw_multi_label_accuracy: 0.9931 - val_loss: 1.2497 - val_raw_multi_label_accuracy: 0.3443\n",
      "Epoch 148/1000\n",
      " - 4s - loss: 0.0277 - raw_multi_label_accuracy: 0.9840 - val_loss: 1.4573 - val_raw_multi_label_accuracy: 0.3124\n",
      "Epoch 149/1000\n",
      " - 4s - loss: 0.0283 - raw_multi_label_accuracy: 0.9878 - val_loss: 1.4738 - val_raw_multi_label_accuracy: 0.3135\n",
      "Epoch 150/1000\n",
      " - 4s - loss: 0.0250 - raw_multi_label_accuracy: 0.9927 - val_loss: 1.3762 - val_raw_multi_label_accuracy: 0.3373\n",
      "Epoch 151/1000\n",
      " - 4s - loss: 0.0213 - raw_multi_label_accuracy: 0.9934 - val_loss: 1.3604 - val_raw_multi_label_accuracy: 0.3289\n",
      "Epoch 152/1000\n",
      " - 4s - loss: 0.0184 - raw_multi_label_accuracy: 0.9933 - val_loss: 1.3292 - val_raw_multi_label_accuracy: 0.3374\n",
      "Epoch 153/1000\n",
      " - 4s - loss: 0.0189 - raw_multi_label_accuracy: 0.9913 - val_loss: 1.2487 - val_raw_multi_label_accuracy: 0.3346\n",
      "Epoch 154/1000\n",
      " - 4s - loss: 0.0169 - raw_multi_label_accuracy: 0.9941 - val_loss: 1.2663 - val_raw_multi_label_accuracy: 0.3232\n",
      "Epoch 155/1000\n",
      " - 4s - loss: 0.0171 - raw_multi_label_accuracy: 0.9937 - val_loss: 1.3745 - val_raw_multi_label_accuracy: 0.2951\n",
      "Epoch 156/1000\n",
      " - 4s - loss: 0.0158 - raw_multi_label_accuracy: 0.9953 - val_loss: 1.2338 - val_raw_multi_label_accuracy: 0.3340\n",
      "Epoch 157/1000\n",
      " - 4s - loss: 0.0156 - raw_multi_label_accuracy: 0.9952 - val_loss: 1.3718 - val_raw_multi_label_accuracy: 0.3188\n",
      "Epoch 158/1000\n",
      " - 4s - loss: 0.0181 - raw_multi_label_accuracy: 0.9911 - val_loss: 1.3217 - val_raw_multi_label_accuracy: 0.3305\n",
      "Epoch 159/1000\n",
      " - 4s - loss: 0.0186 - raw_multi_label_accuracy: 0.9915 - val_loss: 1.3149 - val_raw_multi_label_accuracy: 0.3280\n",
      "Epoch 160/1000\n",
      " - 4s - loss: 0.0175 - raw_multi_label_accuracy: 0.9942 - val_loss: 1.4523 - val_raw_multi_label_accuracy: 0.3198\n",
      "Epoch 161/1000\n",
      " - 4s - loss: 0.0180 - raw_multi_label_accuracy: 0.9901 - val_loss: 1.2869 - val_raw_multi_label_accuracy: 0.3019\n",
      "Epoch 162/1000\n",
      " - 4s - loss: 0.0170 - raw_multi_label_accuracy: 0.9949 - val_loss: 1.3581 - val_raw_multi_label_accuracy: 0.3565\n",
      "Epoch 163/1000\n",
      " - 4s - loss: 0.0178 - raw_multi_label_accuracy: 0.9922 - val_loss: 1.3287 - val_raw_multi_label_accuracy: 0.3291\n",
      "Epoch 164/1000\n",
      " - 4s - loss: 0.0187 - raw_multi_label_accuracy: 0.9938 - val_loss: 1.4674 - val_raw_multi_label_accuracy: 0.3189\n",
      "Epoch 165/1000\n",
      " - 4s - loss: 0.0180 - raw_multi_label_accuracy: 0.9952 - val_loss: 1.4904 - val_raw_multi_label_accuracy: 0.3092\n",
      "Epoch 166/1000\n",
      " - 4s - loss: 0.0164 - raw_multi_label_accuracy: 0.9960 - val_loss: 1.4061 - val_raw_multi_label_accuracy: 0.3188\n",
      "Epoch 167/1000\n",
      " - 4s - loss: 0.0171 - raw_multi_label_accuracy: 0.9908 - val_loss: 1.3542 - val_raw_multi_label_accuracy: 0.3147\n",
      "Epoch 168/1000\n",
      " - 4s - loss: 0.0186 - raw_multi_label_accuracy: 0.9934 - val_loss: 1.3425 - val_raw_multi_label_accuracy: 0.3493\n",
      "Epoch 169/1000\n",
      " - 4s - loss: 0.0201 - raw_multi_label_accuracy: 0.9904 - val_loss: 1.4219 - val_raw_multi_label_accuracy: 0.3130\n",
      "Epoch 170/1000\n",
      " - 4s - loss: 0.0198 - raw_multi_label_accuracy: 0.9924 - val_loss: 1.4633 - val_raw_multi_label_accuracy: 0.3404\n",
      "Epoch 171/1000\n",
      " - 4s - loss: 0.0206 - raw_multi_label_accuracy: 0.9915 - val_loss: 1.4588 - val_raw_multi_label_accuracy: 0.3165\n",
      "Epoch 172/1000\n",
      " - 4s - loss: 0.0199 - raw_multi_label_accuracy: 0.9918 - val_loss: 1.5423 - val_raw_multi_label_accuracy: 0.2996\n",
      "Epoch 173/1000\n",
      " - 4s - loss: 0.0193 - raw_multi_label_accuracy: 0.9937 - val_loss: 1.4246 - val_raw_multi_label_accuracy: 0.3247\n",
      "Epoch 174/1000\n",
      " - 4s - loss: 0.0178 - raw_multi_label_accuracy: 0.9930 - val_loss: 1.5253 - val_raw_multi_label_accuracy: 0.3288\n",
      "Epoch 175/1000\n",
      " - 4s - loss: 0.0217 - raw_multi_label_accuracy: 0.9906 - val_loss: 1.4312 - val_raw_multi_label_accuracy: 0.3175\n",
      "Epoch 176/1000\n",
      " - 4s - loss: 0.0228 - raw_multi_label_accuracy: 0.9901 - val_loss: 1.5567 - val_raw_multi_label_accuracy: 0.3160\n",
      "Epoch 177/1000\n",
      " - 4s - loss: 0.0253 - raw_multi_label_accuracy: 0.9887 - val_loss: 1.4798 - val_raw_multi_label_accuracy: 0.3039\n",
      "Epoch 178/1000\n",
      " - 4s - loss: 0.0230 - raw_multi_label_accuracy: 0.9933 - val_loss: 1.4370 - val_raw_multi_label_accuracy: 0.3487\n",
      "Epoch 179/1000\n",
      " - 4s - loss: 0.0209 - raw_multi_label_accuracy: 0.9959 - val_loss: 1.6393 - val_raw_multi_label_accuracy: 0.3303\n",
      "Epoch 180/1000\n",
      " - 4s - loss: 0.0193 - raw_multi_label_accuracy: 0.9930 - val_loss: 1.5445 - val_raw_multi_label_accuracy: 0.2918\n",
      "Epoch 181/1000\n",
      " - 4s - loss: 0.0184 - raw_multi_label_accuracy: 0.9949 - val_loss: 1.4464 - val_raw_multi_label_accuracy: 0.3365\n",
      "Epoch 182/1000\n",
      " - 4s - loss: 0.0170 - raw_multi_label_accuracy: 0.9945 - val_loss: 1.5038 - val_raw_multi_label_accuracy: 0.3123\n",
      "Epoch 183/1000\n",
      " - 4s - loss: 0.0175 - raw_multi_label_accuracy: 0.9926 - val_loss: 1.4580 - val_raw_multi_label_accuracy: 0.2990\n",
      "Epoch 184/1000\n",
      " - 4s - loss: 0.0183 - raw_multi_label_accuracy: 0.9923 - val_loss: 1.4656 - val_raw_multi_label_accuracy: 0.3243\n",
      "Epoch 185/1000\n",
      " - 4s - loss: 0.0197 - raw_multi_label_accuracy: 0.9933 - val_loss: 1.4873 - val_raw_multi_label_accuracy: 0.3053\n",
      "Epoch 186/1000\n",
      " - 4s - loss: 0.0185 - raw_multi_label_accuracy: 0.9945 - val_loss: 1.4856 - val_raw_multi_label_accuracy: 0.3341\n",
      "Epoch 187/1000\n",
      " - 4s - loss: 0.0189 - raw_multi_label_accuracy: 0.9918 - val_loss: 1.5055 - val_raw_multi_label_accuracy: 0.3164\n",
      "Epoch 188/1000\n",
      " - 4s - loss: 0.0194 - raw_multi_label_accuracy: 0.9941 - val_loss: 1.5955 - val_raw_multi_label_accuracy: 0.2815\n",
      "Epoch 189/1000\n",
      " - 4s - loss: 0.0211 - raw_multi_label_accuracy: 0.9903 - val_loss: 1.4588 - val_raw_multi_label_accuracy: 0.3279\n",
      "Epoch 190/1000\n",
      " - 4s - loss: 0.0188 - raw_multi_label_accuracy: 0.9942 - val_loss: 1.4767 - val_raw_multi_label_accuracy: 0.3247\n",
      "Epoch 191/1000\n",
      " - 5s - loss: 0.0199 - raw_multi_label_accuracy: 0.9912 - val_loss: 1.6091 - val_raw_multi_label_accuracy: 0.3079\n",
      "Epoch 192/1000\n",
      " - 4s - loss: 0.0203 - raw_multi_label_accuracy: 0.9917 - val_loss: 1.6078 - val_raw_multi_label_accuracy: 0.3162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000\n",
      " - 4s - loss: 0.0211 - raw_multi_label_accuracy: 0.9918 - val_loss: 1.6954 - val_raw_multi_label_accuracy: 0.3380\n",
      "Epoch 194/1000\n",
      " - 4s - loss: 0.0256 - raw_multi_label_accuracy: 0.9891 - val_loss: 1.6477 - val_raw_multi_label_accuracy: 0.3172\n",
      "Epoch 195/1000\n",
      " - 4s - loss: 0.0249 - raw_multi_label_accuracy: 0.9919 - val_loss: 1.5984 - val_raw_multi_label_accuracy: 0.3140\n",
      "Epoch 196/1000\n",
      " - 4s - loss: 0.0242 - raw_multi_label_accuracy: 0.9929 - val_loss: 1.6638 - val_raw_multi_label_accuracy: 0.3121\n",
      "Epoch 197/1000\n",
      " - 4s - loss: 0.0241 - raw_multi_label_accuracy: 0.9912 - val_loss: 1.6545 - val_raw_multi_label_accuracy: 0.2815\n",
      "Epoch 198/1000\n",
      " - 4s - loss: 0.0221 - raw_multi_label_accuracy: 0.9937 - val_loss: 1.6714 - val_raw_multi_label_accuracy: 0.3044\n",
      "Epoch 199/1000\n",
      " - 4s - loss: 0.0183 - raw_multi_label_accuracy: 0.9949 - val_loss: 1.6279 - val_raw_multi_label_accuracy: 0.3238\n",
      "Epoch 200/1000\n",
      " - 4s - loss: 0.0197 - raw_multi_label_accuracy: 0.9927 - val_loss: 1.5487 - val_raw_multi_label_accuracy: 0.3100\n",
      "Epoch 201/1000\n",
      " - 4s - loss: 0.0189 - raw_multi_label_accuracy: 0.9926 - val_loss: 1.6227 - val_raw_multi_label_accuracy: 0.3336\n",
      "Epoch 202/1000\n",
      " - 4s - loss: 0.0178 - raw_multi_label_accuracy: 0.9941 - val_loss: 1.5463 - val_raw_multi_label_accuracy: 0.3178\n",
      "Epoch 203/1000\n",
      " - 4s - loss: 0.0194 - raw_multi_label_accuracy: 0.9930 - val_loss: 1.6366 - val_raw_multi_label_accuracy: 0.3260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff99957f748>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=200)], epochs=1000, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3321256038647344"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42822636300897177"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_precision(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4366804692891649"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_recall(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correctly decided label decisions: 64.59627329192547\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuruacy for Action-Adventure: 0.5755693581780539\n",
      "Precision for Action-Adventure: 0.46484375\n",
      "Recall for Action-Adventure: 0.6363636363636364\n",
      "\n",
      "Accuruacy for Romance: 0.722567287784679\n",
      "Precision for Romance: 0.3157894736842105\n",
      "Recall for Romance: 0.22641509433962265\n",
      "\n",
      "Accuruacy for Horror-Thriller: 0.505175983436853\n",
      "Precision for Horror-Thriller: 0.41637010676156583\n",
      "Recall for Horror-Thriller: 0.609375\n",
      "\n",
      "Accuruacy for Comedy: 0.5631469979296067\n",
      "Precision for Comedy: 0.5083333333333333\n",
      "Recall for Comedy: 0.2863849765258216\n",
      "\n",
      "Accuruacy for Science Fiction: 0.8633540372670807\n",
      "Precision for Science Fiction: 0.25\n",
      "Recall for Science Fiction: 0.08928571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_per_label_metrics(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
